{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "딥러닝2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1h5WuhNPAtmx1u_Rko6BAF7DCkjLIxjrh",
      "authorship_tag": "ABX9TyNOeKC397vkpBMrc1S5zjqZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/euna-jeong20/deep-learning-from-scratch/blob/main/%EB%94%A5%EB%9F%AC%EB%8B%9D2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40-N_I4SzfM7"
      },
      "source": [
        "#1장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Solp2sVRzQPu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "e5ba4bc7-e885-4b6b-e3c9-0fd6ceb6d47d"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.array([1, 2, 3])\n",
        "print(x.__class__)\n",
        "\n",
        "print(x.shape)\n",
        "print(x.ndim)\n",
        "\n",
        "W = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "print(W.shape)\n",
        "print(W.ndim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(3,)\n",
            "1\n",
            "(2, 3)\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUi7l23H1fmh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "01e77150-c57f-41bc-f1a7-f8362f305117"
      },
      "source": [
        "A = np.array([[1, 2] , [3, 4]])\n",
        "print(A * 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10 20]\n",
            " [30 40]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOsd14hw1tZD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2ec3d407-c457-40b1-e088-ad92606f6257"
      },
      "source": [
        "A = np.array([[1, 2], [3, 4]])\n",
        "b = np.array([10, 20])\n",
        "print(A * b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10 40]\n",
            " [30 80]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJfYOoh411nT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "8a6bac4f-5b82-4f28-8c2a-61fdd9f84a17"
      },
      "source": [
        "#벡터의 내적 - dot\n",
        "a = np.array([1, 2, 3])\n",
        "b = np.array([4, 5, 6])\n",
        "print(np.dot(a, b))\n",
        "\n",
        "#행렬의 곱 - matmul\n",
        "A = np.array([[1, 2], [3, 4]])\n",
        "B = np.array([[5, 6], [7, 8]])\n",
        "print(np.matmul(A, B))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "[[19 22]\n",
            " [43 50]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_93moQak2u0T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5d654546-b7af-4016-8055-9d94cf380535"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "W1 = np.random.randn(2, 4)  # 가중치\n",
        "b1 = np.random.randn(4)     # 편향\n",
        "x = np.random.randn(10, 2)  # 입력\n",
        "h = np.matmul(x, W1) + b1\n",
        "\n",
        "print(h.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETghDsoS4MlK"
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9Ur9TkP4_gi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2c4dbf66-9382-4509-a120-29d76a5ad5d7"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "#형태 맞추기\n",
        "x = np.random.randn(10, 2)\n",
        "W1 = np.random.randn(2, 4)\n",
        "b1 = np.random.randn(4)\n",
        "W2 = np.random.randn(4, 3)\n",
        "b2 = np.random.randn(3)\n",
        "\n",
        "h = np.matmul(x, W1) + b1\n",
        "a = sigmoid(h)\n",
        "s = np.matmul(a, W2) + b2\n",
        "\n",
        "print(s.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC5w6wGI5mZU"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class Sigmoid:\n",
        "  def __init__(self):\n",
        "    self.params = []    #1권에서는 딕셔너리\n",
        "\n",
        "  def forward(self, x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "class Affine:\n",
        "  def __init__(self, W, b):\n",
        "    self.params = [W, b]\n",
        "\n",
        "  def forward(self, x):\n",
        "    W, b = self.params\n",
        "    out = np.matmul(x, W) + b\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyj7U4qi65fb"
      },
      "source": [
        "class TwoLayerNet:\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    I, H, O = input_size, hidden_size, output_size\n",
        "    \n",
        "    #가중치와 편향 초기화\n",
        "    W1 = np.random.randn(I, H)\n",
        "    b1 = np.random.randn(H)\n",
        "    W2 = np.random.randn(H, O)\n",
        "    b2 = np.random.randn(O)\n",
        "\n",
        "    #계층생성\n",
        "    self.layers = [Affine(W1, b1), Sigmoid(), Affine(W2, b2)]\n",
        "\n",
        "    #모든 가중치를 리스트에 모은다\n",
        "    self.params = []\n",
        "    for layer in self.layers:\n",
        "      self.params += layer.params\n",
        "\n",
        "  def predict(self, x):\n",
        "    for layer in self.layers:\n",
        "      x = layer.forward(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tA0Hybk8dKA"
      },
      "source": [
        "x = np.random.randn(10, 2)\n",
        "model = TwoLayerNet(2, 4, 3)\n",
        "s = model.predict(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_34hxLQ9duh"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "D, N = 8, 7\n",
        "x = np.random.randn(1, D)               # 입력      행으로 계산하고 싶어서\n",
        "y = np.repeat(x, N, axis=0)             # 순전파      N번 복제를 세로 방향으로 하고 싶다\n",
        "dy = np.random.randn(N, D)              # 무작위 기울기     7X8\n",
        "dx = np.sum(dy, axis=0, keepdims=True)  # 역전파       열끼리 다 더한다/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMMfEOR6FT9X"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "D, N = 8, 7\n",
        "x = np.random.randn(N, D)              # 입력\n",
        "y = np.sum(x, axis=0, keepdims=True)   # 순전파\n",
        "\n",
        "dy = np.random.randn(1, D)             # 무작위 기울기\n",
        "dx = np.repeat(dy, N, axis=0)          # 역전파"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7od1du1CFoxo"
      },
      "source": [
        "class MatMul:\n",
        "  def __init__(sself, W):\n",
        "    self.params = [W]\n",
        "    self.grads = [np.zeros_like(W)]\n",
        "    self.x = None\n",
        "  \n",
        "  def forward(self, x):\n",
        "    W,  = self.params\n",
        "    out = np.matmul(x, W)\n",
        "    self.x = x\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    W,  =self.params\n",
        "    dx = np.matmul(dout, W.T)\n",
        "    dW = np.matmul(self.x.T, dout)\n",
        "    self.grads[0][...] = dW\n",
        "    return dx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqoTvG_OHAz7"
      },
      "source": [
        "list1 = [1, 2, 3]\n",
        "list2 = list1 #얕은 복사 메모리가 저장\n",
        "\n",
        "#깊은 복사\n",
        "list2 = list1[:]\n",
        "list2 = list1.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7arAKoHwIaZn"
      },
      "source": [
        "class Sigmoid:\n",
        "  def __init__(self):\n",
        "    self.params, self.grads = [], []\n",
        "    self.out = None\n",
        "  \n",
        "  def forward(self, x):\n",
        "    out = 1 / (1 +np.exp(-x))\n",
        "    self.out = out\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    dx = dout * (1.0 - self.out) * self.out\n",
        "    return dx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbH03GGSI_zf"
      },
      "source": [
        "class Affine:\n",
        "  def __init__(self, W, b):\n",
        "    self.params = [W, b]\n",
        "    self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
        "    self.x = None\n",
        "  \n",
        "  def forward(self, x):\n",
        "    W, b = self.params\n",
        "    out = np.matmul(x, W) + b\n",
        "    self.x = x\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    W, b =self.params\n",
        "    dx = np.matmul(dout, W.T)\n",
        "    dw = np.matmul(self.x.T, dout)\n",
        "    db = np.sum(dout,axis=0)\n",
        "\n",
        "    self.grads[0][...] = dw\n",
        "    self.grads[1][...] = db\n",
        "    return dx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1abJGREJyiK"
      },
      "source": [
        "class SGD:\n",
        "  def __init__(self, lr=0.01):\n",
        "    self.lr = %ldir\n",
        "    \n",
        "  def update(self, params, grads):\n",
        "    for i in randge(len(params)):\n",
        "      params[i] -= self.lr * grads[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DObHvYwQK6ph",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "7b2b2ad1-79f4-475b-87f7-ce0cac17975f"
      },
      "source": [
        "import numpy as np\n",
        "import sys, os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master')\n",
        "\n",
        "from dataset import spiral\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x, t = spiral.load_data()\n",
        "print('x', x.shape)\n",
        "print('t', t.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x (300, 2)\n",
            "t (300, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2a8V-QANUUY"
      },
      "source": [
        "import numpy as np\n",
        "import sys, os\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master')\n",
        "\n",
        "from common.layers import Affine, Sigmoid, SoftmaxWithLoss\n",
        "\n",
        "class TwoLayerNet:\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    I, H, O = input_size, hidden_size, output_size\n",
        "    \n",
        "    #가중치와 편향 초기화\n",
        "    W1 = 0.01 * np.random.randn(I, H)   #가중치를 작은 무작위 값으로 설정하면 학습이 잘 될 가능성이 커져서 0.01을 곱해준다\n",
        "    b1 = np.zeros(H)\n",
        "    W2 = 0.01 * np.random.randn(H, O)\n",
        "    b2 = np.zeros(O)\n",
        "\n",
        "\n",
        "    #계층생성\n",
        "    self.layers = [Affine(W1, b1), Sigmoid(), Affine(W2, b2)]\n",
        "    self.loss_layer = SoftmaxWithLoss()\n",
        "\n",
        "    #모든 가중치와 기울기를 리스트에 모은다.  p39참고\n",
        "    self.params, self.grads = [], []\n",
        "    for layer in self.layers:\n",
        "      self.params += layer.params\n",
        "      self.grads += layer.grads"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjL_5X63Xj_g"
      },
      "source": [
        "def predict(self, x):\n",
        "  for layer in self.layers:\n",
        "    x = layer.forward(x)\n",
        "  return x\n",
        "\n",
        "def forward(self, x, t):\n",
        "  score = self.predict(x)\n",
        "  loss = self.loss_layer.forward(score, t)\n",
        "  return loss\n",
        "\n",
        "def backward(self, dout=1):\n",
        "  dout = self.loo_layer.backward(dout)\n",
        "  for layer in reversed(self.layers):\n",
        "    dout = layer.backward(dout)\n",
        "  return dout\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p22dfv_oYZ_h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5e53c8eb-7322-4a98-be8e-49fd7ef202e0"
      },
      "source": [
        "import numpy as np\n",
        "import sys, os\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master')\n",
        "\n",
        "\n",
        "\n",
        "from common.optimizer import SGD\n",
        "from dataset import spiral\n",
        "import matplotlib.pyplot as plt\n",
        "from ch01.two_layer_net import TwoLayerNet\n",
        "\n",
        "#1 하이퍼파라미터 설정\n",
        "max_epoch = 300\n",
        "batch_size = 30\n",
        "hidden_size = 10\n",
        "learning_rate = 1.0\n",
        "\n",
        "#2 데이터 읽기, 모델과 옵티마이저 생성\n",
        "x, t = spiral.load_data()\n",
        "model = TwoLayerNet(input_size=2, hidden_size=hidden_size, output_size=3)\n",
        "optimizer = SGD(lr=learning_rate)\n",
        "\n",
        "#학습에 사용하는 변수\n",
        "data_size = len(x)\n",
        "max_iters = data_size // batch_size\n",
        "total_loss = 0\n",
        "loss_count = 0\n",
        "loss_list = []\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "  #3 데이터 뒤섞기\n",
        "  idx = np.random.permutation(data_size)\n",
        "  x = x[idx]\n",
        "  t = t[idx]\n",
        "\n",
        "  for iters in range(max_iters):\n",
        "    batch_x = x[iters * batch_size : (iters+1) * batch_size]\n",
        "    batch_t = t[iters * batch_size : (iters+1) * batch_size]\n",
        "\n",
        "    #4 기울기를 구해 매개변수 갱신\n",
        "    loss = model.forward(batch_x, batch_t)\n",
        "    model.backward()\n",
        "    optimizer.update(model.params, model.grads)\n",
        "\n",
        "    total_loss += loss\n",
        "    loss_count += 1\n",
        "\n",
        "    #5 정기적으로 학습 경과 출력\n",
        "    if (iters+1) % 10 == 0:\n",
        "      avg_loss = total_loss / loss_count\n",
        "      print('| 에폭 %d | 반복  %d / %d | 손실 %.2f' % (epoch +1, iters +1, max_iters, avg_loss))\n",
        "      loss_list.append(avg_loss)\n",
        "      total_loss, loss_count = 0, 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| 에폭 1 | 반복  10 / 10 | 손실 1.13\n",
            "| 에폭 2 | 반복  10 / 10 | 손실 1.13\n",
            "| 에폭 3 | 반복  10 / 10 | 손실 1.12\n",
            "| 에폭 4 | 반복  10 / 10 | 손실 1.12\n",
            "| 에폭 5 | 반복  10 / 10 | 손실 1.11\n",
            "| 에폭 6 | 반복  10 / 10 | 손실 1.14\n",
            "| 에폭 7 | 반복  10 / 10 | 손실 1.16\n",
            "| 에폭 8 | 반복  10 / 10 | 손실 1.11\n",
            "| 에폭 9 | 반복  10 / 10 | 손실 1.12\n",
            "| 에폭 10 | 반복  10 / 10 | 손실 1.13\n",
            "| 에폭 11 | 반복  10 / 10 | 손실 1.12\n",
            "| 에폭 12 | 반복  10 / 10 | 손실 1.11\n",
            "| 에폭 13 | 반복  10 / 10 | 손실 1.09\n",
            "| 에폭 14 | 반복  10 / 10 | 손실 1.08\n",
            "| 에폭 15 | 반복  10 / 10 | 손실 1.04\n",
            "| 에폭 16 | 반복  10 / 10 | 손실 1.03\n",
            "| 에폭 17 | 반복  10 / 10 | 손실 0.96\n",
            "| 에폭 18 | 반복  10 / 10 | 손실 0.92\n",
            "| 에폭 19 | 반복  10 / 10 | 손실 0.92\n",
            "| 에폭 20 | 반복  10 / 10 | 손실 0.87\n",
            "| 에폭 21 | 반복  10 / 10 | 손실 0.85\n",
            "| 에폭 22 | 반복  10 / 10 | 손실 0.82\n",
            "| 에폭 23 | 반복  10 / 10 | 손실 0.79\n",
            "| 에폭 24 | 반복  10 / 10 | 손실 0.78\n",
            "| 에폭 25 | 반복  10 / 10 | 손실 0.82\n",
            "| 에폭 26 | 반복  10 / 10 | 손실 0.78\n",
            "| 에폭 27 | 반복  10 / 10 | 손실 0.76\n",
            "| 에폭 28 | 반복  10 / 10 | 손실 0.76\n",
            "| 에폭 29 | 반복  10 / 10 | 손실 0.78\n",
            "| 에폭 30 | 반복  10 / 10 | 손실 0.75\n",
            "| 에폭 31 | 반복  10 / 10 | 손실 0.78\n",
            "| 에폭 32 | 반복  10 / 10 | 손실 0.77\n",
            "| 에폭 33 | 반복  10 / 10 | 손실 0.77\n",
            "| 에폭 34 | 반복  10 / 10 | 손실 0.78\n",
            "| 에폭 35 | 반복  10 / 10 | 손실 0.75\n",
            "| 에폭 36 | 반복  10 / 10 | 손실 0.74\n",
            "| 에폭 37 | 반복  10 / 10 | 손실 0.76\n",
            "| 에폭 38 | 반복  10 / 10 | 손실 0.76\n",
            "| 에폭 39 | 반복  10 / 10 | 손실 0.73\n",
            "| 에폭 40 | 반복  10 / 10 | 손실 0.75\n",
            "| 에폭 41 | 반복  10 / 10 | 손실 0.76\n",
            "| 에폭 42 | 반복  10 / 10 | 손실 0.76\n",
            "| 에폭 43 | 반복  10 / 10 | 손실 0.76\n",
            "| 에폭 44 | 반복  10 / 10 | 손실 0.74\n",
            "| 에폭 45 | 반복  10 / 10 | 손실 0.75\n",
            "| 에폭 46 | 반복  10 / 10 | 손실 0.73\n",
            "| 에폭 47 | 반복  10 / 10 | 손실 0.72\n",
            "| 에폭 48 | 반복  10 / 10 | 손실 0.73\n",
            "| 에폭 49 | 반복  10 / 10 | 손실 0.72\n",
            "| 에폭 50 | 반복  10 / 10 | 손실 0.72\n",
            "| 에폭 51 | 반복  10 / 10 | 손실 0.72\n",
            "| 에폭 52 | 반복  10 / 10 | 손실 0.72\n",
            "| 에폭 53 | 반복  10 / 10 | 손실 0.74\n",
            "| 에폭 54 | 반복  10 / 10 | 손실 0.74\n",
            "| 에폭 55 | 반복  10 / 10 | 손실 0.72\n",
            "| 에폭 56 | 반복  10 / 10 | 손실 0.72\n",
            "| 에폭 57 | 반복  10 / 10 | 손실 0.71\n",
            "| 에폭 58 | 반복  10 / 10 | 손실 0.70\n",
            "| 에폭 59 | 반복  10 / 10 | 손실 0.72\n",
            "| 에폭 60 | 반복  10 / 10 | 손실 0.70\n",
            "| 에폭 61 | 반복  10 / 10 | 손실 0.71\n",
            "| 에폭 62 | 반복  10 / 10 | 손실 0.72\n",
            "| 에폭 63 | 반복  10 / 10 | 손실 0.70\n",
            "| 에폭 64 | 반복  10 / 10 | 손실 0.71\n",
            "| 에폭 65 | 반복  10 / 10 | 손실 0.73\n",
            "| 에폭 66 | 반복  10 / 10 | 손실 0.70\n",
            "| 에폭 67 | 반복  10 / 10 | 손실 0.71\n",
            "| 에폭 68 | 반복  10 / 10 | 손실 0.69\n",
            "| 에폭 69 | 반복  10 / 10 | 손실 0.70\n",
            "| 에폭 70 | 반복  10 / 10 | 손실 0.71\n",
            "| 에폭 71 | 반복  10 / 10 | 손실 0.68\n",
            "| 에폭 72 | 반복  10 / 10 | 손실 0.69\n",
            "| 에폭 73 | 반복  10 / 10 | 손실 0.67\n",
            "| 에폭 74 | 반복  10 / 10 | 손실 0.68\n",
            "| 에폭 75 | 반복  10 / 10 | 손실 0.67\n",
            "| 에폭 76 | 반복  10 / 10 | 손실 0.66\n",
            "| 에폭 77 | 반복  10 / 10 | 손실 0.69\n",
            "| 에폭 78 | 반복  10 / 10 | 손실 0.64\n",
            "| 에폭 79 | 반복  10 / 10 | 손실 0.68\n",
            "| 에폭 80 | 반복  10 / 10 | 손실 0.64\n",
            "| 에폭 81 | 반복  10 / 10 | 손실 0.64\n",
            "| 에폭 82 | 반복  10 / 10 | 손실 0.66\n",
            "| 에폭 83 | 반복  10 / 10 | 손실 0.62\n",
            "| 에폭 84 | 반복  10 / 10 | 손실 0.62\n",
            "| 에폭 85 | 반복  10 / 10 | 손실 0.61\n",
            "| 에폭 86 | 반복  10 / 10 | 손실 0.60\n",
            "| 에폭 87 | 반복  10 / 10 | 손실 0.60\n",
            "| 에폭 88 | 반복  10 / 10 | 손실 0.61\n",
            "| 에폭 89 | 반복  10 / 10 | 손실 0.59\n",
            "| 에폭 90 | 반복  10 / 10 | 손실 0.58\n",
            "| 에폭 91 | 반복  10 / 10 | 손실 0.56\n",
            "| 에폭 92 | 반복  10 / 10 | 손실 0.56\n",
            "| 에폭 93 | 반복  10 / 10 | 손실 0.54\n",
            "| 에폭 94 | 반복  10 / 10 | 손실 0.53\n",
            "| 에폭 95 | 반복  10 / 10 | 손실 0.53\n",
            "| 에폭 96 | 반복  10 / 10 | 손실 0.52\n",
            "| 에폭 97 | 반복  10 / 10 | 손실 0.51\n",
            "| 에폭 98 | 반복  10 / 10 | 손실 0.50\n",
            "| 에폭 99 | 반복  10 / 10 | 손실 0.48\n",
            "| 에폭 100 | 반복  10 / 10 | 손실 0.48\n",
            "| 에폭 101 | 반복  10 / 10 | 손실 0.46\n",
            "| 에폭 102 | 반복  10 / 10 | 손실 0.45\n",
            "| 에폭 103 | 반복  10 / 10 | 손실 0.45\n",
            "| 에폭 104 | 반복  10 / 10 | 손실 0.44\n",
            "| 에폭 105 | 반복  10 / 10 | 손실 0.44\n",
            "| 에폭 106 | 반복  10 / 10 | 손실 0.41\n",
            "| 에폭 107 | 반복  10 / 10 | 손실 0.40\n",
            "| 에폭 108 | 반복  10 / 10 | 손실 0.41\n",
            "| 에폭 109 | 반복  10 / 10 | 손실 0.40\n",
            "| 에폭 110 | 반복  10 / 10 | 손실 0.40\n",
            "| 에폭 111 | 반복  10 / 10 | 손실 0.38\n",
            "| 에폭 112 | 반복  10 / 10 | 손실 0.38\n",
            "| 에폭 113 | 반복  10 / 10 | 손실 0.36\n",
            "| 에폭 114 | 반복  10 / 10 | 손실 0.37\n",
            "| 에폭 115 | 반복  10 / 10 | 손실 0.35\n",
            "| 에폭 116 | 반복  10 / 10 | 손실 0.34\n",
            "| 에폭 117 | 반복  10 / 10 | 손실 0.34\n",
            "| 에폭 118 | 반복  10 / 10 | 손실 0.34\n",
            "| 에폭 119 | 반복  10 / 10 | 손실 0.33\n",
            "| 에폭 120 | 반복  10 / 10 | 손실 0.34\n",
            "| 에폭 121 | 반복  10 / 10 | 손실 0.32\n",
            "| 에폭 122 | 반복  10 / 10 | 손실 0.32\n",
            "| 에폭 123 | 반복  10 / 10 | 손실 0.31\n",
            "| 에폭 124 | 반복  10 / 10 | 손실 0.31\n",
            "| 에폭 125 | 반복  10 / 10 | 손실 0.30\n",
            "| 에폭 126 | 반복  10 / 10 | 손실 0.30\n",
            "| 에폭 127 | 반복  10 / 10 | 손실 0.28\n",
            "| 에폭 128 | 반복  10 / 10 | 손실 0.28\n",
            "| 에폭 129 | 반복  10 / 10 | 손실 0.28\n",
            "| 에폭 130 | 반복  10 / 10 | 손실 0.28\n",
            "| 에폭 131 | 반복  10 / 10 | 손실 0.27\n",
            "| 에폭 132 | 반복  10 / 10 | 손실 0.27\n",
            "| 에폭 133 | 반복  10 / 10 | 손실 0.27\n",
            "| 에폭 134 | 반복  10 / 10 | 손실 0.27\n",
            "| 에폭 135 | 반복  10 / 10 | 손실 0.27\n",
            "| 에폭 136 | 반복  10 / 10 | 손실 0.26\n",
            "| 에폭 137 | 반복  10 / 10 | 손실 0.26\n",
            "| 에폭 138 | 반복  10 / 10 | 손실 0.26\n",
            "| 에폭 139 | 반복  10 / 10 | 손실 0.25\n",
            "| 에폭 140 | 반복  10 / 10 | 손실 0.24\n",
            "| 에폭 141 | 반복  10 / 10 | 손실 0.24\n",
            "| 에폭 142 | 반복  10 / 10 | 손실 0.25\n",
            "| 에폭 143 | 반복  10 / 10 | 손실 0.24\n",
            "| 에폭 144 | 반복  10 / 10 | 손실 0.24\n",
            "| 에폭 145 | 반복  10 / 10 | 손실 0.23\n",
            "| 에폭 146 | 반복  10 / 10 | 손실 0.24\n",
            "| 에폭 147 | 반복  10 / 10 | 손실 0.23\n",
            "| 에폭 148 | 반복  10 / 10 | 손실 0.23\n",
            "| 에폭 149 | 반복  10 / 10 | 손실 0.22\n",
            "| 에폭 150 | 반복  10 / 10 | 손실 0.22\n",
            "| 에폭 151 | 반복  10 / 10 | 손실 0.22\n",
            "| 에폭 152 | 반복  10 / 10 | 손실 0.22\n",
            "| 에폭 153 | 반복  10 / 10 | 손실 0.22\n",
            "| 에폭 154 | 반복  10 / 10 | 손실 0.22\n",
            "| 에폭 155 | 반복  10 / 10 | 손실 0.22\n",
            "| 에폭 156 | 반복  10 / 10 | 손실 0.21\n",
            "| 에폭 157 | 반복  10 / 10 | 손실 0.21\n",
            "| 에폭 158 | 반복  10 / 10 | 손실 0.20\n",
            "| 에폭 159 | 반복  10 / 10 | 손실 0.21\n",
            "| 에폭 160 | 반복  10 / 10 | 손실 0.20\n",
            "| 에폭 161 | 반복  10 / 10 | 손실 0.20\n",
            "| 에폭 162 | 반복  10 / 10 | 손실 0.20\n",
            "| 에폭 163 | 반복  10 / 10 | 손실 0.21\n",
            "| 에폭 164 | 반복  10 / 10 | 손실 0.20\n",
            "| 에폭 165 | 반복  10 / 10 | 손실 0.20\n",
            "| 에폭 166 | 반복  10 / 10 | 손실 0.19\n",
            "| 에폭 167 | 반복  10 / 10 | 손실 0.19\n",
            "| 에폭 168 | 반복  10 / 10 | 손실 0.19\n",
            "| 에폭 169 | 반복  10 / 10 | 손실 0.19\n",
            "| 에폭 170 | 반복  10 / 10 | 손실 0.19\n",
            "| 에폭 171 | 반복  10 / 10 | 손실 0.19\n",
            "| 에폭 172 | 반복  10 / 10 | 손실 0.18\n",
            "| 에폭 173 | 반복  10 / 10 | 손실 0.18\n",
            "| 에폭 174 | 반복  10 / 10 | 손실 0.18\n",
            "| 에폭 175 | 반복  10 / 10 | 손실 0.18\n",
            "| 에폭 176 | 반복  10 / 10 | 손실 0.18\n",
            "| 에폭 177 | 반복  10 / 10 | 손실 0.18\n",
            "| 에폭 178 | 반복  10 / 10 | 손실 0.18\n",
            "| 에폭 179 | 반복  10 / 10 | 손실 0.17\n",
            "| 에폭 180 | 반복  10 / 10 | 손실 0.17\n",
            "| 에폭 181 | 반복  10 / 10 | 손실 0.18\n",
            "| 에폭 182 | 반복  10 / 10 | 손실 0.17\n",
            "| 에폭 183 | 반복  10 / 10 | 손실 0.18\n",
            "| 에폭 184 | 반복  10 / 10 | 손실 0.17\n",
            "| 에폭 185 | 반복  10 / 10 | 손실 0.17\n",
            "| 에폭 186 | 반복  10 / 10 | 손실 0.18\n",
            "| 에폭 187 | 반복  10 / 10 | 손실 0.17\n",
            "| 에폭 188 | 반복  10 / 10 | 손실 0.17\n",
            "| 에폭 189 | 반복  10 / 10 | 손실 0.17\n",
            "| 에폭 190 | 반복  10 / 10 | 손실 0.17\n",
            "| 에폭 191 | 반복  10 / 10 | 손실 0.16\n",
            "| 에폭 192 | 반복  10 / 10 | 손실 0.17\n",
            "| 에폭 193 | 반복  10 / 10 | 손실 0.16\n",
            "| 에폭 194 | 반복  10 / 10 | 손실 0.16\n",
            "| 에폭 195 | 반복  10 / 10 | 손실 0.16\n",
            "| 에폭 196 | 반복  10 / 10 | 손실 0.16\n",
            "| 에폭 197 | 반복  10 / 10 | 손실 0.16\n",
            "| 에폭 198 | 반복  10 / 10 | 손실 0.15\n",
            "| 에폭 199 | 반복  10 / 10 | 손실 0.16\n",
            "| 에폭 200 | 반복  10 / 10 | 손실 0.16\n",
            "| 에폭 201 | 반복  10 / 10 | 손실 0.15\n",
            "| 에폭 202 | 반복  10 / 10 | 손실 0.16\n",
            "| 에폭 203 | 반복  10 / 10 | 손실 0.16\n",
            "| 에폭 204 | 반복  10 / 10 | 손실 0.15\n",
            "| 에폭 205 | 반복  10 / 10 | 손실 0.16\n",
            "| 에폭 206 | 반복  10 / 10 | 손실 0.15\n",
            "| 에폭 207 | 반복  10 / 10 | 손실 0.15\n",
            "| 에폭 208 | 반복  10 / 10 | 손실 0.15\n",
            "| 에폭 209 | 반복  10 / 10 | 손실 0.15\n",
            "| 에폭 210 | 반복  10 / 10 | 손실 0.15\n",
            "| 에폭 211 | 반복  10 / 10 | 손실 0.15\n",
            "| 에폭 212 | 반복  10 / 10 | 손실 0.15\n",
            "| 에폭 213 | 반복  10 / 10 | 손실 0.15\n",
            "| 에폭 214 | 반복  10 / 10 | 손실 0.15\n",
            "| 에폭 215 | 반복  10 / 10 | 손실 0.15\n",
            "| 에폭 216 | 반복  10 / 10 | 손실 0.14\n",
            "| 에폭 217 | 반복  10 / 10 | 손실 0.14\n",
            "| 에폭 218 | 반복  10 / 10 | 손실 0.15\n",
            "| 에폭 219 | 반복  10 / 10 | 손실 0.14\n",
            "| 에폭 220 | 반복  10 / 10 | 손실 0.14\n",
            "| 에폭 221 | 반복  10 / 10 | 손실 0.14\n",
            "| 에폭 222 | 반복  10 / 10 | 손실 0.14\n",
            "| 에폭 223 | 반복  10 / 10 | 손실 0.14\n",
            "| 에폭 224 | 반복  10 / 10 | 손실 0.14\n",
            "| 에폭 225 | 반복  10 / 10 | 손실 0.14\n",
            "| 에폭 226 | 반복  10 / 10 | 손실 0.14\n",
            "| 에폭 227 | 반복  10 / 10 | 손실 0.14\n",
            "| 에폭 228 | 반복  10 / 10 | 손실 0.14\n",
            "| 에폭 229 | 반복  10 / 10 | 손실 0.13\n",
            "| 에폭 230 | 반복  10 / 10 | 손실 0.14\n",
            "| 에폭 231 | 반복  10 / 10 | 손실 0.13\n",
            "| 에폭 232 | 반복  10 / 10 | 손실 0.14\n",
            "| 에폭 233 | 반복  10 / 10 | 손실 0.13\n",
            "| 에폭 234 | 반복  10 / 10 | 손실 0.13\n",
            "| 에폭 235 | 반복  10 / 10 | 손실 0.13\n",
            "| 에폭 236 | 반복  10 / 10 | 손실 0.13\n",
            "| 에폭 237 | 반복  10 / 10 | 손실 0.14\n",
            "| 에폭 238 | 반복  10 / 10 | 손실 0.13\n",
            "| 에폭 239 | 반복  10 / 10 | 손실 0.13\n",
            "| 에폭 240 | 반복  10 / 10 | 손실 0.14\n",
            "| 에폭 241 | 반복  10 / 10 | 손실 0.13\n",
            "| 에폭 242 | 반복  10 / 10 | 손실 0.13\n",
            "| 에폭 243 | 반복  10 / 10 | 손실 0.13\n",
            "| 에폭 244 | 반복  10 / 10 | 손실 0.13\n",
            "| 에폭 245 | 반복  10 / 10 | 손실 0.13\n",
            "| 에폭 246 | 반복  10 / 10 | 손실 0.13\n",
            "| 에폭 247 | 반복  10 / 10 | 손실 0.13\n",
            "| 에폭 248 | 반복  10 / 10 | 손실 0.13\n",
            "| 에폭 249 | 반복  10 / 10 | 손실 0.13\n",
            "| 에폭 250 | 반복  10 / 10 | 손실 0.13\n",
            "| 에폭 251 | 반복  10 / 10 | 손실 0.13\n",
            "| 에폭 252 | 반복  10 / 10 | 손실 0.12\n",
            "| 에폭 253 | 반복  10 / 10 | 손실 0.12\n",
            "| 에폭 254 | 반복  10 / 10 | 손실 0.12\n",
            "| 에폭 255 | 반복  10 / 10 | 손실 0.12\n",
            "| 에폭 256 | 반복  10 / 10 | 손실 0.12\n",
            "| 에폭 257 | 반복  10 / 10 | 손실 0.12\n",
            "| 에폭 258 | 반복  10 / 10 | 손실 0.12\n",
            "| 에폭 259 | 반복  10 / 10 | 손실 0.13\n",
            "| 에폭 260 | 반복  10 / 10 | 손실 0.12\n",
            "| 에폭 261 | 반복  10 / 10 | 손실 0.13\n",
            "| 에폭 262 | 반복  10 / 10 | 손실 0.12\n",
            "| 에폭 263 | 반복  10 / 10 | 손실 0.12\n",
            "| 에폭 264 | 반복  10 / 10 | 손실 0.13\n",
            "| 에폭 265 | 반복  10 / 10 | 손실 0.12\n",
            "| 에폭 266 | 반복  10 / 10 | 손실 0.12\n",
            "| 에폭 267 | 반복  10 / 10 | 손실 0.12\n",
            "| 에폭 268 | 반복  10 / 10 | 손실 0.12\n",
            "| 에폭 269 | 반복  10 / 10 | 손실 0.11\n",
            "| 에폭 270 | 반복  10 / 10 | 손실 0.12\n",
            "| 에폭 271 | 반복  10 / 10 | 손실 0.12\n",
            "| 에폭 272 | 반복  10 / 10 | 손실 0.12\n",
            "| 에폭 273 | 반복  10 / 10 | 손실 0.12\n",
            "| 에폭 274 | 반복  10 / 10 | 손실 0.12\n",
            "| 에폭 275 | 반복  10 / 10 | 손실 0.11\n",
            "| 에폭 276 | 반복  10 / 10 | 손실 0.12\n",
            "| 에폭 277 | 반복  10 / 10 | 손실 0.12\n",
            "| 에폭 278 | 반복  10 / 10 | 손실 0.11\n",
            "| 에폭 279 | 반복  10 / 10 | 손실 0.11\n",
            "| 에폭 280 | 반복  10 / 10 | 손실 0.11\n",
            "| 에폭 281 | 반복  10 / 10 | 손실 0.11\n",
            "| 에폭 282 | 반복  10 / 10 | 손실 0.12\n",
            "| 에폭 283 | 반복  10 / 10 | 손실 0.11\n",
            "| 에폭 284 | 반복  10 / 10 | 손실 0.11\n",
            "| 에폭 285 | 반복  10 / 10 | 손실 0.11\n",
            "| 에폭 286 | 반복  10 / 10 | 손실 0.11\n",
            "| 에폭 287 | 반복  10 / 10 | 손실 0.11\n",
            "| 에폭 288 | 반복  10 / 10 | 손실 0.12\n",
            "| 에폭 289 | 반복  10 / 10 | 손실 0.11\n",
            "| 에폭 290 | 반복  10 / 10 | 손실 0.11\n",
            "| 에폭 291 | 반복  10 / 10 | 손실 0.11\n",
            "| 에폭 292 | 반복  10 / 10 | 손실 0.11\n",
            "| 에폭 293 | 반복  10 / 10 | 손실 0.11\n",
            "| 에폭 294 | 반복  10 / 10 | 손실 0.11\n",
            "| 에폭 295 | 반복  10 / 10 | 손실 0.12\n",
            "| 에폭 296 | 반복  10 / 10 | 손실 0.11\n",
            "| 에폭 297 | 반복  10 / 10 | 손실 0.12\n",
            "| 에폭 298 | 반복  10 / 10 | 손실 0.11\n",
            "| 에폭 299 | 반복  10 / 10 | 손실 0.11\n",
            "| 에폭 300 | 반복  10 / 10 | 손실 0.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_gtvxWBhd5n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f97e5fad-68aa-4a0e-ba97-933ccd647b90"
      },
      "source": [
        "import numpy as np\n",
        "print(np.random.permutation(10))\n",
        "print(np.random.permutation(10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5 1 8 4 9 7 0 2 6 3]\n",
            "[3 4 2 7 8 5 6 0 9 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q62E6LzUHplr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1ae41b70-e8a9-478c-b4c7-888b5f5cb2c2"
      },
      "source": [
        "import numpy as np\n",
        "import sys, os\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append('os.chdir')\n",
        "\n",
        "from common.optimizer import SGD\n",
        "from common.trainer import Trainer\n",
        "from dataset import spiral\n",
        "from ch01.two_layer_net import TwoLayerNet\n",
        "\n",
        "max_epoch = 300\n",
        "batch_size = 30\n",
        "hidden_size = 10\n",
        "learning_rate = 1.0\n",
        "x, t = spiral.load_data()\n",
        "model = TwoLayerNet(input_size=2, hidden_size=hidden_size, output_size=3 )\n",
        "optimizer = SGD(lr=learning_rate)\n",
        "\n",
        "trainer = Trainer(model, optimizer)\n",
        "trainer.fit(x, t, max_epoch, batch_size, eval_interval=10)\n",
        "trainer.plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| 에폭 1 |  반복 1 / 10 | 시간 0[s] | 손실 1.10\n",
            "| 에폭 2 |  반복 1 / 10 | 시간 0[s] | 손실 1.12\n",
            "| 에폭 3 |  반복 1 / 10 | 시간 0[s] | 손실 1.13\n",
            "| 에폭 4 |  반복 1 / 10 | 시간 0[s] | 손실 1.12\n",
            "| 에폭 5 |  반복 1 / 10 | 시간 0[s] | 손실 1.12\n",
            "| 에폭 6 |  반복 1 / 10 | 시간 0[s] | 손실 1.10\n",
            "| 에폭 7 |  반복 1 / 10 | 시간 0[s] | 손실 1.14\n",
            "| 에폭 8 |  반복 1 / 10 | 시간 0[s] | 손실 1.16\n",
            "| 에폭 9 |  반복 1 / 10 | 시간 0[s] | 손실 1.11\n",
            "| 에폭 10 |  반복 1 / 10 | 시간 0[s] | 손실 1.12\n",
            "| 에폭 11 |  반복 1 / 10 | 시간 0[s] | 손실 1.12\n",
            "| 에폭 12 |  반복 1 / 10 | 시간 0[s] | 손실 1.12\n",
            "| 에폭 13 |  반복 1 / 10 | 시간 0[s] | 손실 1.10\n",
            "| 에폭 14 |  반복 1 / 10 | 시간 0[s] | 손실 1.09\n",
            "| 에폭 15 |  반복 1 / 10 | 시간 0[s] | 손실 1.08\n",
            "| 에폭 16 |  반복 1 / 10 | 시간 0[s] | 손실 1.04\n",
            "| 에폭 17 |  반복 1 / 10 | 시간 0[s] | 손실 1.03\n",
            "| 에폭 18 |  반복 1 / 10 | 시간 0[s] | 손실 0.94\n",
            "| 에폭 19 |  반복 1 / 10 | 시간 0[s] | 손실 0.92\n",
            "| 에폭 20 |  반복 1 / 10 | 시간 0[s] | 손실 0.92\n",
            "| 에폭 21 |  반복 1 / 10 | 시간 0[s] | 손실 0.87\n",
            "| 에폭 22 |  반복 1 / 10 | 시간 0[s] | 손실 0.85\n",
            "| 에폭 23 |  반복 1 / 10 | 시간 0[s] | 손실 0.80\n",
            "| 에폭 24 |  반복 1 / 10 | 시간 0[s] | 손실 0.79\n",
            "| 에폭 25 |  반복 1 / 10 | 시간 0[s] | 손실 0.78\n",
            "| 에폭 26 |  반복 1 / 10 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 27 |  반복 1 / 10 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 28 |  반복 1 / 10 | 시간 0[s] | 손실 0.76\n",
            "| 에폭 29 |  반복 1 / 10 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 30 |  반복 1 / 10 | 시간 0[s] | 손실 0.76\n",
            "| 에폭 31 |  반복 1 / 10 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 32 |  반복 1 / 10 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 33 |  반복 1 / 10 | 시간 0[s] | 손실 0.78\n",
            "| 에폭 34 |  반복 1 / 10 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 35 |  반복 1 / 10 | 시간 0[s] | 손실 0.78\n",
            "| 에폭 36 |  반복 1 / 10 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 37 |  반복 1 / 10 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 38 |  반복 1 / 10 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 39 |  반복 1 / 10 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 40 |  반복 1 / 10 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 41 |  반복 1 / 10 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 42 |  반복 1 / 10 | 시간 0[s] | 손실 0.76\n",
            "| 에폭 43 |  반복 1 / 10 | 시간 0[s] | 손실 0.79\n",
            "| 에폭 44 |  반복 1 / 10 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 45 |  반복 1 / 10 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 46 |  반복 1 / 10 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 47 |  반복 1 / 10 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 48 |  반복 1 / 10 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 49 |  반복 1 / 10 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 50 |  반복 1 / 10 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 51 |  반복 1 / 10 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 52 |  반복 1 / 10 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 53 |  반복 1 / 10 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 54 |  반복 1 / 10 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 55 |  반복 1 / 10 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 56 |  반복 1 / 10 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 57 |  반복 1 / 10 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 58 |  반복 1 / 10 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 59 |  반복 1 / 10 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 60 |  반복 1 / 10 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 61 |  반복 1 / 10 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 62 |  반복 1 / 10 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 63 |  반복 1 / 10 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 64 |  반복 1 / 10 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 65 |  반복 1 / 10 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 66 |  반복 1 / 10 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 67 |  반복 1 / 10 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 68 |  반복 1 / 10 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 69 |  반복 1 / 10 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 70 |  반복 1 / 10 | 시간 0[s] | 손실 0.68\n",
            "| 에폭 71 |  반복 1 / 10 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 72 |  반복 1 / 10 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 73 |  반복 1 / 10 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 74 |  반복 1 / 10 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 75 |  반복 1 / 10 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 76 |  반복 1 / 10 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 77 |  반복 1 / 10 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 78 |  반복 1 / 10 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 79 |  반복 1 / 10 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 80 |  반복 1 / 10 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 81 |  반복 1 / 10 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 82 |  반복 1 / 10 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 83 |  반복 1 / 10 | 시간 0[s] | 손실 0.64\n",
            "| 에폭 84 |  반복 1 / 10 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 85 |  반복 1 / 10 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 86 |  반복 1 / 10 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 87 |  반복 1 / 10 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 88 |  반복 1 / 10 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 89 |  반복 1 / 10 | 시간 0[s] | 손실 0.61\n",
            "| 에폭 90 |  반복 1 / 10 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 91 |  반복 1 / 10 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 92 |  반복 1 / 10 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 93 |  반복 1 / 10 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 94 |  반복 1 / 10 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 95 |  반복 1 / 10 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 96 |  반복 1 / 10 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 97 |  반복 1 / 10 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 98 |  반복 1 / 10 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 99 |  반복 1 / 10 | 시간 0[s] | 손실 0.50\n",
            "| 에폭 100 |  반복 1 / 10 | 시간 0[s] | 손실 0.47\n",
            "| 에폭 101 |  반복 1 / 10 | 시간 0[s] | 손실 0.49\n",
            "| 에폭 102 |  반복 1 / 10 | 시간 0[s] | 손실 0.46\n",
            "| 에폭 103 |  반복 1 / 10 | 시간 0[s] | 손실 0.44\n",
            "| 에폭 104 |  반복 1 / 10 | 시간 0[s] | 손실 0.47\n",
            "| 에폭 105 |  반복 1 / 10 | 시간 0[s] | 손실 0.44\n",
            "| 에폭 106 |  반복 1 / 10 | 시간 0[s] | 손실 0.43\n",
            "| 에폭 107 |  반복 1 / 10 | 시간 0[s] | 손실 0.43\n",
            "| 에폭 108 |  반복 1 / 10 | 시간 0[s] | 손실 0.39\n",
            "| 에폭 109 |  반복 1 / 10 | 시간 0[s] | 손실 0.40\n",
            "| 에폭 110 |  반복 1 / 10 | 시간 0[s] | 손실 0.41\n",
            "| 에폭 111 |  반복 1 / 10 | 시간 0[s] | 손실 0.38\n",
            "| 에폭 112 |  반복 1 / 10 | 시간 0[s] | 손실 0.38\n",
            "| 에폭 113 |  반복 1 / 10 | 시간 0[s] | 손실 0.38\n",
            "| 에폭 114 |  반복 1 / 10 | 시간 0[s] | 손실 0.37\n",
            "| 에폭 115 |  반복 1 / 10 | 시간 0[s] | 손실 0.36\n",
            "| 에폭 116 |  반복 1 / 10 | 시간 0[s] | 손실 0.34\n",
            "| 에폭 117 |  반복 1 / 10 | 시간 0[s] | 손실 0.35\n",
            "| 에폭 118 |  반복 1 / 10 | 시간 0[s] | 손실 0.33\n",
            "| 에폭 119 |  반복 1 / 10 | 시간 0[s] | 손실 0.35\n",
            "| 에폭 120 |  반복 1 / 10 | 시간 0[s] | 손실 0.33\n",
            "| 에폭 121 |  반복 1 / 10 | 시간 0[s] | 손실 0.33\n",
            "| 에폭 122 |  반복 1 / 10 | 시간 0[s] | 손실 0.32\n",
            "| 에폭 123 |  반복 1 / 10 | 시간 0[s] | 손실 0.31\n",
            "| 에폭 124 |  반복 1 / 10 | 시간 0[s] | 손실 0.31\n",
            "| 에폭 125 |  반복 1 / 10 | 시간 0[s] | 손실 0.31\n",
            "| 에폭 126 |  반복 1 / 10 | 시간 0[s] | 손실 0.30\n",
            "| 에폭 127 |  반복 1 / 10 | 시간 0[s] | 손실 0.30\n",
            "| 에폭 128 |  반복 1 / 10 | 시간 0[s] | 손실 0.27\n",
            "| 에폭 129 |  반복 1 / 10 | 시간 0[s] | 손실 0.30\n",
            "| 에폭 130 |  반복 1 / 10 | 시간 0[s] | 손실 0.28\n",
            "| 에폭 131 |  반복 1 / 10 | 시간 0[s] | 손실 0.26\n",
            "| 에폭 132 |  반복 1 / 10 | 시간 0[s] | 손실 0.27\n",
            "| 에폭 133 |  반복 1 / 10 | 시간 0[s] | 손실 0.27\n",
            "| 에폭 134 |  반복 1 / 10 | 시간 0[s] | 손실 0.28\n",
            "| 에폭 135 |  반복 1 / 10 | 시간 0[s] | 손실 0.26\n",
            "| 에폭 136 |  반복 1 / 10 | 시간 0[s] | 손실 0.28\n",
            "| 에폭 137 |  반복 1 / 10 | 시간 0[s] | 손실 0.25\n",
            "| 에폭 138 |  반복 1 / 10 | 시간 0[s] | 손실 0.26\n",
            "| 에폭 139 |  반복 1 / 10 | 시간 0[s] | 손실 0.26\n",
            "| 에폭 140 |  반복 1 / 10 | 시간 0[s] | 손실 0.26\n",
            "| 에폭 141 |  반복 1 / 10 | 시간 0[s] | 손실 0.23\n",
            "| 에폭 142 |  반복 1 / 10 | 시간 0[s] | 손실 0.23\n",
            "| 에폭 143 |  반복 1 / 10 | 시간 0[s] | 손실 0.26\n",
            "| 에폭 144 |  반복 1 / 10 | 시간 0[s] | 손실 0.23\n",
            "| 에폭 145 |  반복 1 / 10 | 시간 0[s] | 손실 0.24\n",
            "| 에폭 146 |  반복 1 / 10 | 시간 0[s] | 손실 0.24\n",
            "| 에폭 147 |  반복 1 / 10 | 시간 0[s] | 손실 0.25\n",
            "| 에폭 148 |  반복 1 / 10 | 시간 0[s] | 손실 0.21\n",
            "| 에폭 149 |  반복 1 / 10 | 시간 0[s] | 손실 0.23\n",
            "| 에폭 150 |  반복 1 / 10 | 시간 0[s] | 손실 0.22\n",
            "| 에폭 151 |  반복 1 / 10 | 시간 0[s] | 손실 0.22\n",
            "| 에폭 152 |  반복 1 / 10 | 시간 0[s] | 손실 0.23\n",
            "| 에폭 153 |  반복 1 / 10 | 시간 0[s] | 손실 0.23\n",
            "| 에폭 154 |  반복 1 / 10 | 시간 0[s] | 손실 0.20\n",
            "| 에폭 155 |  반복 1 / 10 | 시간 0[s] | 손실 0.22\n",
            "| 에폭 156 |  반복 1 / 10 | 시간 0[s] | 손실 0.21\n",
            "| 에폭 157 |  반복 1 / 10 | 시간 0[s] | 손실 0.21\n",
            "| 에폭 158 |  반복 1 / 10 | 시간 0[s] | 손실 0.20\n",
            "| 에폭 159 |  반복 1 / 10 | 시간 0[s] | 손실 0.21\n",
            "| 에폭 160 |  반복 1 / 10 | 시간 0[s] | 손실 0.20\n",
            "| 에폭 161 |  반복 1 / 10 | 시간 0[s] | 손실 0.19\n",
            "| 에폭 162 |  반복 1 / 10 | 시간 0[s] | 손실 0.22\n",
            "| 에폭 163 |  반복 1 / 10 | 시간 0[s] | 손실 0.19\n",
            "| 에폭 164 |  반복 1 / 10 | 시간 0[s] | 손실 0.21\n",
            "| 에폭 165 |  반복 1 / 10 | 시간 0[s] | 손실 0.20\n",
            "| 에폭 166 |  반복 1 / 10 | 시간 0[s] | 손실 0.20\n",
            "| 에폭 167 |  반복 1 / 10 | 시간 0[s] | 손실 0.20\n",
            "| 에폭 168 |  반복 1 / 10 | 시간 0[s] | 손실 0.19\n",
            "| 에폭 169 |  반복 1 / 10 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 170 |  반복 1 / 10 | 시간 0[s] | 손실 0.19\n",
            "| 에폭 171 |  반복 1 / 10 | 시간 0[s] | 손실 0.19\n",
            "| 에폭 172 |  반복 1 / 10 | 시간 0[s] | 손실 0.20\n",
            "| 에폭 173 |  반복 1 / 10 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 174 |  반복 1 / 10 | 시간 0[s] | 손실 0.20\n",
            "| 에폭 175 |  반복 1 / 10 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 176 |  반복 1 / 10 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 177 |  반복 1 / 10 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 178 |  반복 1 / 10 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 179 |  반복 1 / 10 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 180 |  반복 1 / 10 | 시간 0[s] | 손실 0.19\n",
            "| 에폭 181 |  반복 1 / 10 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 182 |  반복 1 / 10 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 183 |  반복 1 / 10 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 184 |  반복 1 / 10 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 185 |  반복 1 / 10 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 186 |  반복 1 / 10 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 187 |  반복 1 / 10 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 188 |  반복 1 / 10 | 시간 0[s] | 손실 0.18\n",
            "| 에폭 189 |  반복 1 / 10 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 190 |  반복 1 / 10 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 191 |  반복 1 / 10 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 192 |  반복 1 / 10 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 193 |  반복 1 / 10 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 194 |  반복 1 / 10 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 195 |  반복 1 / 10 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 196 |  반복 1 / 10 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 197 |  반복 1 / 10 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 198 |  반복 1 / 10 | 시간 0[s] | 손실 0.17\n",
            "| 에폭 199 |  반복 1 / 10 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 200 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 201 |  반복 1 / 10 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 202 |  반복 1 / 10 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 203 |  반복 1 / 10 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 204 |  반복 1 / 10 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 205 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 206 |  반복 1 / 10 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 207 |  반복 1 / 10 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 208 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 209 |  반복 1 / 10 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 210 |  반복 1 / 10 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 211 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 212 |  반복 1 / 10 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 213 |  반복 1 / 10 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 214 |  반복 1 / 10 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 215 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 216 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 217 |  반복 1 / 10 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 218 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 219 |  반복 1 / 10 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 220 |  반복 1 / 10 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 221 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 222 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 223 |  반복 1 / 10 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 224 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 225 |  반복 1 / 10 | 시간 0[s] | 손실 0.16\n",
            "| 에폭 226 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 227 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 228 |  반복 1 / 10 | 시간 0[s] | 손실 0.15\n",
            "| 에폭 229 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 230 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 231 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 232 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 233 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 234 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 235 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 236 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 237 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 238 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 239 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 240 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 241 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 242 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 243 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 244 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 245 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 246 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 247 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 248 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 249 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 250 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 251 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 252 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 253 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 254 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 255 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 256 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 257 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 258 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 259 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 260 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 261 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 262 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 263 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 264 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 265 |  반복 1 / 10 | 시간 0[s] | 손실 0.14\n",
            "| 에폭 266 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 267 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 268 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 269 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 270 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 271 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 272 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 273 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 274 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 275 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 276 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 277 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 278 |  반복 1 / 10 | 시간 0[s] | 손실 0.13\n",
            "| 에폭 279 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 280 |  반복 1 / 10 | 시간 0[s] | 손실 0.10\n",
            "| 에폭 281 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 282 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 283 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 284 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 285 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 286 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 287 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 288 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 289 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 290 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 291 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 292 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 293 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 294 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 295 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 296 |  반복 1 / 10 | 시간 0[s] | 손실 0.12\n",
            "| 에폭 297 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 298 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 299 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n",
            "| 에폭 300 |  반복 1 / 10 | 시간 0[s] | 손실 0.11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48152 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48373 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49552 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49892 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48152 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48373 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49552 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49892 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15caD2PVHscl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "484ab2f2-57ac-4739-b77c-cea635cd8da2"
      },
      "source": [
        "b = np.random.randn(3).astype(np.float32)\n",
        "print(b.dtype)\n",
        "\n",
        "c = np.random.randn(3).astype('f')\n",
        "print(c.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "float32\n",
            "float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8crf8bAHyDh"
      },
      "source": [
        "#2장"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtI3zznKw4tC"
      },
      "source": [
        "##2.3.1 파이썬으로 말뭉치로 전처리하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Os6T7rI9HvFu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "8ee97209-97cd-4b67-e032-3430f0cf8c05"
      },
      "source": [
        "text = 'You say goodbye and I say hello.' \n",
        "text = text.lower()   # 문장을 소문자로\n",
        "text = text.replace('.', ' .')    #두번째는 문자 점을 표현하고 싶어서 띄우고 점을 입력\n",
        "print(text)\n",
        "\n",
        "words = text.split(' ')\n",
        "print(words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "you say goodbye and i say hello .\n",
            "['you', 'say', 'goodbye', 'and', 'i', 'say', 'hello', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbrniu4fH1mV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "51039a5a-5ac5-4ce2-b3de-87cea826f6c5"
      },
      "source": [
        "word_to_id = {}\n",
        "id_to_word = {}\n",
        "\n",
        "for word in words:\n",
        "  if word not in word_to_id:\n",
        "    new_id = len(word_to_id)\n",
        "    word_to_id[word] = new_id\n",
        "    id_to_word[new_id] = word\n",
        "\n",
        "\n",
        "print(id_to_word)\n",
        "print(word_to_id)\n",
        "\n",
        "print(id_to_word[1])\n",
        "print(word_to_id['hello'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n",
            "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}\n",
            "say\n",
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jd04jkH-H3WV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1fa748b4-54c3-4e10-ee43-a90bde17906f"
      },
      "source": [
        "import numpy as np\n",
        "corpus = [word_to_id[w] for w in words]\n",
        "corpus = np.array(corpus)\n",
        "print(corpus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 1 5 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKk_6LR2xNns"
      },
      "source": [
        "##2.3.4 동시발생 행렬"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvyraHQyH5bl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "e32ae9ec-488c-40a1-c5e6-6a78c4db490e"
      },
      "source": [
        "import sys, os\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append('os.chdir')\n",
        "\n",
        "from common.util import  preprocess\n",
        "\n",
        "text = 'You say goodbye and I say hello.' \n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "print(corpus)   # corpus는 단어 id 목록\n",
        "# [0 1 2 3 4 1 5 6]\n",
        "\n",
        "print(id_to_word)\n",
        "# {0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 1 5 6]\n",
            "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A43cr5HJH7Ie",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "ab80c53d-5535-498c-dccc-9decde78f75a"
      },
      "source": [
        "def create_co_matrix(corpus, vocab_size, window_size=1):\n",
        "  corpus_size = len(corpus)\n",
        "  co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
        "\n",
        "  for idx, word_id in enumerate(corpus):     #idx 는 [0 1 2 3 4 5 6 7] /  word_id 는 [0 1 2 3 4 1 5 6]\n",
        "    for i in range(1, window_size +1):\n",
        "      left_idx = idx - i\n",
        "      right_idx = idx + i\n",
        "\n",
        "      #왼쪽 끝과 오른쪽 끝을 안 벗어 날때만 1을 추가해준다\n",
        "      # say일 경우에 한 행에서 두번 계산 된다\n",
        "\n",
        "      if left_idx >= 0:\n",
        "        left_word_id = corpus[left_idx]\n",
        "        co_matrix[word_id, left_word_id] += 1\n",
        "\n",
        "      if right_idx < corpus_size:\n",
        "        right_word_id = corpus[right_idx]\n",
        "        co_matrix[word_id, right_word_id] += 1\n",
        "\n",
        "  return co_matrix\n",
        "\n",
        "\n",
        "\n",
        "text = 'You say goodbye and I say hello.' \n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "print(create_co_matrix(corpus, 7))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 1 0 0 0 0 0]\n",
            " [1 0 1 0 1 1 0]\n",
            " [0 1 0 1 0 0 0]\n",
            " [0 0 1 0 1 0 0]\n",
            " [0 1 0 1 0 0 0]\n",
            " [0 1 0 0 0 0 1]\n",
            " [0 0 0 0 0 1 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IBA055cxXX7"
      },
      "source": [
        "##2.3.5 벡터 간 유사도"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cI_ZfQj9H8ze"
      },
      "source": [
        "def cos_similarity(x, y):\n",
        "  nx = x / np.sqrt(np.sum(x**2))   #x의 정규화\n",
        "  ny = y / np.sqrt(np.sum(y**2))   #y의 정규화\n",
        "  return np.dot(nx, ny)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbeP2ObxH-hn"
      },
      "source": [
        "def cos_similarity(x, y):\n",
        "  nx = x / np.sqrt(np.sum(x**2))   #x의 정규화\n",
        "  ny = y / np.sqrt(np.sum(y**2))   #y의 정규화\n",
        "  return np.dot(nx, ny)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUe50f2kIAI-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "709b708d-9b02-4f35-8c02-4c26f63a531c"
      },
      "source": [
        "import sys, os\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/common\")\n",
        "sys.path.append('os.chdir')\n",
        "\n",
        "from util import preprocess, create_co_matrix, cos_similarity\n",
        "\n",
        "text = 'You say goodbye and I say helllo.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "vocab_size = len(word_to_id)\n",
        "C = create_co_matrix(corpus, vocab_size)\n",
        "\n",
        "c0 = C[word_to_id['you']] #you의 단어 벡터  행으로 뽑는다\n",
        "c1 = C[word_to_id['i']]   #i의 단어 벡터    행으로 뽑는다\n",
        "\n",
        "print(cos_similarity(c0, c1))   #0.7071067691154799"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7071067691154799\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQPZnJrPyQWY"
      },
      "source": [
        "##2.3.6 유사 단어의 랭킹 표시"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LhiEmEIIB_d"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def most_similar(query, word_to_id, id_to_word, word_matrix,top=5):\n",
        "\n",
        "  # 1 검색어를 꺼낸다\n",
        "  if query not in word_to_id:\n",
        "    print('%s(을)를 찾을 수없습니다.' %query)\n",
        "    return\n",
        "\n",
        "  print('\\n[query] ' + query)\n",
        "  query_id = word_to_id[query]\n",
        "  query_vec = word_matrix[query_id]\n",
        "\n",
        "  # 2 코사인 유사도 계산\n",
        "  vocab_size = len(id_to_word)\n",
        "  similarity = np.zeros(vocab_size)\n",
        "  for i in range(vocab_size):\n",
        "    similarity[i] = cos_similarity(word_matrix[i], query_vec)\n",
        "\n",
        "  # 3 코사인 유사도를 기준으로 내림차순으로 출력\n",
        "  count = 0\n",
        "  for i in (-1 * similarity).argsort():\n",
        "    if id_to_word[i] == query:      #같으면 출력할 필요 없으니까 continue를 사용 \n",
        "      continue\n",
        "    \n",
        "    print(' %s: %s' % (id_to_word[i], similarity[i]))\n",
        "    count += 1\n",
        "    \n",
        "    if count >= top:\n",
        "      return\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGSN5YJp3JFD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "e451e225-a35c-4f71-c935-e70ff5983595"
      },
      "source": [
        "import sys, os\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/common\")\n",
        "sys.path.append('os.chdir')\n",
        "\n",
        "import numpy as np\n",
        "from util import preprocess, create_co_matrix, cos_similarity\n",
        "\n",
        "text = 'You say goodbye and I say helllo.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "vocab_size = len(word_to_id)\n",
        "C = create_co_matrix(corpus, vocab_size)\n",
        "\n",
        "print(most_similar('you', word_to_id, id_to_word, C,top=5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[query] you\n",
            " goodbye: 0.7071067691154799\n",
            " i: 0.7071067691154799\n",
            " helllo: 0.7071067691154799\n",
            " say: 0.0\n",
            " and: 0.0\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aI9xXZFEUl8g"
      },
      "source": [
        "##2.4.1 상호 정보량"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCXk07yxUawa"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def ppmi(C, verbose=False, eps=1e-8):\n",
        "  M = np.zeros_like(C, dtype=np.float32)\n",
        "  N = np.sum(C)\n",
        "  S = np.sum(C, axis=0)   #행을 기준으로 더함\n",
        "  total = C.shapep[0] * C.shape[1]\n",
        "  cnt = 0\n",
        "\n",
        "  for i in randge(C.shape[0]):\n",
        "    for j in range(C.shape[1]):\n",
        "      pmi = np.log2(C[i, j] * N / (S[j] * S[i]) + eps)\n",
        "      M[i, j] = max(0, pmi)\n",
        "\n",
        "      if verbose:\n",
        "        cnt += 1\n",
        "        if cnt % (total//100) == 0:\n",
        "          print('%.1f%% 완료' % (100*cnt/total))\n",
        "\n",
        "  return M"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6iI_UkiV6ek",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "88e466c4-1857-4b53-c4dc-759ed374d352"
      },
      "source": [
        "import sys,os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append('os.chdir')\n",
        "\n",
        "import numpy as np\n",
        "from common.util import preprocess, create_co_matrix, cos_similarity, ppmi\n",
        "\n",
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "vocab_size = len(word_to_id)\n",
        "C = create_co_matrix(corpus, vocab_size)\n",
        "W = ppmi(C)\n",
        "\n",
        "np.set_printoptions(precision=3)  #유효 자릿수를 세 자리로 표시\n",
        "print('동시발행 행렬')\n",
        "print(C)\n",
        "print('-'*50)\n",
        "print('PPMI')\n",
        "print(W)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "동시발행 행렬\n",
            "[[0 1 0 0 0 0 0]\n",
            " [1 0 1 0 1 1 0]\n",
            " [0 1 0 1 0 0 0]\n",
            " [0 0 1 0 1 0 0]\n",
            " [0 1 0 1 0 0 0]\n",
            " [0 1 0 0 0 0 1]\n",
            " [0 0 0 0 0 1 0]]\n",
            "--------------------------------------------------\n",
            "PPMI\n",
            "[[0.    1.807 0.    0.    0.    0.    0.   ]\n",
            " [1.807 0.    0.807 0.    0.807 0.807 0.   ]\n",
            " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
            " [0.    0.    1.807 0.    1.807 0.    0.   ]\n",
            " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
            " [0.    0.807 0.    0.    0.    0.    2.807]\n",
            " [0.    0.    0.    0.    0.    2.807 0.   ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_Z-sd_6bxXV"
      },
      "source": [
        "##2.4.3 SVD에 의한 차원 감소"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2htDEXCkboEm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "3f937a1a-e1ff-42f2-c7aa-4b240655c4c6"
      },
      "source": [
        "import sys,os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append('os.chdir')\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from common.util import preprocess, create_co_matrix, ppmi\n",
        "\n",
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "vocab_size = len(word_to_id)\n",
        "C = create_co_matrix(corpus, vocab_size, window_size=1)\n",
        "W = ppmi(C)\n",
        "\n",
        "# SVD\n",
        "U, S, V = np.linalg.svd(W)\n",
        "\n",
        "print(C[0])   # 동시발생 행렬\n",
        "              # [0 1 0 0 0 0 0]\n",
        "\n",
        "print(W[0])   # PPMI 행렬\n",
        "              # [0.    1.807 0.    0.    0.    0.    0.   ]\n",
        "            \n",
        "print(U[0])   # SVD\n",
        "              # [ 3.409e-01  0.000e+00 -1.205e-01 -3.886e-16 -9.323e-01 -1.110e-16 -2.426e-17]\n",
        "\n",
        "# U의 차원을 만약 2차원 벡터로 줄이려면 처음 두 원소를 꺼냄\n",
        "\n",
        "print(U[0, :2]) # [0.341 0.   ]\n",
        "\n",
        "for word, word_id in word_to_id.items():\n",
        "  plt.annotate(word, (U[word_id, 0], U[word_id, 1]))\n",
        "\n",
        "plt.scatter(U[:,0], U[:,1], alpha=0.5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 0 0 0 0]\n",
            "[0.    1.807 0.    0.    0.    0.    0.   ]\n",
            "[ 3.409e-01  0.000e+00 -1.205e-01 -3.886e-16 -9.323e-01 -1.110e-16\n",
            " -2.426e-17]\n",
            "[0.341 0.   ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeF0Kod-fDzg"
      },
      "source": [
        "##2.4.4 PTB 데이터셋"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Njq3BHrcdO8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "dee8d3b4-71e4-49c2-eaf4-1e9e670911a8"
      },
      "source": [
        "import sys,os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append('os.chdir')\n",
        "\n",
        "from dataset import ptb\n",
        "\n",
        "corpus, word_to_id, id_to_word = ptb.load_data('train')   # 데이터를 읽어 들임 \n",
        "                                                          # train 훈련용\n",
        "                                                          # test 테스트용\n",
        "                                                          # valid 검증용\n",
        "\n",
        "print('말뭉치 크기 : ', len(corpus))\n",
        "print('corpus[:30]:', corpus[:30])\n",
        "print()\n",
        "print('id_to_word[0] :', id_to_word[0])\n",
        "print('id_to_word[1] :', id_to_word[1])\n",
        "print('id_to_word[2] :', id_to_word[2])\n",
        "print()\n",
        "print(\"word_to_id['car'] : \", word_to_id['car'])\n",
        "print(\"word_to_id['happy'] : \", word_to_id['happy'])\n",
        "print(\"word_to_id['lexus'] : \", word_to_id['lexus'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "말뭉치 크기 :  929589\n",
            "corpus[:30]: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29]\n",
            "\n",
            "id_to_word[0] : aer\n",
            "id_to_word[1] : banknote\n",
            "id_to_word[2] : berlitz\n",
            "\n",
            "word_to_id['car'] :  3856\n",
            "word_to_id['happy'] :  4428\n",
            "word_to_id['lexus'] :  7426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbEEysMpgvKv"
      },
      "source": [
        "##2.4.5 PTB 데이터셋 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-UszhweeFhF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "584dcd16-16ba-479f-af91-88e9fcd52202"
      },
      "source": [
        "import sys,os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append('os.chdir')\n",
        "\n",
        "import numpy as np\n",
        "from common.util import most_similar, create_co_matrix, ppmi\n",
        "from dataset import ptb\n",
        "\n",
        "window_size = 2\n",
        "wordvec_size = 100\n",
        "\n",
        "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
        "vocab_size = len(word_to_id)\n",
        "print('동시발생 수 계산 ...')\n",
        "C = create_co_matrix(corpus, vocab_size, window_size)\n",
        "print('PPMI 계산 ...')\n",
        "W = ppmi(C, verbose=True)\n",
        "\n",
        "print('SVD 계산 ...')\n",
        "try:\n",
        "  #truncated SVD (빠르다!)\n",
        "  from sklenarn.utils.extmath import randomized_svd\n",
        "  U, S, V = randomized_svd(W, n_components=wordvec_size, n_iter=5, random_state=None)\n",
        "\n",
        "except ImportError:\n",
        "  # SVD (느리다)\n",
        "  U, S, V = np.linalg.svd(W)\n",
        "\n",
        "word_vecs = U[:, :wordvec_size]\n",
        "\n",
        "querys = ['you', 'year', 'car', 'toyota']\n",
        "for query in querys:\n",
        "  most_similar(query, word_to_id, id_to_word, word_vecs, top=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "동시발생 수 계산 ...\n",
            "PPMI 계산 ...\n",
            "1.0% 완료\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-1bf68d8a8bf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_co_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PPMI 계산 ...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mppmi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SVD 계산 ...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/common/util.py\u001b[0m in \u001b[0;36mppmi\u001b[0;34m(C, verbose, eps)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mpmi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpmi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCyrPwSowyKt"
      },
      "source": [
        "#3장"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMD5rcct0T28"
      },
      "source": [
        "##3.1.3 신경망에서의 단어 처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNV1jUlti8F0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c78e7e98-4c94-4030-b719-7639050f9391"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "c = np.array([[1, 0, 0, 0, 0, 0, 0]])   #입력\n",
        "W = np.random.randn(7, 3)               #가중치\n",
        "h = np.matmul(c, W)                     #중간 노드\n",
        "print(h)                                #[[-1.7250735   0.28164515  0.17008804]]\n",
        "\n",
        "# c가 첫번째 원소만 1 이라서 곱할때 W의 첫번째 행벡터만 가지고 온다\n",
        "#이건 불필요한 계산이다 나중에 다른 방법으로 수정"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.588  0.423 -0.245]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3pW1yG00zwe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "26728dc4-aa76-4341-e818-6205cae26e9c"
      },
      "source": [
        "import sys,os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append('os.chdir')\n",
        "from common.layers import MatMul\n",
        "\n",
        "\n",
        "c = np.array([[1, 0, 0, 0, 0, 0, 0]])   \n",
        "W = np.random.randn(7, 3)\n",
        "layer = MatMul(W)               \n",
        "h = layer.forward(c)       \n",
        "print(h)              #[[ 0.52330489  2.10803087 -0.73193039]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-1.382 -0.07   0.911]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg5L0Lsn8Pki"
      },
      "source": [
        "##3.2.1 CBOW 모델의 추론 처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhiOtGmF1c71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "5da8c657-4c45-4aef-a7e7-edbca547ced1"
      },
      "source": [
        "import sys,os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append('os.chdir')\n",
        "from common.layers import MatMul\n",
        "import numpy as np\n",
        "    \n",
        "# 샘플 맥락 데이터\n",
        "c0 = np.array([[1, 0, 0, 0, 0, 0, 0]])\n",
        "c1 = np.array([[0, 0, 1, 0, 0, 0, 0]])\n",
        "\n",
        "# 가중치 초기화\n",
        "W_in = np.random.randn(7, 3)\n",
        "W_out = np.random.randn(3, 7)\n",
        "\n",
        "# 계층 생성\n",
        "in_layer0 = MatMul(W_in)\n",
        "in_layer1 = MatMul(W_in)\n",
        "out_layer = MatMul(W_out)\n",
        "\n",
        "# 순전파\n",
        "h0 = in_layer0.forward(c0)\n",
        "h1 = in_layer1.forward(c1)\n",
        "h = 0.5 * (h0 + h1)\n",
        "s = out_layer.forward(h)\n",
        "\n",
        "print(h0)\n",
        "print(s)\n",
        "#[[-0.8467628  -0.96041423  0.27781406  1.00420635 -0.86524163 -0.7114661 -0.26299879]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.494  0.751  0.73 ]]\n",
            "[[-0.054  0.573 -0.26   0.013  0.235  0.186  0.22 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBlRf-xAgXG7"
      },
      "source": [
        "##3.3.1 맥락과 타깃"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZsikZn9-oFV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "c17f6303-27fc-40b6-e0d2-cc5db870ae33"
      },
      "source": [
        "import sys,os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append('os.chdir')\n",
        "\n",
        "from common.util import preprocess\n",
        "\n",
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "print(corpus)\n",
        "\n",
        "print(id_to_word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 1 5 6]\n",
            "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZFfC6weg-nH"
      },
      "source": [
        "def create_contexts_target(corpus, window_size=1):\n",
        "  target = corpus[window_size:-window_size]\n",
        "  contexts = []\n",
        "\n",
        "  for idx in range(window_size, len(corpus) - window_size):\n",
        "    cs = []\n",
        "    for t in range(-window_size, window_size + 1):\n",
        "      if t == 0:\n",
        "        continue\n",
        "      cs.append(corpus[idx + t])\n",
        "    contexts.append(cs)\n",
        "\n",
        "  return np.array(contexts), np.array(target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCUImTMUiaSr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "f91f31d0-7e0e-414c-caf4-97181d309e05"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "contexts, target = create_contexts_target(corpus, window_size=1)\n",
        "\n",
        "print(contexts)\n",
        "# [[0 2]\n",
        "# [1 3]\n",
        "# [2 4]\n",
        "# [3 1]\n",
        "# [4 5]\n",
        "# [1 6]]\n",
        "\n",
        "print(target)\n",
        "# [1 2 3 4 1 5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 2]\n",
            " [1 3]\n",
            " [2 4]\n",
            " [3 1]\n",
            " [4 5]\n",
            " [1 6]]\n",
            "[1 2 3 4 1 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08AgWAjco_a3"
      },
      "source": [
        "##3.3.2 원핫 표현으로 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qW23j0PwldX2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "d27cf0cf-d70d-4080-d6fa-53170d6a68b9"
      },
      "source": [
        "import sys,os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append('os.chdir')\n",
        "\n",
        "from common.util import preprocess, create_contexts_target, convert_one_hot\n",
        "\n",
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "\n",
        "contexts, target = create_contexts_target(corpus, window_size=1)\n",
        "\n",
        "vocab_size = len(word_to_id)\n",
        "target = convert_one_hot(target, vocab_size)\n",
        "contexts = convert_one_hot(contexts, vocab_size)\n",
        "\n",
        "print(target)\n",
        "print(contexts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 1 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0]\n",
            " [0 0 0 1 0 0 0]\n",
            " [0 0 0 0 1 0 0]\n",
            " [0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0]]\n",
            "[[[1 0 0 0 0 0 0]\n",
            "  [0 0 1 0 0 0 0]]\n",
            "\n",
            " [[0 1 0 0 0 0 0]\n",
            "  [0 0 0 1 0 0 0]]\n",
            "\n",
            " [[0 0 1 0 0 0 0]\n",
            "  [0 0 0 0 1 0 0]]\n",
            "\n",
            " [[0 0 0 1 0 0 0]\n",
            "  [0 1 0 0 0 0 0]]\n",
            "\n",
            " [[0 0 0 0 1 0 0]\n",
            "  [0 0 0 0 0 1 0]]\n",
            "\n",
            " [[0 1 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 1]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkBTXo6upFhQ"
      },
      "source": [
        "##3.4 CBOW 모델 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn-lkSzqobWr"
      },
      "source": [
        "import sys,os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append('os.chdir')\n",
        "\n",
        "from common.layers import MatMul, SoftmaxWithLoss\n",
        "\n",
        "class SimpleCBOW:\n",
        "  def __init__(self, vocab_size, hidden_size):\n",
        "    V, H = vocab_size, hidden_size\n",
        "\n",
        "    #가중치 초기화\n",
        "    W_in = 0.01 * np.random.randn(V, H).astype('f')\n",
        "    W_out = 0.01 * np.random.randn(H, V).astype('f')\n",
        "\n",
        "    #계층 생성\n",
        "    self.in_layer0 = MatMul(W_in)\n",
        "    self.in_layer1 = MatMul(W_in)\n",
        "    self.out_layer = MatMul(W_out)\n",
        "    self.loss_layer = SoftmaxWithLoss()\n",
        "\n",
        "    # 모든 가중치와 기울기를 리스트에 모은다.\n",
        "    layers = [self.in_layer0, self.in_layer1, self.out_layer]\n",
        "    self.params, self.grads = [], []\n",
        "    \n",
        "    for layer in layers:\n",
        "      self.params += layer.params\n",
        "      self.grads += layer.grads\n",
        "\n",
        "      # 인스턴스 변수에 단어의 분산 표현을 저장한다.\n",
        "      self.word_vecs = W_in\n",
        "\n",
        "  def forward(self,contexts, target):\n",
        "    h0 = self.in_layer0.forward(contexts[:, 0])\n",
        "    h1 = self.in_layer1.forward(contexts[:, 1])\n",
        "    h = (h0 + h1) * 0.5\n",
        "    score = self.out_layer.foward(h)\n",
        "    loss = self.loss_layer.forward(score, target)\n",
        "    return loss \n",
        "\n",
        "  def backward(self, dout=1):\n",
        "    ds = self.loss_layer.backward(dout)\n",
        "    da = self.out_layer.backward(ds)\n",
        "    da *= 0.5\n",
        "    self.in_layer1.backward(da)\n",
        "    self.in_layer0.backward(da)\n",
        "    return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUZw8ZXry3Z3"
      },
      "source": [
        "##3.4.1 학습 코드 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLcbotpVrP0F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5b4489e6-8804-44eb-d518-1646ce718818"
      },
      "source": [
        "import sys,os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append('os.chdir')\n",
        "\n",
        "from common.trainer import Trainer\n",
        "from common.optimizer import Adam\n",
        "from ch03.simple_cbow import SimpleCBOW\n",
        "from common.util import preprocess, create_contexts_target, convert_one_hot\n",
        "\n",
        "window_size = 1\n",
        "hidden_size = 5\n",
        "#batch_size = 3\n",
        "#max_epoch = 1000\n",
        "\n",
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "\n",
        "vocab_size = len(word_to_id)\n",
        "contexts, target = create_contexts_target(corpus, window_size)\n",
        "target = convert_one_hot(target, vocab_size)\n",
        "contexts = convert_one_hot(contexts, vocab_size)\n",
        "\n",
        "#contexts는 (6,2,7)이 된다\n",
        "\n",
        "model = SimpleCBOW(vocab_size, hidden_size)\n",
        "optimizer = Adam()\n",
        "trainer = Trainer(model, optimizer)\n",
        "\n",
        "trainer.fit(contexts, target, max_epoch, batch_size)\n",
        "trainer.plot()\n",
        "\n",
        "word_vecs = model.word_vecs\n",
        "for word_id, word in id_to_word.items():\n",
        "  print(word, word_vecs[word_id])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| 에폭 1 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 2 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 3 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 4 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 5 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 6 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 7 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 8 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 9 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 10 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 11 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 12 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
            "| 에폭 13 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 14 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 15 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 16 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 17 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 18 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 19 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 20 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 21 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 22 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 23 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 24 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 25 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 26 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 27 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 28 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 29 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
            "| 에폭 30 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
            "| 에폭 31 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
            "| 에폭 32 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
            "| 에폭 33 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
            "| 에폭 34 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
            "| 에폭 35 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
            "| 에폭 36 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
            "| 에폭 37 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
            "| 에폭 38 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
            "| 에폭 39 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
            "| 에폭 40 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
            "| 에폭 41 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
            "| 에폭 42 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
            "| 에폭 43 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
            "| 에폭 44 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
            "| 에폭 45 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
            "| 에폭 46 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
            "| 에폭 47 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
            "| 에폭 48 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
            "| 에폭 49 |  반복 1 / 2 | 시간 0[s] | 손실 1.90\n",
            "| 에폭 50 |  반복 1 / 2 | 시간 0[s] | 손실 1.90\n",
            "| 에폭 51 |  반복 1 / 2 | 시간 0[s] | 손실 1.90\n",
            "| 에폭 52 |  반복 1 / 2 | 시간 0[s] | 손실 1.90\n",
            "| 에폭 53 |  반복 1 / 2 | 시간 0[s] | 손실 1.89\n",
            "| 에폭 54 |  반복 1 / 2 | 시간 0[s] | 손실 1.90\n",
            "| 에폭 55 |  반복 1 / 2 | 시간 0[s] | 손실 1.89\n",
            "| 에폭 56 |  반복 1 / 2 | 시간 0[s] | 손실 1.88\n",
            "| 에폭 57 |  반복 1 / 2 | 시간 0[s] | 손실 1.89\n",
            "| 에폭 58 |  반복 1 / 2 | 시간 0[s] | 손실 1.88\n",
            "| 에폭 59 |  반복 1 / 2 | 시간 0[s] | 손실 1.88\n",
            "| 에폭 60 |  반복 1 / 2 | 시간 0[s] | 손실 1.88\n",
            "| 에폭 61 |  반복 1 / 2 | 시간 0[s] | 손실 1.88\n",
            "| 에폭 62 |  반복 1 / 2 | 시간 0[s] | 손실 1.87\n",
            "| 에폭 63 |  반복 1 / 2 | 시간 0[s] | 손실 1.87\n",
            "| 에폭 64 |  반복 1 / 2 | 시간 0[s] | 손실 1.87\n",
            "| 에폭 65 |  반복 1 / 2 | 시간 0[s] | 손실 1.87\n",
            "| 에폭 66 |  반복 1 / 2 | 시간 0[s] | 손실 1.86\n",
            "| 에폭 67 |  반복 1 / 2 | 시간 0[s] | 손실 1.86\n",
            "| 에폭 68 |  반복 1 / 2 | 시간 0[s] | 손실 1.84\n",
            "| 에폭 69 |  반복 1 / 2 | 시간 0[s] | 손실 1.86\n",
            "| 에폭 70 |  반복 1 / 2 | 시간 0[s] | 손실 1.85\n",
            "| 에폭 71 |  반복 1 / 2 | 시간 0[s] | 손실 1.85\n",
            "| 에폭 72 |  반복 1 / 2 | 시간 0[s] | 손실 1.84\n",
            "| 에폭 73 |  반복 1 / 2 | 시간 0[s] | 손실 1.84\n",
            "| 에폭 74 |  반복 1 / 2 | 시간 0[s] | 손실 1.82\n",
            "| 에폭 75 |  반복 1 / 2 | 시간 0[s] | 손실 1.84\n",
            "| 에폭 76 |  반복 1 / 2 | 시간 0[s] | 손실 1.82\n",
            "| 에폭 77 |  반복 1 / 2 | 시간 0[s] | 손실 1.83\n",
            "| 에폭 78 |  반복 1 / 2 | 시간 0[s] | 손실 1.81\n",
            "| 에폭 79 |  반복 1 / 2 | 시간 0[s] | 손실 1.82\n",
            "| 에폭 80 |  반복 1 / 2 | 시간 0[s] | 손실 1.80\n",
            "| 에폭 81 |  반복 1 / 2 | 시간 0[s] | 손실 1.81\n",
            "| 에폭 82 |  반복 1 / 2 | 시간 0[s] | 손실 1.80\n",
            "| 에폭 83 |  반복 1 / 2 | 시간 0[s] | 손실 1.82\n",
            "| 에폭 84 |  반복 1 / 2 | 시간 0[s] | 손실 1.79\n",
            "| 에폭 85 |  반복 1 / 2 | 시간 0[s] | 손실 1.78\n",
            "| 에폭 86 |  반복 1 / 2 | 시간 0[s] | 손실 1.79\n",
            "| 에폭 87 |  반복 1 / 2 | 시간 0[s] | 손실 1.78\n",
            "| 에폭 88 |  반복 1 / 2 | 시간 0[s] | 손실 1.78\n",
            "| 에폭 89 |  반복 1 / 2 | 시간 0[s] | 손실 1.77\n",
            "| 에폭 90 |  반복 1 / 2 | 시간 0[s] | 손실 1.76\n",
            "| 에폭 91 |  반복 1 / 2 | 시간 0[s] | 손실 1.76\n",
            "| 에폭 92 |  반복 1 / 2 | 시간 0[s] | 손실 1.78\n",
            "| 에폭 93 |  반복 1 / 2 | 시간 0[s] | 손실 1.73\n",
            "| 에폭 94 |  반복 1 / 2 | 시간 0[s] | 손실 1.76\n",
            "| 에폭 95 |  반복 1 / 2 | 시간 0[s] | 손실 1.74\n",
            "| 에폭 96 |  반복 1 / 2 | 시간 0[s] | 손실 1.77\n",
            "| 에폭 97 |  반복 1 / 2 | 시간 0[s] | 손실 1.74\n",
            "| 에폭 98 |  반복 1 / 2 | 시간 0[s] | 손실 1.72\n",
            "| 에폭 99 |  반복 1 / 2 | 시간 0[s] | 손실 1.76\n",
            "| 에폭 100 |  반복 1 / 2 | 시간 0[s] | 손실 1.70\n",
            "| 에폭 101 |  반복 1 / 2 | 시간 0[s] | 손실 1.71\n",
            "| 에폭 102 |  반복 1 / 2 | 시간 0[s] | 손실 1.71\n",
            "| 에폭 103 |  반복 1 / 2 | 시간 0[s] | 손실 1.70\n",
            "| 에폭 104 |  반복 1 / 2 | 시간 0[s] | 손실 1.75\n",
            "| 에폭 105 |  반복 1 / 2 | 시간 0[s] | 손실 1.67\n",
            "| 에폭 106 |  반복 1 / 2 | 시간 0[s] | 손실 1.73\n",
            "| 에폭 107 |  반복 1 / 2 | 시간 0[s] | 손실 1.67\n",
            "| 에폭 108 |  반복 1 / 2 | 시간 0[s] | 손실 1.67\n",
            "| 에폭 109 |  반복 1 / 2 | 시간 0[s] | 손실 1.68\n",
            "| 에폭 110 |  반복 1 / 2 | 시간 0[s] | 손실 1.69\n",
            "| 에폭 111 |  반복 1 / 2 | 시간 0[s] | 손실 1.65\n",
            "| 에폭 112 |  반복 1 / 2 | 시간 0[s] | 손실 1.67\n",
            "| 에폭 113 |  반복 1 / 2 | 시간 0[s] | 손실 1.71\n",
            "| 에폭 114 |  반복 1 / 2 | 시간 0[s] | 손실 1.64\n",
            "| 에폭 115 |  반복 1 / 2 | 시간 0[s] | 손실 1.65\n",
            "| 에폭 116 |  반복 1 / 2 | 시간 0[s] | 손실 1.64\n",
            "| 에폭 117 |  반복 1 / 2 | 시간 0[s] | 손실 1.66\n",
            "| 에폭 118 |  반복 1 / 2 | 시간 0[s] | 손실 1.60\n",
            "| 에폭 119 |  반복 1 / 2 | 시간 0[s] | 손실 1.67\n",
            "| 에폭 120 |  반복 1 / 2 | 시간 0[s] | 손실 1.56\n",
            "| 에폭 121 |  반복 1 / 2 | 시간 0[s] | 손실 1.70\n",
            "| 에폭 122 |  반복 1 / 2 | 시간 0[s] | 손실 1.57\n",
            "| 에폭 123 |  반복 1 / 2 | 시간 0[s] | 손실 1.63\n",
            "| 에폭 124 |  반복 1 / 2 | 시간 0[s] | 손실 1.57\n",
            "| 에폭 125 |  반복 1 / 2 | 시간 0[s] | 손실 1.60\n",
            "| 에폭 126 |  반복 1 / 2 | 시간 0[s] | 손실 1.63\n",
            "| 에폭 127 |  반복 1 / 2 | 시간 0[s] | 손실 1.59\n",
            "| 에폭 128 |  반복 1 / 2 | 시간 0[s] | 손실 1.59\n",
            "| 에폭 129 |  반복 1 / 2 | 시간 0[s] | 손실 1.57\n",
            "| 에폭 130 |  반복 1 / 2 | 시간 0[s] | 손실 1.56\n",
            "| 에폭 131 |  반복 1 / 2 | 시간 0[s] | 손실 1.60\n",
            "| 에폭 132 |  반복 1 / 2 | 시간 0[s] | 손실 1.52\n",
            "| 에폭 133 |  반복 1 / 2 | 시간 0[s] | 손실 1.64\n",
            "| 에폭 134 |  반복 1 / 2 | 시간 0[s] | 손실 1.52\n",
            "| 에폭 135 |  반복 1 / 2 | 시간 0[s] | 손실 1.55\n",
            "| 에폭 136 |  반복 1 / 2 | 시간 0[s] | 손실 1.52\n",
            "| 에폭 137 |  반복 1 / 2 | 시간 0[s] | 손실 1.56\n",
            "| 에폭 138 |  반복 1 / 2 | 시간 0[s] | 손실 1.52\n",
            "| 에폭 139 |  반복 1 / 2 | 시간 0[s] | 손실 1.53\n",
            "| 에폭 140 |  반복 1 / 2 | 시간 0[s] | 손실 1.53\n",
            "| 에폭 141 |  반복 1 / 2 | 시간 0[s] | 손실 1.48\n",
            "| 에폭 142 |  반복 1 / 2 | 시간 0[s] | 손실 1.59\n",
            "| 에폭 143 |  반복 1 / 2 | 시간 0[s] | 손실 1.45\n",
            "| 에폭 144 |  반복 1 / 2 | 시간 0[s] | 손실 1.55\n",
            "| 에폭 145 |  반복 1 / 2 | 시간 0[s] | 손실 1.48\n",
            "| 에폭 146 |  반복 1 / 2 | 시간 0[s] | 손실 1.46\n",
            "| 에폭 147 |  반복 1 / 2 | 시간 0[s] | 손실 1.54\n",
            "| 에폭 148 |  반복 1 / 2 | 시간 0[s] | 손실 1.51\n",
            "| 에폭 149 |  반복 1 / 2 | 시간 0[s] | 손실 1.43\n",
            "| 에폭 150 |  반복 1 / 2 | 시간 0[s] | 손실 1.43\n",
            "| 에폭 151 |  반복 1 / 2 | 시간 0[s] | 손실 1.53\n",
            "| 에폭 152 |  반복 1 / 2 | 시간 0[s] | 손실 1.47\n",
            "| 에폭 153 |  반복 1 / 2 | 시간 0[s] | 손실 1.48\n",
            "| 에폭 154 |  반복 1 / 2 | 시간 0[s] | 손실 1.40\n",
            "| 에폭 155 |  반복 1 / 2 | 시간 0[s] | 손실 1.48\n",
            "| 에폭 156 |  반복 1 / 2 | 시간 0[s] | 손실 1.44\n",
            "| 에폭 157 |  반복 1 / 2 | 시간 0[s] | 손실 1.42\n",
            "| 에폭 158 |  반복 1 / 2 | 시간 0[s] | 손실 1.40\n",
            "| 에폭 159 |  반복 1 / 2 | 시간 0[s] | 손실 1.43\n",
            "| 에폭 160 |  반복 1 / 2 | 시간 0[s] | 손실 1.41\n",
            "| 에폭 161 |  반복 1 / 2 | 시간 0[s] | 손실 1.52\n",
            "| 에폭 162 |  반복 1 / 2 | 시간 0[s] | 손실 1.34\n",
            "| 에폭 163 |  반복 1 / 2 | 시간 0[s] | 손실 1.48\n",
            "| 에폭 164 |  반복 1 / 2 | 시간 0[s] | 손실 1.36\n",
            "| 에폭 165 |  반복 1 / 2 | 시간 0[s] | 손실 1.42\n",
            "| 에폭 166 |  반복 1 / 2 | 시간 0[s] | 손실 1.35\n",
            "| 에폭 167 |  반복 1 / 2 | 시간 0[s] | 손실 1.44\n",
            "| 에폭 168 |  반복 1 / 2 | 시간 0[s] | 손실 1.44\n",
            "| 에폭 169 |  반복 1 / 2 | 시간 0[s] | 손실 1.36\n",
            "| 에폭 170 |  반복 1 / 2 | 시간 0[s] | 손실 1.29\n",
            "| 에폭 171 |  반복 1 / 2 | 시간 0[s] | 손실 1.37\n",
            "| 에폭 172 |  반복 1 / 2 | 시간 0[s] | 손실 1.37\n",
            "| 에폭 173 |  반복 1 / 2 | 시간 0[s] | 손실 1.41\n",
            "| 에폭 174 |  반복 1 / 2 | 시간 0[s] | 손실 1.39\n",
            "| 에폭 175 |  반복 1 / 2 | 시간 0[s] | 손실 1.32\n",
            "| 에폭 176 |  반복 1 / 2 | 시간 0[s] | 손실 1.30\n",
            "| 에폭 177 |  반복 1 / 2 | 시간 0[s] | 손실 1.39\n",
            "| 에폭 178 |  반복 1 / 2 | 시간 0[s] | 손실 1.35\n",
            "| 에폭 179 |  반복 1 / 2 | 시간 0[s] | 손실 1.32\n",
            "| 에폭 180 |  반복 1 / 2 | 시간 0[s] | 손실 1.35\n",
            "| 에폭 181 |  반복 1 / 2 | 시간 0[s] | 손실 1.33\n",
            "| 에폭 182 |  반복 1 / 2 | 시간 0[s] | 손실 1.30\n",
            "| 에폭 183 |  반복 1 / 2 | 시간 0[s] | 손실 1.38\n",
            "| 에폭 184 |  반복 1 / 2 | 시간 0[s] | 손실 1.27\n",
            "| 에폭 185 |  반복 1 / 2 | 시간 0[s] | 손실 1.29\n",
            "| 에폭 186 |  반복 1 / 2 | 시간 0[s] | 손실 1.33\n",
            "| 에폭 187 |  반복 1 / 2 | 시간 0[s] | 손실 1.36\n",
            "| 에폭 188 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
            "| 에폭 189 |  반복 1 / 2 | 시간 0[s] | 손실 1.35\n",
            "| 에폭 190 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
            "| 에폭 191 |  반복 1 / 2 | 시간 0[s] | 손실 1.34\n",
            "| 에폭 192 |  반복 1 / 2 | 시간 0[s] | 손실 1.28\n",
            "| 에폭 193 |  반복 1 / 2 | 시간 0[s] | 손실 1.28\n",
            "| 에폭 194 |  반복 1 / 2 | 시간 0[s] | 손실 1.33\n",
            "| 에폭 195 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
            "| 에폭 196 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
            "| 에폭 197 |  반복 1 / 2 | 시간 0[s] | 손실 1.32\n",
            "| 에폭 198 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
            "| 에폭 199 |  반복 1 / 2 | 시간 0[s] | 손실 1.31\n",
            "| 에폭 200 |  반복 1 / 2 | 시간 0[s] | 손실 1.25\n",
            "| 에폭 201 |  반복 1 / 2 | 시간 0[s] | 손실 1.17\n",
            "| 에폭 202 |  반복 1 / 2 | 시간 0[s] | 손실 1.32\n",
            "| 에폭 203 |  반복 1 / 2 | 시간 0[s] | 손실 1.17\n",
            "| 에폭 204 |  반복 1 / 2 | 시간 0[s] | 손실 1.36\n",
            "| 에폭 205 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
            "| 에폭 206 |  반복 1 / 2 | 시간 0[s] | 손실 1.30\n",
            "| 에폭 207 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
            "| 에폭 208 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
            "| 에폭 209 |  반복 1 / 2 | 시간 0[s] | 손실 1.20\n",
            "| 에폭 210 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
            "| 에폭 211 |  반복 1 / 2 | 시간 0[s] | 손실 1.27\n",
            "| 에폭 212 |  반복 1 / 2 | 시간 0[s] | 손실 1.26\n",
            "| 에폭 213 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
            "| 에폭 214 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
            "| 에폭 215 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
            "| 에폭 216 |  반복 1 / 2 | 시간 0[s] | 손실 1.25\n",
            "| 에폭 217 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
            "| 에폭 218 |  반복 1 / 2 | 시간 0[s] | 손실 1.25\n",
            "| 에폭 219 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
            "| 에폭 220 |  반복 1 / 2 | 시간 0[s] | 손실 1.17\n",
            "| 에폭 221 |  반복 1 / 2 | 시간 0[s] | 손실 1.30\n",
            "| 에폭 222 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
            "| 에폭 223 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
            "| 에폭 224 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
            "| 에폭 225 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
            "| 에폭 226 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
            "| 에폭 227 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
            "| 에폭 228 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
            "| 에폭 229 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
            "| 에폭 230 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
            "| 에폭 231 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
            "| 에폭 232 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
            "| 에폭 233 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
            "| 에폭 234 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
            "| 에폭 235 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
            "| 에폭 236 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
            "| 에폭 237 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
            "| 에폭 238 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
            "| 에폭 239 |  반복 1 / 2 | 시간 0[s] | 손실 1.18\n",
            "| 에폭 240 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
            "| 에폭 241 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
            "| 에폭 242 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
            "| 에폭 243 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
            "| 에폭 244 |  반복 1 / 2 | 시간 0[s] | 손실 1.24\n",
            "| 에폭 245 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
            "| 에폭 246 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
            "| 에폭 247 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
            "| 에폭 248 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
            "| 에폭 249 |  반복 1 / 2 | 시간 0[s] | 손실 1.17\n",
            "| 에폭 250 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
            "| 에폭 251 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
            "| 에폭 252 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
            "| 에폭 253 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
            "| 에폭 254 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
            "| 에폭 255 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
            "| 에폭 256 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
            "| 에폭 257 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
            "| 에폭 258 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
            "| 에폭 259 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
            "| 에폭 260 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
            "| 에폭 261 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
            "| 에폭 262 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
            "| 에폭 263 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
            "| 에폭 264 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
            "| 에폭 265 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
            "| 에폭 266 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
            "| 에폭 267 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
            "| 에폭 268 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
            "| 에폭 269 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
            "| 에폭 270 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
            "| 에폭 271 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
            "| 에폭 272 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
            "| 에폭 273 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
            "| 에폭 274 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
            "| 에폭 275 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
            "| 에폭 276 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
            "| 에폭 277 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
            "| 에폭 278 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
            "| 에폭 279 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
            "| 에폭 280 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
            "| 에폭 281 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
            "| 에폭 282 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
            "| 에폭 283 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
            "| 에폭 284 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
            "| 에폭 285 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
            "| 에폭 286 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
            "| 에폭 287 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
            "| 에폭 288 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
            "| 에폭 289 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
            "| 에폭 290 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
            "| 에폭 291 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
            "| 에폭 292 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
            "| 에폭 293 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
            "| 에폭 294 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
            "| 에폭 295 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
            "| 에폭 296 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
            "| 에폭 297 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
            "| 에폭 298 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
            "| 에폭 299 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
            "| 에폭 300 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
            "| 에폭 301 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
            "| 에폭 302 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
            "| 에폭 303 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
            "| 에폭 304 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
            "| 에폭 305 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
            "| 에폭 306 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
            "| 에폭 307 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
            "| 에폭 308 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
            "| 에폭 309 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
            "| 에폭 310 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
            "| 에폭 311 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
            "| 에폭 312 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
            "| 에폭 313 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
            "| 에폭 314 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
            "| 에폭 315 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
            "| 에폭 316 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
            "| 에폭 317 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
            "| 에폭 318 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
            "| 에폭 319 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
            "| 에폭 320 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
            "| 에폭 321 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
            "| 에폭 322 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 323 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
            "| 에폭 324 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 325 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
            "| 에폭 326 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
            "| 에폭 327 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
            "| 에폭 328 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 329 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
            "| 에폭 330 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
            "| 에폭 331 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
            "| 에폭 332 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
            "| 에폭 333 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 334 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
            "| 에폭 335 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 336 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
            "| 에폭 337 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
            "| 에폭 338 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
            "| 에폭 339 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
            "| 에폭 340 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
            "| 에폭 341 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
            "| 에폭 342 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
            "| 에폭 343 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
            "| 에폭 344 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
            "| 에폭 345 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
            "| 에폭 346 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
            "| 에폭 347 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
            "| 에폭 348 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
            "| 에폭 349 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 350 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
            "| 에폭 351 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
            "| 에폭 352 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 353 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
            "| 에폭 354 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
            "| 에폭 355 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
            "| 에폭 356 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 357 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
            "| 에폭 358 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
            "| 에폭 359 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
            "| 에폭 360 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
            "| 에폭 361 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
            "| 에폭 362 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
            "| 에폭 363 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
            "| 에폭 364 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
            "| 에폭 365 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
            "| 에폭 366 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
            "| 에폭 367 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
            "| 에폭 368 |  반복 1 / 2 | 시간 0[s] | 손실 0.64\n",
            "| 에폭 369 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
            "| 에폭 370 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
            "| 에폭 371 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 372 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
            "| 에폭 373 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
            "| 에폭 374 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 375 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
            "| 에폭 376 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
            "| 에폭 377 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 378 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 379 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
            "| 에폭 380 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 381 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 382 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
            "| 에폭 383 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
            "| 에폭 384 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 385 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
            "| 에폭 386 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
            "| 에폭 387 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
            "| 에폭 388 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 389 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
            "| 에폭 390 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 391 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
            "| 에폭 392 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
            "| 에폭 393 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
            "| 에폭 394 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
            "| 에폭 395 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
            "| 에폭 396 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
            "| 에폭 397 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
            "| 에폭 398 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
            "| 에폭 399 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 400 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
            "| 에폭 401 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 402 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 403 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
            "| 에폭 404 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 405 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
            "| 에폭 406 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 407 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
            "| 에폭 408 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
            "| 에폭 409 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 410 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
            "| 에폭 411 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
            "| 에폭 412 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
            "| 에폭 413 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 414 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 415 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
            "| 에폭 416 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
            "| 에폭 417 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 418 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 419 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 420 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
            "| 에폭 421 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 422 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
            "| 에폭 423 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 424 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
            "| 에폭 425 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 426 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
            "| 에폭 427 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
            "| 에폭 428 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 429 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
            "| 에폭 430 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
            "| 에폭 431 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 432 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 433 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 434 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 435 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 436 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 437 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 438 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
            "| 에폭 439 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
            "| 에폭 440 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 441 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 442 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 443 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
            "| 에폭 444 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 445 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 446 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 447 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 448 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
            "| 에폭 449 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
            "| 에폭 450 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 451 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
            "| 에폭 452 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 453 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 454 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
            "| 에폭 455 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
            "| 에폭 456 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 457 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
            "| 에폭 458 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 459 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 460 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 461 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 462 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 463 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
            "| 에폭 464 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 465 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
            "| 에폭 466 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
            "| 에폭 467 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 468 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 469 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
            "| 에폭 470 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 471 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 472 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
            "| 에폭 473 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 474 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 475 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 476 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
            "| 에폭 477 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 478 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
            "| 에폭 479 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
            "| 에폭 480 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 481 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 482 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
            "| 에폭 483 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 484 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 485 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
            "| 에폭 486 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 487 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
            "| 에폭 488 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 489 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
            "| 에폭 490 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 491 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 492 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 493 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 494 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 495 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 496 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 497 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 498 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 499 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 500 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 501 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 502 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 503 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 504 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
            "| 에폭 505 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 506 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 507 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 508 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 509 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 510 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
            "| 에폭 511 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 512 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 513 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 514 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
            "| 에폭 515 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 516 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 517 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 518 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 519 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
            "| 에폭 520 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
            "| 에폭 521 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 522 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
            "| 에폭 523 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
            "| 에폭 524 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 525 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
            "| 에폭 526 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
            "| 에폭 527 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 528 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 529 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 530 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 531 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 532 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
            "| 에폭 533 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 534 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
            "| 에폭 535 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 536 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 537 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 538 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
            "| 에폭 539 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 540 |  반복 1 / 2 | 시간 0[s] | 손실 0.64\n",
            "| 에폭 541 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 542 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 543 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 544 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 545 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 546 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
            "| 에폭 547 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
            "| 에폭 548 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 549 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 550 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 551 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 552 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 553 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 554 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 555 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
            "| 에폭 556 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
            "| 에폭 557 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 558 |  반복 1 / 2 | 시간 0[s] | 손실 0.64\n",
            "| 에폭 559 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 560 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 561 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
            "| 에폭 562 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 563 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 564 |  반복 1 / 2 | 시간 0[s] | 손실 0.36\n",
            "| 에폭 565 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 566 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 567 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
            "| 에폭 568 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 569 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 570 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 571 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 572 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 573 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
            "| 에폭 574 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
            "| 에폭 575 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 576 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 577 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 578 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 579 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 580 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 581 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 582 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
            "| 에폭 583 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 584 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 585 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 586 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 587 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
            "| 에폭 588 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 589 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
            "| 에폭 590 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
            "| 에폭 591 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 592 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 593 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
            "| 에폭 594 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 595 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 596 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
            "| 에폭 597 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
            "| 에폭 598 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 599 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 600 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 601 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 602 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
            "| 에폭 603 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 604 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
            "| 에폭 605 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 606 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
            "| 에폭 607 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 608 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
            "| 에폭 609 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
            "| 에폭 610 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
            "| 에폭 611 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 612 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 613 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 614 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
            "| 에폭 615 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 616 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 617 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 618 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 619 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
            "| 에폭 620 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 621 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 622 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 623 |  반복 1 / 2 | 시간 0[s] | 손실 0.64\n",
            "| 에폭 624 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 625 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
            "| 에폭 626 |  반복 1 / 2 | 시간 0[s] | 손실 0.64\n",
            "| 에폭 627 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 628 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
            "| 에폭 629 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 630 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
            "| 에폭 631 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 632 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 633 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
            "| 에폭 634 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 635 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 636 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
            "| 에폭 637 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 638 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 639 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 640 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 641 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 642 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 643 |  반복 1 / 2 | 시간 0[s] | 손실 0.43\n",
            "| 에폭 644 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 645 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 646 |  반복 1 / 2 | 시간 0[s] | 손실 0.43\n",
            "| 에폭 647 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 648 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
            "| 에폭 649 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 650 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 651 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
            "| 에폭 652 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 653 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 654 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 655 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 656 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 657 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
            "| 에폭 658 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
            "| 에폭 659 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 660 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 661 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
            "| 에폭 662 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 663 |  반복 1 / 2 | 시간 0[s] | 손실 0.43\n",
            "| 에폭 664 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 665 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 666 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 667 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 668 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 669 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
            "| 에폭 670 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
            "| 에폭 671 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 672 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 673 |  반복 1 / 2 | 시간 0[s] | 손실 0.64\n",
            "| 에폭 674 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 675 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 676 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
            "| 에폭 677 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 678 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
            "| 에폭 679 |  반복 1 / 2 | 시간 0[s] | 손실 0.38\n",
            "| 에폭 680 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 681 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 682 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
            "| 에폭 683 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
            "| 에폭 684 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 685 |  반복 1 / 2 | 시간 0[s] | 손실 0.37\n",
            "| 에폭 686 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
            "| 에폭 687 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 688 |  반복 1 / 2 | 시간 0[s] | 손실 0.64\n",
            "| 에폭 689 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 690 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 691 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
            "| 에폭 692 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 693 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
            "| 에폭 694 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 695 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 696 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 697 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 698 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
            "| 에폭 699 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 700 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
            "| 에폭 701 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
            "| 에폭 702 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 703 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 704 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
            "| 에폭 705 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 706 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 707 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 708 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 709 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 710 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
            "| 에폭 711 |  반복 1 / 2 | 시간 0[s] | 손실 0.41\n",
            "| 에폭 712 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
            "| 에폭 713 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
            "| 에폭 714 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 715 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
            "| 에폭 716 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 717 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
            "| 에폭 718 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 719 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
            "| 에폭 720 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
            "| 에폭 721 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 722 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 723 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 724 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 725 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 726 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 727 |  반복 1 / 2 | 시간 0[s] | 손실 0.36\n",
            "| 에폭 728 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
            "| 에폭 729 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 730 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 731 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 732 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
            "| 에폭 733 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 734 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 735 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 736 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 737 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 738 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 739 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 740 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 741 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
            "| 에폭 742 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 743 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 744 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 745 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 746 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 747 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 748 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
            "| 에폭 749 |  반복 1 / 2 | 시간 0[s] | 손실 0.29\n",
            "| 에폭 750 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
            "| 에폭 751 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
            "| 에폭 752 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
            "| 에폭 753 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 754 |  반복 1 / 2 | 시간 0[s] | 손실 0.42\n",
            "| 에폭 755 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
            "| 에폭 756 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
            "| 에폭 757 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 758 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
            "| 에폭 759 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 760 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 761 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 762 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 763 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 764 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 765 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 766 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 767 |  반복 1 / 2 | 시간 0[s] | 손실 0.41\n",
            "| 에폭 768 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 769 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
            "| 에폭 770 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 771 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 772 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 773 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
            "| 에폭 774 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
            "| 에폭 775 |  반복 1 / 2 | 시간 0[s] | 손실 0.41\n",
            "| 에폭 776 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
            "| 에폭 777 |  반복 1 / 2 | 시간 0[s] | 손실 0.42\n",
            "| 에폭 778 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 779 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 780 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 781 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 782 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 783 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 784 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 785 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
            "| 에폭 786 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 787 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 788 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 789 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 790 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 791 |  반복 1 / 2 | 시간 0[s] | 손실 0.64\n",
            "| 에폭 792 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 793 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 794 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
            "| 에폭 795 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 796 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 797 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 798 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 799 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 800 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 801 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 802 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
            "| 에폭 803 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
            "| 에폭 804 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
            "| 에폭 805 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
            "| 에폭 806 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 807 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 808 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 809 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
            "| 에폭 810 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 811 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 812 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
            "| 에폭 813 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
            "| 에폭 814 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 815 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 816 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 817 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 818 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 819 |  반복 1 / 2 | 시간 0[s] | 손실 0.40\n",
            "| 에폭 820 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 821 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
            "| 에폭 822 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 823 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 824 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 825 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 826 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 827 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 828 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 829 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 830 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
            "| 에폭 831 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 832 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 833 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 834 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 835 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
            "| 에폭 836 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 837 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 838 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
            "| 에폭 839 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 840 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 841 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
            "| 에폭 842 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 843 |  반복 1 / 2 | 시간 0[s] | 손실 0.53\n",
            "| 에폭 844 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 845 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
            "| 에폭 846 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 847 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 848 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 849 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
            "| 에폭 850 |  반복 1 / 2 | 시간 0[s] | 손실 0.40\n",
            "| 에폭 851 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
            "| 에폭 852 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 853 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 854 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 855 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 856 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
            "| 에폭 857 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 858 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
            "| 에폭 859 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
            "| 에폭 860 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 861 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 862 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 863 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
            "| 에폭 864 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
            "| 에폭 865 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 866 |  반복 1 / 2 | 시간 0[s] | 손실 0.64\n",
            "| 에폭 867 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 868 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 869 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 870 |  반복 1 / 2 | 시간 0[s] | 손실 0.64\n",
            "| 에폭 871 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
            "| 에폭 872 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 873 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
            "| 에폭 874 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
            "| 에폭 875 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 876 |  반복 1 / 2 | 시간 0[s] | 손실 0.59\n",
            "| 에폭 877 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
            "| 에폭 878 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 879 |  반복 1 / 2 | 시간 0[s] | 손실 0.64\n",
            "| 에폭 880 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
            "| 에폭 881 |  반복 1 / 2 | 시간 0[s] | 손실 0.64\n",
            "| 에폭 882 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 883 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 884 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 885 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
            "| 에폭 886 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 887 |  반복 1 / 2 | 시간 0[s] | 손실 0.64\n",
            "| 에폭 888 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
            "| 에폭 889 |  반복 1 / 2 | 시간 0[s] | 손실 0.39\n",
            "| 에폭 890 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 891 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
            "| 에폭 892 |  반복 1 / 2 | 시간 0[s] | 손실 0.46\n",
            "| 에폭 893 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 894 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
            "| 에폭 895 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 896 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 897 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
            "| 에폭 898 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 899 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 900 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 901 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 902 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
            "| 에폭 903 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 904 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 905 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 906 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
            "| 에폭 907 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
            "| 에폭 908 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
            "| 에폭 909 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
            "| 에폭 910 |  반복 1 / 2 | 시간 0[s] | 손실 0.38\n",
            "| 에폭 911 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
            "| 에폭 912 |  반복 1 / 2 | 시간 0[s] | 손실 0.38\n",
            "| 에폭 913 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
            "| 에폭 914 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 915 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
            "| 에폭 916 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 917 |  반복 1 / 2 | 시간 0[s] | 손실 0.43\n",
            "| 에폭 918 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 919 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
            "| 에폭 920 |  반복 1 / 2 | 시간 0[s] | 손실 0.52\n",
            "| 에폭 921 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
            "| 에폭 922 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
            "| 에폭 923 |  반복 1 / 2 | 시간 0[s] | 손실 0.32\n",
            "| 에폭 924 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 925 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 926 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 927 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 928 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
            "| 에폭 929 |  반복 1 / 2 | 시간 0[s] | 손실 0.68\n",
            "| 에폭 930 |  반복 1 / 2 | 시간 0[s] | 손실 0.32\n",
            "| 에폭 931 |  반복 1 / 2 | 시간 0[s] | 손실 0.63\n",
            "| 에폭 932 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 933 |  반복 1 / 2 | 시간 0[s] | 손실 0.43\n",
            "| 에폭 934 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 935 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
            "| 에폭 936 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
            "| 에폭 937 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
            "| 에폭 938 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 939 |  반복 1 / 2 | 시간 0[s] | 손실 0.45\n",
            "| 에폭 940 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
            "| 에폭 941 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 942 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 943 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 944 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 945 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
            "| 에폭 946 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
            "| 에폭 947 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 948 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
            "| 에폭 949 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 950 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 951 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
            "| 에폭 952 |  반복 1 / 2 | 시간 0[s] | 손실 0.58\n",
            "| 에폭 953 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 954 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 955 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 956 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 957 |  반복 1 / 2 | 시간 0[s] | 손실 0.43\n",
            "| 에폭 958 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
            "| 에폭 959 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 960 |  반복 1 / 2 | 시간 0[s] | 손실 0.47\n",
            "| 에폭 961 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 962 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
            "| 에폭 963 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 964 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
            "| 에폭 965 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 966 |  반복 1 / 2 | 시간 0[s] | 손실 0.54\n",
            "| 에폭 967 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 968 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
            "| 에폭 969 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 970 |  반복 1 / 2 | 시간 0[s] | 손실 0.37\n",
            "| 에폭 971 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 972 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
            "| 에폭 973 |  반복 1 / 2 | 시간 0[s] | 손실 0.37\n",
            "| 에폭 974 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
            "| 에폭 975 |  반복 1 / 2 | 시간 0[s] | 손실 0.51\n",
            "| 에폭 976 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
            "| 에폭 977 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 978 |  반복 1 / 2 | 시간 0[s] | 손실 0.42\n",
            "| 에폭 979 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
            "| 에폭 980 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 981 |  반복 1 / 2 | 시간 0[s] | 손실 0.49\n",
            "| 에폭 982 |  반복 1 / 2 | 시간 0[s] | 손실 0.57\n",
            "| 에폭 983 |  반복 1 / 2 | 시간 0[s] | 손실 0.35\n",
            "| 에폭 984 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
            "| 에폭 985 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
            "| 에폭 986 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
            "| 에폭 987 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
            "| 에폭 988 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 989 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
            "| 에폭 990 |  반복 1 / 2 | 시간 0[s] | 손실 0.44\n",
            "| 에폭 991 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 992 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
            "| 에폭 993 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
            "| 에폭 994 |  반복 1 / 2 | 시간 0[s] | 손실 0.50\n",
            "| 에폭 995 |  반복 1 / 2 | 시간 0[s] | 손실 0.42\n",
            "| 에폭 996 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
            "| 에폭 997 |  반복 1 / 2 | 시간 0[s] | 손실 0.48\n",
            "| 에폭 998 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
            "| 에폭 999 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n",
            "| 에폭 1000 |  반복 1 / 2 | 시간 0[s] | 손실 0.55\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48152 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48373 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49552 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49892 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48152 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48373 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49552 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49892 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEHCAYAAAC0pdErAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5hU5fXA8e/ZTq9LL0sTQborqNhFBLFHE1GjJho1GtPNDzQRWxKjSUzsGiV2ktiiERRRUUQpLkhHegdl6X1hd8/vj7kzzMze2Sk7d2dn93yeZx/mvrfMOzvsPfftoqoYY4wx4TJSnQFjjDE1kwUIY4wxrixAGGOMcWUBwhhjjCsLEMYYY1xZgDDGGOMqy6sLi0hH4EWgNaDAM6r697BjBPg7cB5wALhOVec6+64Ffuscer+qvhDtPVu2bKkFBQVJ+wzGGFPbzZkzZ5uq5rvt8yxAAKXAr1R1rog0AuaIyBRVXRJ0zEigh/MzBHgSGCIizYFxQCG+4DJHRN5R1Z2VvWFBQQFFRUVefBZjjKmVRGRdpH2eVTGp6hZ/aUBV9wJLgfZhh10EvKg+M4GmItIWOBeYoqo7nKAwBRjhVV6NMcZUVC1tECJSAAwEZoXtag9sCNre6KRFSjfGGFNNPA8QItIQeAP4uaru8eD6N4pIkYgUFRcXJ/vyxhhTZ3kaIEQkG19weEVV33Q5ZBPQMWi7g5MWKb0CVX1GVQtVtTA/37WdxRhjTAI8CxBOD6XngKWq+tcIh70DXCM+JwK7VXULMBkYLiLNRKQZMNxJM8YYU0287MU0FPg+sFBE5jlpdwCdAFT1KWASvi6uK/F1c/2Bs2+HiNwHfOmcd6+q7vAwr8YYY8J4FiBUdTogUY5R4NYI+8YD4z3ImjHGmBh4WYJIG498tILMDKFBTiYNcrNomJtF26b16N22MTlZNtjcGFM3WYAAnv50FfsPl1VIz8nKoG/7Jgzq1JTTjslnaLeWZGRUWigyxphaQ2rTinKFhYWa6EjqktIy9peUsb+klH0lpazdtp+563cyd/0uFm7azeHScjo2r8c1JxZw5ZBONMi12GqMSX8iMkdVC133WYCI7tCRMiYv/oZXZq5n9toddM1vwC+GHcMF/dsl/b2MMaY6VRYgrII9BnnZmVw0oD3/vulExl9XSGmZctuErzjrz59wuLQ81dkzxhhPWICIg4hw1rGt+fCXp9OhWT1Wb9tPn3GTWbd9f6qzZowxSWcBIgE5WRl89psz+W5hBw6XlXP6Q59w6ROfs/vAkVRnzRhjksYCRIJEhAcv68+jowcCMHf9Li554vMU58oYY5LHAkQVnd+vbaCxerXT88kYY2oDCxBVJCI8OnogY0ceC8ClT3xBSWnFMRXGGJNuLEAkyU2nd+Om07sC0PO377No0+4U58gYY6rGAkQSjRlxLLef2xOA8x+dzpdrbX5BY0z6sgCRRCLCj0/vFti+/KkZHDhcmsIcGWNM4ixAJFlGhnBytxaB7d53TWbXgcMpzJExxiTGAoQHnrmmkCeuGhTYLlprPZuMMenHAoQHGuZmcV7ftoHtG14sskZrY0zasQDhoSb1sgOvz390Ou/M35zC3BhjTHwsQHhoxtizePWGIYHtn074KoW5McaY+FiA8FD9nCxO7t4y1dkwxpiEWICoBrPuODvweuf+w5SW2RThxpiazwJENWjdOI9LB7YHYOB9U+h+53s2iM4YU+N5FiBEZLyIbBWRRRH23y4i85yfRSJSJiLNnX1rRWShsy/5S8SlwG1n9wjZtgBhjKnpvCxBPA+MiLRTVR9S1QGqOgAYC3yqqsF3zTOd/a5L4aWbLi0bsPz+kYHtB99fxkWPTWfvIVtDwhhTM3kWIFR1GhDrY/JoYIJXeakpcrIyuOm0roHt+Rt3c/0LRTZFuDGmRkp5G4SI1MdX0ngjKFmBD0RkjojcmJqceeMX5xwTsj17zQ4ufeKLFOXGGGMiy0p1BoALgM/DqpdOUdVNItIKmCIiXzslkgqcAHIjQKdOnbzPbRXlZrnH5ENHysjLzqzm3BhjTGQpL0EAVxBWvaSqm5x/twJvAYMjnayqz6hqoaoW5ufne5rRZBAR1/QfvVgr2uKNMbVISgOEiDQBTgfeDkprICKN/K+B4YBrT6h0NfuOs2ndODck7bMV21KUG2OMcedlN9cJwAygp4hsFJHrReRmEbk56LBLgA9UdX9QWmtguojMB2YDE1X1fa/ymQqtGudx56jeqc6GMcZUSlQ11XlImsLCQi0qSp+qmoIxE0O2z+ndmp6tG/FrZ1U6Y4zxmojMiTScoCa0QdRZOWEN1lOWfMtjU1fyv/mbKRgzkd0HbYyEMSZ1LECk0Py7hnPFCR0rpD8zbTUA67cfqO4sGWNMgAWIFKqXk0mT+tkR9yu1p/rPGJN+LECkWKtGeRXSFtrqc8aYGsACRIpdd3IBJ3VtkepsGGNMBRYgUiwzQ5hw44n069Ak1VkxxpgQFiBqiA7N6lVIKyu3NghjTOpYgKgh/nhpP84+tlVI2v6SMgA+X7mNz1YUpyJbxpg6zAJEDdGkXjbPXXdCSNrVz81i5da9XPXsLL7/3OwU5cwYU1dZgKhhLuzfLmR72F9dJ7E1xhjPWYCoYTIz3Gd7NcaY6mYBoobJzrQAYYypGSxA1DD/N+LYSvfvPniE0rLyasqNMaYuswBRw7RomBtxn6rS/54P+M0bC6oxR8aYusoCRBo5UuYbF/HWV5tSnBNjTF1gASKNHHGqlqyVwhhTHSxApBF/gMiIsK61McYkU1aqM2Aq+t9PTmHr3kOcdWwruoydFEgfcO8UAErLFVVFLFAYYzxkJYgaqG+HJpzdqzUiwjs/Gep6zOLNe6o5V8aYusYCRA0XqVfT7ycupTatJ26MqXksQNRwmRGqkWas3s6oR6azfV9JNefIGFNXeBYgRGS8iGwVkUUR9p8hIrtFZJ7zc1fQvhEiskxEVorIGK/ymA7q52ZG3Ldkyx5emrmuGnNjjKlLvCxBPA+MiHLMZ6o6wPm5F0BEMoHHgZFAb2C0iPT2MJ81WuO8bB7+Xv+I+0vLlMWbd1MwZqJNCW6MSSrPAoSqTgN2JHDqYGClqq5W1cPAv4CLkpq5NHPJwA6sfWAUp/ZoWWFfabkya7Xv1/zR0q3VnTVjTC2W6jaIk0Rkvoi8JyLHOWntgQ1Bx2x00lyJyI0iUiQiRcXFtfsJOi+7YnVTaVk55U5jtfV6NcYkUyoDxFygs6r2Bx4F/pvIRVT1GVUtVNXC/Pz8pGawpsnNqvh1rd2+PxAgSkptEj9jTPKkLECo6h5V3ee8ngRki0hLYBPQMejQDk5andezdaMKaR8u3crBw77A8Oqs9dWdJWNMLZayACEibcQZCiwig528bAe+BHqISBcRyQGuAN5JVT5rklvO7O6a/vCHy6s5J8aYusCzqTZEZAJwBtBSRDYC44BsAFV9CrgM+LGIlAIHgSvUN/KrVER+AkwGMoHxqrrYq3ymE1ttzhhTnTwLEKo6Osr+x4DHIuybBExy22eMMaZ6pLoXk0myPYeOpDoLxphawgJEmpk59mym3X5mxP397v6AT5fX7u6+xpjqYQEizbRpkkenFvUrPeaLVduqKTfGmNrMAkSa+s9NJ5GTGeHrs0lejTFJYAEiTQ3u0pzTjnEfGLiqeB+TFm6p5hwZY2obCxBpzb2o8OHSrdzyylwO28hqY0wVWIBIY78a3pNGuZF7Kq/bvr8ac2OMqW0sQKSxXm0bs/Cec5l/13DX/VaKMMZUhQWIWqBJ/WzX9BVb9zHy79MoGDOxmnNkjKkNLEDUcquKfdVMZeXWtckYEx8LEHXEjFXbK6RNWriFfSWlKciNMSYdWICoI65+bhYj/jYtsP31N3u45ZW5jHljQQpzZYypySxA1CFff7OX3Qd9czXtd0oOm3YdTGWWjDE1mAWIWmJo9xZc0L9d1OMufGw6qkfbI2wCcWNMJJ5N922q1ys3nAjAB4u/qXTp0XXbD/Dc9DUM6Ni0urJmjElTVoKoZSSGIsH9E5fajK/GmKgsQNQyEmOl0aMfr/QdH0tEMcbUSRYgapl47/dz1u30JiPGmLRnAaKWCY8PVw7pFPWc8qBBdNeMn82E2euTnCtjTDqyRupaJjsrAw6X8eIPB7O/pJQm9bN5dVblN/zSciUnwxdapi0vZtryYkYPjh5YjDG1mwWIWmbCj07kv/M2cWqPlogInyzbGvUcm4bDGOPGsyomERkvIltFZFGE/VeJyAIRWSgiX4hI/6B9a530eSJS5FUea6NebRszdmSvQONzy4a5Uc/59Wvz+Wjpt15nzRiTZrxsg3geGFHJ/jXA6araF7gPeCZs/5mqOkBVCz3KX53Qp30T3r3tlEqPmbhwC9e/UGQlCWNMCM+qmFR1mogUVLL/i6DNmUAHr/JS13VoVi+m44b84UOPc2KMSSc1pRfT9cB7QdsKfCAic0TkxspOFJEbRaRIRIqKi23wl5vMjNj6vm7bd7jS/Qs37qZ4b0kysmSMSQMpb6QWkTPxBYjgepBTVHWTiLQCpojI16o6ze18VX0Gp3qqsLDQ6khcZGcm5znggsem07xBDnN/d05SrmeMqdlSWoIQkX7As8BFqhpYsEBVNzn/bgXeAganJoe1Q1aMJYhY7NhfeSnDGFN7pCxAiEgn4E3g+6q6PCi9gYg08r8GhgOuPaFMbGKtYgpWMGYid7+z2IPcGGPShZfdXCcAM4CeIrJRRK4XkZtF5GbnkLuAFsATYd1ZWwPTRWQ+MBuYqKrve5XPuiDR+Zae/2JtcjNijEkrXvZiGh1l/w3ADS7pq4H+Fc8wVTGkS3NmrdkR93k3vVTE098vDFlDwhhTN9SUXkymhpq8+FtWFe+j1MZIGFPnpLwXk6keGVWY1vvsv3zKTad1TWJujDHpwEoQdcRDl/fj+yd2Zv5dw/nsN2fGff7T01Z7kCtjTE1mAaKO6NCsPvdd3Icm9bNplFe1guPsBNoyjDHpxwJEHVQ/p2oB4rtPz2Dd9v1Jyo0xpqayAFEH5WRlsOz+yuZRjG5fSWmScmOMqaliepQUkbuiHLJVVZ9KQn5MNcnNyiQnK4PDpeW0bpzLt3vim2Npxbf7aNEglzZN8jzKoTEm1SSW/u0iMgm4goorWvq9oKoXJzNjiSgsLNSiIls+Ilb+7/6ml+bwwZLE1oNY+8CoZGbJGFPNRGROpGUVYq1iKlPVPaq62+0H3+yrJs2ICCJCVYY4vDprvSeD6P43f7NVYxmTYrEGiGh3AAsQaawqN/g73lrIzNXJ7dW0ZPMebpvwFWPfXJjU6xpj4hNrd5ZsEWkcYZ8AmUnKj0mBqkb3Q0fKkpIPP3/JYcuug0m9rjEmPrEGiJnAzyPsE0IX+zFppryKVUT+Qdp/+3A52/aVcP/Ffat0PX+JpgqDv40xSRBrgBhClEZqwHoxpSl/G8STVw3i7XmbeX/xN3Gd758t9m8frgCoECD+U7SB2Wt28OfLY5uD0R+uJOJ/N2NMdYg1QJSp6p5IO0XE2iDSmP+JvX5uFk99/3g+W1HM95+bHfP5ZeXlrukbdhygdeM8fvP6AgBen7OR+jmZfPSr02nbJPI62f4CjZUgjEkta6Q2gSom/7pC8S4wVHKkYoDYV1LKqQ9O5Y63QhuaDxwu4753l1R6PatiMqZmiDVAZItI4wg/TbBG6rQ2ok9bALq0bADEP/NrSWk5U8LGUew9dASAz1YUJ5wvq2IyJrXibaSO9BdrK76lsauHdOKyQR2ol+OL8/HelktKy5i+cltI2uFSX6kiJ6viM0i0G3+gDcLigzEpFVOAUNV7vM6ISR0RCQQHgIw4q5h2HjhCeEeoEidAZGe6FFKdyx88XEbx3hI6tagfsrvcqpiMqRFssj5Tgf++PKhTU/5769Coxz/w3te8MXdjYPuml4pY9s1eAHLcAoTjxpeKOO2hqRXSA43UVsVkTErZinKmAv+TuwIDOjaN+/zJi79l8mJfm4R7FZPPZyt81VLl5RpSarEqJmNqBitBGBe+O7P/SX5gp6Z0b9UwoSu5VTHtPniEzUGjpA8cKWN/0LxLXsztZIyJn6cBQkTGi8hWEVkUYb+IyCMislJEFojIoKB914rICufnWi/zaUIFShDOjfqtW4by4S9PT+hablVMn63YxskPfBzYPu3BqRw3bnJg+2gJwooQxqSS1yWI54HKVqYZCfRwfm4EngQQkebAOHwjuAcD40Skmac5NQHJvC3Xz4neA3rH/sOhCU6EiLWt/OaX5vDXD5bFmTNjTDSeBghVnQZUNtXnRcCL6jMTaCoibYFzgSmqukNVdwJTqDzQmCQqaOEbD3HlkE5VvlbT+jlxnxPoxRTj8e8v/oZHPl4JwBtzNvL+ovimCjHGuEt1I3V7YEPQ9kYnLVJ6BSJyI77SB506Vf2GZqBZg5ykLQQU3LspVv4miOXf7mPSwi2c17dtzOf+6rX5gC1kZEwypH0jtao+o6qFqlqYn5+f6uyYJPC3QWzadZBbXpmb0rwYU5elugSxCegYtN3BSdsEnBGW/km15cpU6pNfn0FJaTkXPDY9MGI6GU7640cM6dKc49o1Sdo1jTGJS3UJ4h3gGqc304nAblXdAkwGhotIM6dxeriTZmqAgpYN6NmmEcvvH5nU627ZfYj/ztvM7yctTep1jTGJ8bQEISIT8JUEWorIRnw9k7IBVPUpYBJwHrASOAD8wNm3Q0TuA750LnWvqiZ3XUuTFFN+cRpHypTpK4uZvPhb5qzbScPcrKSuJ/35ym0M7d6yQvq05cX0bNMoae9jjAnlaYBQ1dFR9itwa4R944HxXuTLJE+P1r4bdO92jVm4aQ9z1u3k1R8NYX9JGaP/MTMp73HVs7Po16EJb90yNGQq8mvGz6ZdkzzXcwrGTOTWM7tx+7nHJiUPxtRFqa5iMrXI7y/pw9+vGEC/Dk05qVuLpF57wcbdvPXVJsqd5e/8g/g27z4U8ZzHp65Kah7C7T5whOc/X2Mjv02tZQHCxOzDX57Oy9cPibi/cV42Fw1w7Y2cFL9+bT5d75jE/A27ArPFptKYNxdw9/+WMHf9zlRnxRhPpLoXk0kj3Vs1THhOpmS66PHPufakzqnORmAE+OFSK0GY2slKECYt+WeCDfbCF2urNQ9VmXVWVfn3l+tZXbyPA4eT16BvTDJZCcKkpdLyik/t495ZXL2ZqELBYc66nfzfG771unu3bcykn52apEwZkzxWgjCe+e+tQ7loQDtPrr1+x4EqX6N4bwlfrKpYEolXIpMbHjpytA1lyZY9Vc6DMV6wEoTxzICOTRnUqRlvz9sc9dhu+Q1YVby/GnJ11CVPfM7GnUfXpXjxh4M57ZjYp2vRKhQhMjx6NCspLWPXgSO0buze/deYeFgJwngqvAvosF6tAfjB0IKQ9Cyv7piVCA4OAPe9uyTw+t0Fm7n8qS8A2FdSGrKgkV9gadQEGiEyPFrr4tZXvmLIHz7y5Nqm7rEShKlW/oDRMDf0v15mrIs/xOmGF76kW6uGjB3ZK67zfvLqV4Avv33GTSYrQ7i8sCMbdhzgD5f09e1zjk3kXu9VgPhw6beeXNfUTRYgjKfCn64Daz2I0Kd9YxZt8tW/Z2V6dcPcyodLtzJ2ZK8Ka19XzGvFNH9jeGm5MmH2egBOe2hqyDF/nryMyws7csnA9jEHOpeF9pJKVW1FPlNlVsVkPBVexeTvfCTANScVBNK9KkH4/Wv2erreMYmCMROZvWYH2/aVxHReaVn0doZZa3bw69fm87zTzfaHz3/JcXe9T0lpWcRzvL55u3TyShlVZUMSOhWY6mcBwngqv1FoY2lwtUzwzffSgd6NwAaYuHBL4PV3n55B4f0fVjhGgvoj+e/fR8pjH7HtDzoff72V/YfLmDBrfWDfLa/MCbRprNm2n0WbdseV/3iV16DpP/75+VpOfXAqizd7+5lN8lmAMJ46r28bnrr6ePp18K3xcF6fNk56W4b1akXLhjl88IvTaJLA0qTxaN4g+vWXfbuXvYeOAJDpRIhYShB+W/eU8PznawLbwdOBTFr4DV+u9U3JceafP+Gut0PHbGzdW3FOqSWb9/D+oi0V0mNRg+IDs9f4JmJevz05pYjXijbw2YripFzLVM4ChPGUiDCiT5tAFVKP1o1Y+8AojmndiFaN8yj67Tkc07pR4IbslWYxBqDrny9i76EjR9seymIvQbwxdyN3/+9oT6h4qnk+XVbxhnfeI59x88tz+c+XG/jffF9X4bfnbWL4w5+yPUoVWVVKEIdLy5O6EJRfsmLW7a8v4PvPzY64f866nRSMmcjyb/dy9bOzKg1MBw+XsfvgkSTlrPaxAGGqmfttIpYn/KrIy86M6bjZa3fQ9+4PAtu/fn1Bwu/pdpN+f9E3rsdWdvP8zRsLuG2Cr1fVz/41j+Xf7uPsv35KwZiJrNvuGzvy6fJiNu48eiOsSgmi/z0fMPDeD6IfGKPqbiv3dya4+53FTF+5jb9MWRbx2HP/No3+91T8rM9NX8OHS472CFNV5qyre0vSWIAw1cJ/j4h04zqpWwueuvp4TnFZGCiVpi1PvCqj3KUIcfPLc9wP1qPnrNy6N+q1dx3wPfVOX+kbCX7t+NkMf3ja0fd2ftG3vjqXx6eu5NnPVrNmW2wDEQ8eKWP/4cgN7OmmsvgUaUT+fe8u4YYXiwLbL81cx3eenMFHMXYjXr/9QEzfY01nAcJUi4e/N4DvFnZgQMemEY8Z0acNednu/yX9A+wSlYoen2UJPMY/NnUlw/46jeXfxn9zORB0U/e/88QFW3ho8jLun7iU7z09I+K5y77Zy+NTV8b9nvH4aOlWitb6nsJLy8qjVpPVJCu+3QdUHFwZyWkPTWXYX6e57lu4cTejn5lZaS+3msIChKkWnVs04MHL+pMVdQCA+528cb2qDdlZvLn65ztyK0FE4p+2Y7ozS61/KvGE39slOLmNBve79InPeWjysohtLmc8NJVxby+qUp7emLuRy57yBanfvb2Y4+//kENHKt4kv1i5jZmrt1fpvZLN//0kozf22LcWMGP1dpZ/sy+m4xdv3s0Tn3gbvCOxAGFqlEh/gN9UsnJcLKpSVZSoeBqp/fdz/1reDXKqFhDV5T5f2diLQ06jdKRSz9rtB3hhxrqQtNHPzOSsP3/ievyV/5hZaQ+sSU6344MuVVlXPjuLK56p+nK1yezJVR7cP7uajXpkOg++H7kdxUsWIEyNEj4FxZk9fZPnndQ1uUuYVod4ehIpvhKHv0dNVUeWr9m+n6VxzBLrf7eyOKLajNXbWe3SrqGqfLFqOze/PDfiuf4HgcrebdLCLXGVwirkg6Oj9qsqMO9Wla+UXjwNECIyQkSWichKERnjsv9hEZnn/CwXkV1B+8qC9r3jZT5NzRH+t9y6cR4L7x7OzWd0C6RlZQjvxbF+wiUeD8KL5MlPV8U8gnjplj1c+Ph0Nu3y1XHH2qAcycWPf87Iv38WkravpJRNuw5SVq4Vru//vccTICIJv4Tb/dl/0w4PohMXHC113PLKXF6dvT5k/2tFG1zfc++hI7w0c53r+uDJuKn7r5uMObQSLdmkYu1zzwKEiGQCjwMjgd7AaBHpHXyMqv5CVQeo6gDgUeDNoN0H/ftU9UKv8mlqlqtPDF1K9GfDetAoL5usoLqn3KwMerVtTK+2jWO65t0XHpfUPMZK1TftRixP8i/OWBeYlwp8N8dwq4sr1lkfPFwW11P2L/89j6enreLMP3/Cuws2UzBmIne/s5gjzoDA4ADhVv0Ti1iCTKAEEXboizPWhmxv3hXaKPzgZPeqlnHvLOZ3/13EzNWJd0UtK9eI4z/KNXltEIlKxfQpXpYgBgMrVXW1qh4G/gVcVMnxo4EJHubHpIGh3Vuy9oFRge22TeoBodUEr//4ZCC2P9aCFvVpUi87uZmMw9a9JTzxyaqkXOusv3xaIe3+iUsDpY5YKPD1Fl8PqUc/8jV8+ueQgtCV+s552Pd+j3y0IpC2v6SUL9dWfhMOLxWI6zO8Ly38qTjaQ3Kk/dv2+Rr1DwX1DIr3gfu6f87mmN++F5J2yp8+ZteBwyHXSkYpC+JvzkjW+8bDywDRHgguD2500ioQkc5AF+DjoOQ8ESkSkZkicrF32TTpxl9yiKW4n0hX02TaffBIyAA2L8Szul52ptCyYS7gXo0VfBPyd+n865TlgbSf/3selz81I2Syw1tfncs/pq0ObIcHiFKX+az8wT38nhe+CFPFby+B7zPGG7HbOucbdx7k85XbA/kc8+ZChj7wccgxCzfupmDMRNcSXjIH16Vifq2a0kh9BfC6qgaXaTuraiFwJfA3EenmdqKI3OgEkqLiYpufpS6JpQQRx1x7nvlq/a7oB1XBkTimA8nMyKBFQ9+o9cMu54U/pYZ3e13sTDIYXP00ccEWfj9pqes1Zq/ZweTFFQeXBdo8nJve/pJSDh0pS2o1SjJvp8GB65s9oT3q3vxqIwBTXaZL+c6TM0J+h4s37w50uV64aTevzgptY1HViCWFVDzreBkgNgEdg7Y7OGluriCseklVNzn/rgY+AQa6naiqz6hqoaoW5ufHvlykSX+x9E7p3qphNeQkteKZUHDa8mLmbYgcsMJvTt3vDK1y8e+N9DS7Y//hkLmNPl/pvua3v/Tnbz85btxkTvnT1ArX/XLNDqYtL/b1jFq5LepN0osmApHKb87RejgFl2Kf/ezoZI5j31zIHW8tDDn25Znr6HbHJIr3+kpowaOx1+84Ojq7tKy8Sj28YuXlgkFfAj1EpAu+wHAFvtJACBE5FmgGzAhKawYcUNUSEWkJDAUe9DCvpoYZ1bctbZpUvq5ytBLEyD5t+NNl/ZKYq5opuAooFlOWRJ4uIlp7hv9e53bD/MsHy3j049ABXW4x/JVZ6wLnBwekbftK6NCsXsixRet2cs342dx70XEVZsANzVfkm6V/WpKqqOz60RqwS8sU/wKK0doR3pjre4besPMA+Y1yuf6Fo9N9nPs338jstQ+Movud73HRgHb8/QrX5+ak8awEoaqlwE+AycBS4D+qulhE7hWR4F5JVwD/0tBvoBdQJCLzgfip0sEAABiCSURBVKnAA6q6BFNnPH7VIH53fkinN8Zd0Ju3bjk5sB2tDWJIl+Y0zktdA3V1WRLHeIdoog1Q81e1uJUgwoMDuDdQ3/nWokA1TXgbUaTSzdptCbTjOJf++Out/PerTRSMmcjb8yJVYhzlNrq7svu6/yNEWq0wuOE/1obmWKqT3p63OaZrVYWnS46q6iRgUljaXWHbd7uc9wXQ18u8mfTzg6FdQrajBYjSGP4YT+3R0rVx0rjz37hibTCNVsqLtW//+KB1NvyWfbOXktIy+nU4Or9XpGrHl2f6RoFPmL2eiwZUPi7mxpdCJ1QUIrdnLN68O9AGFLGKKej/oVuDfch7hV0k1QPzbE1qk75c/nrGXdCbNdv28+KMdTE9hXVv1dACRAKOxNjuEa2ZKI729QqCq1z8rh3vvk5E0TrfYk0zV+9g7vqd5GVlhjQ8+9fbAPdpWdwC4pbdBxn1yPTA9u/eXszOA0f4+OutIcd9vWUP2VkZnFDQPI7Pm7xR4FVhAcKkreCn02G9WvPAd/rSsmEuuw8e4dCRMq4c0qnS87u3asiQLi345+drvc1oLbLVaTx1qwrKELdR1JXf4MrKlU89micrvMus3z+mrea9sHU5/OttuJEIRQi3QXVu7UFXPjsL8AWyMpcSRHm5Bqqn/L+t1cX7Ob5zc0rcqruqcTyEBQiTtjLD6i/8/fub1Mvmwcv6Rz3/w1+eXmGkronN2DcXVkjLzswIWWY1FuWqEZ/6vbL3UORZbSMJL0G8v2hLpXNNReJW7VmmSoYTGvwB9fbXF1Barmx2maSyOsf21JRxEMbE7bejghuxE/ujScbcOiay6FVM3t3s/GuAJ0P4PfmjpVvdD6zE4s27Xaszn5jqG2m/fvsB5qw7mud3F7g3QlfniGoLECZt9WrbmH9cUwhE7/Xx1NXHu6ancm6d2sat9OA+zcZRyXgaPlJWHtdYkPifCaRCCaJ+TmxL2AaL1Nb18Ie+aqnTHpoakh7pV/PL/8wLvF6wcRcrt8a2rkQirIrJpLVY/9ZH9GnDqz8aQl52Jpc+8cXR860E4alXZq2rdH8y6tN//PIcZni8wFB4LuslsF5HvLEwUk+xSQuPtp9c+NjnQGhDfTJZCcLUCrH87Z3crSWDOjXjtGPyycny/de3EoS3oi3R6V9hrio+TKC6Jx6+kdSh/8MiLY1bmXjnUqoJ08RYCcKktUQKAC/+cHDgdSxtEGsfGMXrczby6Mcr+Gb3obgbYk16uylsXATArASmFXfrkVSZVEzOF85KECat+acD79ehSULnx9pIfdnxHfj09jNp17Re9INNjZaMcS+JVGk94jLSvDKpnokYLECYNNe7XWPe+9mp3HZWj4TOl7C/gHZN8hgz8tgk5MynpTNzqjGVcZsCJHjSw1SxAGHSXq+2jSuMiYhVeAnii7Fnc/PpR2eWb9M4dMLAeN/lk9vPTChfpm752b/mVUhbXVy1ZWeTwdogTJ0WKa5kCNTPyeL9n8e+9rWbLGsFN2nMShCmTovUBrHqD+ex8O7hNK0fexVRf5d2kOzM2P/E7r6gd/SDosjOtIBkkscChKnTIrVRi0jcYyTe/skp/OjU0Bln46n6unhg5bOMxqJZHAHNmGgsQJg6LdlTbXTNT3wFu2QM2qsLK+iZ6mMBwtRpcQcI5/Ch3Vsw1unt1LR+dlJGsiba0O538YB2FdbMMKYqLECYOi3Re/I9Fx4XWHgmOMgEX+6l6wcTj8wqliD6tG9Cw9z063fSu23jVGch7Xk1gZ8FCFOnJV6tI4H2i5AAEXS5U3vkA/DRr04PWWs50k08I8JfY7f8BkD0Ekasi/jUNA1y45/4zoS69InPPQkSFiBMnbf2gVH8Ytgx3Hler7jOC6xFHHTfvrC/r1QR3KOpW37DwNrY7952CicUNHO9XqQSxE2n+cZlXDqwPZ2a14+Yn8wMAstfJuLVG4Ywqm/bhM9389TVg6Iek5tlAaKq5m/cHfPyrfFIv/KoMR742bD4R2L758oJfrKvl5MZtT3C7c944k9PiVxCEP/7ue9+6urjea1oA9ecVFClaSREJOIqbH4jjmvD+4u/qfSYYB0rCWh+iUx8Z0JdNKAdWXF0qY6VfTPGJEQDASKWhu7fjOhJ0/rZdM1v4Drt83HtmkSs7vJfP9LNe0SfNjx33QnkZWdyKM4J4ULfJ/oMopGqwcJdcUJHXv3REI5rF32OrJ5tGsV2URPRDad09eS6ngYIERkhIstEZKWIjHHZf52IFIvIPOfnhqB914rICufnWi/zaUysgm/h/ht9LM0YZ/Rsxby7hlM/J4ubTo/vj9l/+VhqEKoy02xGDC32sU5B3bNNI07u1jKmYxvnZdPLaai+/hTve2E1rZ/t+XtUt1yPSmGeBQgRyQQeB0YCvYHRIuI2VPTfqjrA+XnWObc5MA4YAgwGxomIe8WtMSnSrIFvUNpVQzrHdd7J3VoyenDHmI/3P7XHUsecyEpnfkLkUopftP3gm0792pMKYn7fMtVAyaegZYMK+396VnfX8/yN9/HKd9Yur01ys9IsQOC7sa9U1dWqehj4F3BRjOeeC0xR1R2quhOYAozwKJ/GxOyO83rRokEOHZrVp2FuFmv+eB43x1kiALj3oj58t7ADEHoDHNardYUShn/Zzlg6qYzs04Y/X96fws5Hn6f6tI+tG6mIRH2PWPJw2jH5MZVGAtcsVw4e9gWIRi49vDo0c2/H+Mc1hYH2i0X3nMvX941gzR/Pq/S93vvZqbVyHXKvGvq9DBDtgQ1B2xudtHDfEZEFIvK6iPgfq2I915hqdXav1sz53TnkZfv+IBOZkgN8czR1dG58wffcZ68tZOzIXvzzBycE0hrX8900W8bw5CsiXHZ8B7KcOZle/dEQ3rn1lMD+N358UsRzMyR6NZYXPWXKyuGgU4JolOfSbybCrzcrI4PHRg9icEFzGuRkkpedGfW76JbfMKFFpmq6dCxBxOJ/QIGq9sNXSngh3guIyI0iUiQiRcXFxUnPoDFekUDvpIo33TN7tgp5/dBl/fjNiJ4xXzv4ksFP88d3bl5JfmJog6hCfMjMELIzJVBy8mvZKCcQIBq4lCAi5SozUxjWuzX/ufmkmIN0dmZiAb2mS7s2CGATEFzR2sFJC1DV7apa4mw+Cxwf67lB13hGVQtVtTA/Pz8pGTemOvhvVNEeykWEyws7BkotAA9c2pfbzurOdwZ1qOTMo9VTMeXHl5sK6Y+OHshlx/ve51inx9G5x7WO+bp+2ZnCit+fx4OX9Q+kPXHVIEaf0IlTu/satBvkVAwQkaqEshMYBi8icY+eT9YMuW7tQ8HjWv5yef8K+2OV40EXV/B2HMSXQA8R6YLv5n4FcGXwASLSVlW3OJsXAkud15OBPwQ1TA8HxnqYV2Oq3dESRPznDunagi4uDbp+/qVR4xmlnBGhDeKC/u34av0uAJo3yGHtA6NQVYb99VNWBS1q8+RVgyqd3ryXy5Qa5zkD8x6/ahBb95Swt6TiKmqRutYmOndVvAWIzAyJa5T6iV2bM9NlzWq3t21aP5sOzVrwxartnNIjtNfXWce24uOvt8b0nl6MgQAPA4SqlorIT/Dd7DOB8aq6WETuBYpU9R3gpyJyIVAK7ACuc87dISL34QsyAPeqavyrhBtTg0ngmd395tOyYU7EEkK0e9z9F/fhjJ759OvQFPDd5KJNxSASuY0h/KYqIrRunBcSIM48tlVIKSfcP687IeK+vOxMOrWoz5LNeyrsi1SCyIp1UEaM14sk3jmyfj28J5c9NSOm983LzuTxKwcxY/V2WoetXhhrPi/o3y6u/MXD05HUqjoJmBSWdlfQ67FEKBmo6nhgvJf5MyaVAg/AEe7bRb89J+FrN8jNCkwmCDB/3PAKbR31czI5cPjowLq87MyInVjdxmKEx5JoN7RYFl8Kv+efUNCMM4892h7TqXl91u84APjaIBLhP+uBS/sy5s2FABzfuRnb95WwdvuBCsdfMqg9L89cH/P1I/Uocvv11MvOpFmDnEBJKlishYLSKkyvEk2qG6mNqbO+c3wHjmvXmGtOLvD8vRrmZgXmg/Jbcu8IVv3hPJ69ppC/XN6f7q0aRmwP8d/cgks74SWfZKyuGt5m8trNJ4fke1zQqnuRlnP1t5eEL97kl+uUcoJHcL/x45MrVPEAFP12GPdc2KdCer2gklJ477KsCIHLretvZeNWYq1C83KSRgsQxqRIy4a5TPzpqbRvWi/6wWGS1REnM8PXE+g7zk012q2mshJEVdezgPg+V6QA8efL+7P2gVHcOcp9Cde/fW8AN53Wlf4dmpLfKLfS3mFN62W7fq6h3VsEAsPrN4d2HY5UknJLv7wwcieDyqrrgpXFOrw9ATZZnzF1zD+vO4Gtew+57ovcBlGxj1P4ocnoPhpPjEk0ILVrWo+xzsy9X945LMH3kECACr/xRyoVhF+pskkdbzmjGzee1pU357p23uSFHw7m5ZnrmLLkW0o9WgsCLEAYU+cE1+mH+/3FfRnx92k0q5/Dpl0HA+mtGvmelpt7vuZ1HN1yq2E8Q2Xv4Q8eIvDFmLNokJvFjv2HaRI019PIPm04uVsLfvf24pBrBVeVufnNiGMr3X/6MflkZwhTlnxbpSneo7EAYYwJ6NSiPkvu9c1qUzBmYiD9B0O70KJhDhf1P9rwHcu8TPGKVijwMibEO0jc36BerkrHpr7xDE3qZbOvpDRwzPdP7Eyrxr7gGpz3SEvDvv/zU0M6DoS8n4R2ifZ3ZR5cEHnwY1VZgDDGRJWZIVwyMLS+PNaajT7tG7NoU8Xuq278T9kNc7NClmx97MqBfLFqO8e28Y2lOK9vm9je3EP+7q/h3YeDu8VmZkigCiqWGjH/53Oz+o+jQoJ2QcsGfHr7GRHnqkoGCxDGmITEOi/TW7cMjXk5TP89tEXDHAZ2Ojrh4Pn92nF+P19//2gLMrkJf/pOBn+vpPDuw8ElhazMowEinlHtsercIrEZbWNlvZiMMQmJ9X6bnZkRc4+cwLWTfDNfePe5LLrn3EqPudQZlFjZsqv+m39edkZg5tnK8pqZkZHWs8daCcIYE1Gk9bMh+TdxSH4bw61ndmPC7A2ukwCGO75zs8A0In863I8Dh4+2JUz40YlkZwrHtWvCk5+s5AdDu3DwSBmvFW2ke6uGIdcJ7n7booHXjfresgBhjHE1765zKn3y79yiPvM27ErqeyY76Nx+7rHcfm7lPYLCiQgNc7NoGBRUTurWIvD6l8N94yaa4b6WeVZmBh/84jT2HiqlY/P6gd5gXjTqe80ChDHGVbSpMf5wSV8u6NeO5g1zmLtuZzXlKj0c0/roKO2qjB9897ZTOP/R6QnNnpsMFiCMSSPHd27G+h0HYqoy8VqD3CyG9fbduAZ1in9FYLcbZxpX13uiT/smCTXKJ0vq/5cZY2L2x0v7csOpXWJaXa4mW3j3cNfGWy/aNWqKZPRiysvOoGm96mvXsABhTBrJy87kuHZNUp2NKmsUNnGgic2iuyvviZVsFiCMMTVGba5iSkYjtVcLA0Vi4yCMMcZDXgyQqy4WIIwxxkP+Na3bJTCte6pZFZMxxnioRcNcHrtyICd1bcFHS7fSu13k+ZZqGgsQxhjjMf88Ut89oWOKcxIfq2IyxtQY/q6vedl2a6oJrARhjKkxOjSrx6/OOYaLB7aPfrDxnKdhWkRGiMgyEVkpImNc9v9SRJaIyAIR+UhEOgftKxORec7PO17m0xhTM4gIt53dg47NvVvjwMTOsxKEiGQCjwPnABuBL0XkHVVdEnTYV0Chqh4QkR8DDwLfc/YdVNUBXuXPGGNM5bwsQQwGVqrqalU9DPwLuCj4AFWdqqoHnM2ZQAeMMcbUCF4GiPbAhqDtjU5aJNcD7wVt54lIkYjMFJGLvcigMcaYyGpEI7WIXA0UAqcHJXdW1U0i0hX4WEQWquoql3NvBG4E6NSpU7Xk1xhj6gIvSxCbgOBOvx2ctBAiMgy4E7hQVUv86aq6yfl3NfAJMNDtTVT1GVUtVNXC/Pz85OXeGGPqOC8DxJdADxHpIiI5wBVASG8kERkIPI0vOGwNSm8mIrnO65bAUCC4cdsYY4zHPKtiUtVSEfkJMBnIBMar6mIRuRcoUtV3gIeAhsBr4hsgs15VLwR6AU+LSDm+IPZAWO8nY4wxHhOtRSt0FBYWalFRUaqzYYwxaUNE5qhqoeu+2hQgRKQYWJfg6S2BbUnMTjqwz1w32Geu/aryeTurqmsDbq0KEFUhIkWRomhtZZ+5brDPXPt59XltRixjjDGuLEAYY4xxZQHiqGdSnYEUsM9cN9hnrv08+bzWBmGMMcaVlSCMMca4qvMBItqaFelKRDqKyFRnvY3FIvIzJ725iEwRkRXOv82cdBGRR5zfwwIRGZTaT5A4EckUka9E5F1nu4uIzHI+27+dkf2ISK6zvdLZX5DKfCdKRJqKyOsi8rWILBWRk2r79ywiv3D+Xy8SkQkiklfbvmcRGS8iW0VkUVBa3N+riFzrHL9CRK6NJw91OkAErVkxEugNjBaR3qnNVdKUAr9S1d7AicCtzmcbA3ykqj2Aj5xt8P0Oejg/NwJPVn+Wk+ZnwNKg7T8BD6tqd2AnvpmDcf7d6aQ/7ByXjv4OvK+qxwL98X32Wvs9i0h74Kf41pLpg2+mhiuofd/z88CIsLS4vlcRaQ6MA4bgW4JhnD+oxERV6+wPcBIwOWh7LDA21fny6LO+jW/xpmVAWyetLbDMef00MDro+MBx6fSDb1LIj4CzgHcBwTeAKCv8O8c3DcxJzuss5zhJ9WeI8/M2AdaE57s2f88cXUqgufO9vQucWxu/Z6AAWJTo9wqMBp4OSg85LtpPnS5BEP+aFWnJKVIPBGYBrVV1i7PrG6C187q2/C7+BvwGKHe2WwC7VLXU2Q7+XIHP7Ozf7RyfTroAxcA/nWq1Z0WkAbX4e1bfTM9/BtYDW/B9b3Oo3d+zX7zfa5W+77oeIGo9EWkIvAH8XFX3BO9T3yNFrenGJiLnA1tVdU6q81KNsoBBwJOqOhDYz9FqB6BWfs/N8K1O2QVoBzSgYlVMrVcd32tdDxAxrVmRrkQkG19weEVV33SSvxWRts7+toB/mvXa8LsYClwoImvxLXF7Fr76+aYi4p+5OPhzBT6zs78JsL06M5wEG4GNqjrL2X4dX8Cozd/zMGCNqhar6hHgTXzffW3+nv3i/V6r9H3X9QARdc2KdCUiAjwHLFXVvwbtegfw92S4Fl/bhD/9Gqc3xInA7qCibFpQ1bGq2kFVC/B9lx+r6lXAVOAy57Dwz+z/XVzmHJ9WT9qq+g2wQUR6Okln41s7pdZ+z/iqlk4UkfrO/3P/Z66133OQeL/XycBw8a2x0wwY7qTFJtWNMKn+Ac4DlgOrgDtTnZ8kfq5T8BU/FwDznJ/z8NW9fgSsAD4EmjvHC74eXauAhfh6iKT8c1Th858BvOu87grMBlYCrwG5Tnqes73S2d811flO8LMOAIqc7/q/QLPa/j0D9wBfA4uAl4Dc2vY9AxPwtbEcwVdSvD6R7xX4ofPZVwI/iCcPNpLaGGOMq7pexWSMMSYCCxDGGGNcWYAwxhjjygKEMcYYVxYgjDHGuLIAYYwxxpUFCGOSzBms9LGINK7kmAEiMsOZsnqBiHwvaF+kaat/IiI/rI7PYAzYinLGVCAid+ObIt0/8VsWMNN5XSFdVe8OO38UMExVf1HJexyDbzqdFSLSDt9kc71UdZeI/Ad4U1X/JSJPAfNV9UkRqQ98rr45l4zxnJUgjHF3haqer6rn45u2I1p6sKtwpkAQkROcEkKeiDRwSgx9VHW5qq4AUNXN+ObUyXemjjgL35xKAC8AFzvHHQDWisjgZH9YY9xYgDAm+YbiKxGgql/imyfnfuBB4GVVXRR8sHPDz8E3TUJl05ODb0qNUz3NvTGOrOiHGGPi1FxV9wZt34tvYshD+FZCC3Bm5HwJuFZVy30FiEptBY5NYl6NichKEMYkX6mIBP9ttQAaAo3wTRwHgNOIPRHfJJH+No7tRJ62Guf8g15l3JhgFiCMSb5l+GYW9Xsa+B3wCs56yE7PpLeAF1XV396A+nqNRJq2GuAYfDOYGuM5CxDGJN9EfNONIyLXAEdU9VXgAeAEETkL+C5wGnCdiMxzfgY45/8f8EsRWYmv9PFc0LWHAlOq52OYus7aIIxJvmeBF4FnVfVF5zWqWgYMCTruZbeTVXU1UKGnkogMBBararquhmbSjAUIYyraCrwoIuXOdgbwvvM6UnqAqm4RkX+ISGMNWwe8ilriq6oyplrYQDljjDGurA3CGGOMKwsQxhhjXFmAMMYY48oChDHGGFcWIIwxxrj6f3LJPU75gYbQAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "you [ 1.185  0.944 -1.085 -1.382 -1.142]\n",
            "say [-1.215 -1.214  1.218 -0.367  0.538]\n",
            "goodbye [ 0.773  1.054 -0.933 -0.524 -0.689]\n",
            "and [-1.058 -1.079  1.061  1.708  1.574]\n",
            "i [ 0.775  1.065 -0.923 -0.513 -0.692]\n",
            "hello [ 1.173  0.957 -1.091 -1.389 -1.151]\n",
            ". [-1.007 -1.029  1.    -1.404 -1.54 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atVvpOzmg1fX"
      },
      "source": [
        "#4장"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sx-7qbXCg4g0"
      },
      "source": [
        "##4.1.2 Embedding 계층 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlBLYQuTxl37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "47a0d597-d667-42a0-fc98-11aab6f90189"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "W = np.arange(21).reshape(7, 3)\n",
        "print(W)\n",
        "print('\\n')\n",
        "# 행렬에서 한 행 추출\n",
        "print(W[2])\n",
        "print('\\n')\n",
        "print(W[5])\n",
        "print('\\n')\n",
        "# 행렬에서 여러 행을 추출\n",
        "idx = np.array([1, 0, 3, 0])\n",
        "print(W[idx])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  1  2]\n",
            " [ 3  4  5]\n",
            " [ 6  7  8]\n",
            " [ 9 10 11]\n",
            " [12 13 14]\n",
            " [15 16 17]\n",
            " [18 19 20]]\n",
            "\n",
            "\n",
            "[6 7 8]\n",
            "\n",
            "\n",
            "[15 16 17]\n",
            "\n",
            "\n",
            "[[ 3  4  5]\n",
            " [ 0  1  2]\n",
            " [ 9 10 11]\n",
            " [ 0  1  2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5o9SVjYMhZIy"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class Embedding:\n",
        "  def __init(self, W):\n",
        "    self.params = [W]\n",
        "    self.grads = [np.zeros_like(W)]\n",
        "    self.idx = None\n",
        "  \n",
        "  def forward(self, idx):\n",
        "    W,  = self.params\n",
        "    self.idx = idx\n",
        "    out = W[idx]\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    '''dW,  = self.grads\n",
        "    dW[...] = 0\n",
        "    dW[self.idx] = dout #실은 나쁜 예\n",
        "    return None'''\n",
        "\n",
        "    dW, = self.grads\n",
        "    dW[...] = 0\n",
        "\n",
        "    for i, word_id in enumerate(self.idx):      # i 에는 인덱스 값을 주고, word_id에는 그 값을 준다\n",
        "      #dW[word_id] += dout[i]\n",
        "\n",
        "    #또는\n",
        "       np.add.at(dW, self.idx, dout)        # dout을 dW의 self.idx번째 행에 더해준다.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-o4JCeVvC2T"
      },
      "source": [
        "##4.2.4 다중 분류에서 이진 분류로(구현)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9seGJHxitjA"
      },
      "source": [
        "class EmbeddingDot:\n",
        "  def __init__(self, W):\n",
        "    self.embed = Embedding(W)\n",
        "    self.params = self.embed.params\n",
        "    self.grads = self.embed.grads\n",
        "    self.cache = None\n",
        "\n",
        "  def forward(self, h, idx):\n",
        "    target_W = self.embed.forward(idx)\n",
        "    out = np.sum(target_W * h, axis=1)\n",
        "\n",
        "    self.cache = (h, target_W)\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    h, target_W = self.cache\n",
        "    dout = dout.reshape(dout.shape[0], 1)   #dout.shape[0]은 행의 갯수\n",
        "\n",
        "    dtarget_W = dout * h\n",
        "    self.embed.backward(dtarget_W)\n",
        "    dh = dout * target_W\n",
        "    return dh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-uNBvafzK_M"
      },
      "source": [
        "##4.2.6 네거티브 샘플링의 샘플링 기법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vIo0G0Hwi0B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "ca4497db-0f1c-4f62-b02b-038c2304adba"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# 0에서 9까지의 숫자 중 하나를 무작위로 샘플링\n",
        "print(np.random.choice(10))\n",
        "\n",
        "# words에서 하나만 무작위로 샘플링\n",
        "words = ['you', 'say', 'goodbye', 'I', 'hello', '.']\n",
        "print(np.random.choice(words))\n",
        "\n",
        "# 5개만 무작위로 샘플링(중복있음)\n",
        "print(np.random.choice(words, size=5))\n",
        "\n",
        "# 5개만 무작위로 샘플링(중복없음)\n",
        "print(np.random.choice(words, size=5, replace=False))\n",
        "\n",
        "# 확률 분포에 따라 샘플링\n",
        "p = [0.5, 0.1, 0.05, 0.2, 0.05, 0.1]\n",
        "print(np.random.choice(words, p=p))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "you\n",
            "['you' '.' 'hello' 'say' 'hello']\n",
            "['goodbye' '.' 'say' 'I' 'you']\n",
            "you\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmzW48w2ooqQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4b3f1a71-690d-42c4-bdcd-5fa012c9b804"
      },
      "source": [
        "p = [0.7, 0.29, 0.01]\n",
        "new_p = np.power(p, 0.75)\n",
        "new_p /= np.sum(new_p)\n",
        "print(new_p)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.64196878 0.33150408 0.02652714]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdDjPs9SsL5S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "ba78087d-2423-4a30-fad6-7e0cf41f8180"
      },
      "source": [
        "import numpy as np\n",
        "import sys,os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append('os.chdir')\n",
        "\n",
        "from ch04.negative_sampling_layer import UnigramSampler\n",
        "\n",
        "corpus = np.array([0, 1, 2, 3, 4, 1, 2, 3])\n",
        "power = 0.75\n",
        "sample_size = 2\n",
        "\n",
        "sampler = UnigramSampler(corpus, power, sample_size)\n",
        "target = np.array([1, 3, 0])\n",
        "negative_sample = sampler.get_negative_sample(target)\n",
        "print(negative_sample)\n",
        "print(negative_sample[:, 0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2 4]\n",
            " [2 1]\n",
            " [2 3]]\n",
            "[2 2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCseVFfls5C5"
      },
      "source": [
        "class NegativesamplingLoss:\n",
        "  def __init__(self, W, corpus, powert=0.75, sample_size=5):\n",
        "    self.sample_size = sample_size\n",
        "    self.sampler = UnigramSampler(corpus, power, sample_size)\n",
        "    self.loss_layers = [SigmoidWithLoss() for _ in range(sample_size +1)]\n",
        "    self.embed_dot_layers = [EmbeddingDot(W) for _ in range(sample_size + 1)]\n",
        "    self.params, self.grads = [], []\n",
        "\n",
        "    for layer in self.embed_dot_layers:\n",
        "      self.params += layer.params\n",
        "      self.grads += layer.grads\n",
        "\n",
        "  def forward(self, h, target):\n",
        "    batch_size = target.shape[0]\n",
        "    negative_sample = sampleer.get_negative_sample(target)\n",
        "\n",
        "    # 긍정적 예 순전파\n",
        "    score = self.embed_dot_layers[0].forward(h,target)\n",
        "    correct_label = np.ones(batch_size, dtype=np.int32)\n",
        "    loss = self.loss_layers[0].forward(score, correct_label)\n",
        "\n",
        "    # 부정적 예 순전파\n",
        "    negative_label = np.zeros(batch_size, dtype=np.int32)\n",
        "    for i in range(self.sample_size):\n",
        "      negative_target = negative_sample[:, i]\n",
        "      score = self.embed_dot_layers[1 + i].forward(h, negative_target)\n",
        "      loss += self.loss_layer[1 + i].forward(score, negative_label)\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "  def backward(self, dout=1):\n",
        "    dh = 0\n",
        "    for l0, l1 in zip(self.loss_layers, self.embed_dot_layers):\n",
        "      dscore = l0.backward(dout)\n",
        "      dh += l1.backward(dscore)\n",
        "\n",
        "    return dh\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbPafraXGS_P"
      },
      "source": [
        "##4.3.1 CBOW 모델 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3cvnNPvGLdb"
      },
      "source": [
        "import sys,os\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append('os.chdir')\n",
        "\n",
        "from common.np import *  # import numpy as np\n",
        "from common.layers import Embedding\n",
        "from ch04.negative_sampling_layer import NegativeSamplingLoss\n",
        "\n",
        "\n",
        "class CBOW:\n",
        "    def __init__(self, vocab_size, hidden_size, window_size, corpus):\n",
        "        V, H = vocab_size, hidden_size\n",
        "\n",
        "        # 가중치 초기화\n",
        "        W_in = 0.01 * np.random.randn(V, H).astype('f')\n",
        "        W_out = 0.01 * np.random.randn(V, H).astype('f')\n",
        "\n",
        "        # 계층 생성\n",
        "        self.in_layers = []\n",
        "        for i in range(2 * window_size):\n",
        "            layer = Embedding(W_in)  # Embedding 계층 사용\n",
        "            self.in_layers.append(layer)\n",
        "        self.ns_loss = NegativeSamplingLoss(W_out, corpus, power=0.75, sample_size=5)\n",
        "\n",
        "        # 모든 가중치와 기울기를 배열에 모은다.\n",
        "        layers = self.in_layers + [self.ns_loss]\n",
        "        self.params, self.grads = [], []\n",
        "        for layer in layers:\n",
        "            self.params += layer.params\n",
        "            self.grads += layer.grads\n",
        "\n",
        "        # 인스턴스 변수에 단어의 분산 표현을 저장한다.\n",
        "        self.word_vecs = W_in\n",
        "\n",
        "    def forward(self, contexts, target):\n",
        "        h = 0\n",
        "        for i, layer in enumerate(self.in_layers):\n",
        "            h += layer.forward(contexts[:, i])\n",
        "        h *= 1 / len(self.in_layers)\n",
        "        loss = self.ns_loss.forward(h, target)\n",
        "        return loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        dout = self.ns_loss.backward(dout)\n",
        "        dout *= 1 / len(self.in_layers)\n",
        "        for layer in self.in_layers:\n",
        "            layer.backward(dout)\n",
        "        return None\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-XxPexaJmpQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        },
        "outputId": "f175cb9d-ac6e-4889-bb5c-4e8720f55776"
      },
      "source": [
        "import sys,os\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append('os.chdir')\n",
        "\n",
        "import numpy as np\n",
        "from common import config\n",
        "# GPU에서 실행하려면 아래 주석을 해제하세요(CuPy 필요).\n",
        "# ===============================================\n",
        "# config.GPU = True\n",
        "# ===============================================\n",
        "import pickle\n",
        "from common.trainer import Trainer\n",
        "from common.optimizer import Adam\n",
        "from ch04.cbow import CBOW\n",
        "from ch04.skip_gram import SkipGram\n",
        "from common.util import create_contexts_target, to_cpu, to_gpu\n",
        "from dataset import ptb\n",
        "\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "window_size = 5\n",
        "hidden_size = 100\n",
        "batch_size = 100\n",
        "max_epoch = 10\n",
        "\n",
        "# 데이터 읽기\n",
        "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
        "vocab_size = len(word_to_id)\n",
        "\n",
        "contexts, target = create_contexts_target(corpus, window_size)\n",
        "if config.GPU:\n",
        "    contexts, target = to_gpu(contexts), to_gpu(target)\n",
        "\n",
        "# 모델 등 생성\n",
        "model = CBOW(vocab_size, hidden_size, window_size, corpus)\n",
        "# model = SkipGram(vocab_size, hidden_size, window_size, corpus)\n",
        "optimizer = Adam()\n",
        "trainer = Trainer(model, optimizer)\n",
        "\n",
        "# 학습 시작\n",
        "trainer.fit(contexts, target, max_epoch, batch_size)\n",
        "trainer.plot()\n",
        "\n",
        "# 나중에 사용할 수 있도록 필요한 데이터 저장\n",
        "word_vecs = model.word_vecs\n",
        "if config.GPU:\n",
        "    word_vecs = to_cpu(word_vecs)\n",
        "params = {}\n",
        "params['word_vecs'] = word_vecs.astype(np.float16)\n",
        "params['word_to_id'] = word_to_id\n",
        "params['id_to_word'] = id_to_word\n",
        "pkl_file = 'cbow_params.pkl'  # or 'skipgram_params.pkl'\n",
        "with open(pkl_file, 'wb') as f:\n",
        "    pickle.dump(params, f, -1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| 에폭 1 |  반복 1 / 9295 | 시간 0[s] | 손실 4.16\n",
            "| 에폭 1 |  반복 21 / 9295 | 시간 1[s] | 손실 4.16\n",
            "| 에폭 1 |  반복 41 / 9295 | 시간 3[s] | 손실 4.15\n",
            "| 에폭 1 |  반복 61 / 9295 | 시간 4[s] | 손실 4.12\n",
            "| 에폭 1 |  반복 81 / 9295 | 시간 6[s] | 손실 4.04\n",
            "| 에폭 1 |  반복 101 / 9295 | 시간 7[s] | 손실 3.92\n",
            "| 에폭 1 |  반복 121 / 9295 | 시간 8[s] | 손실 3.77\n",
            "| 에폭 1 |  반복 141 / 9295 | 시간 10[s] | 손실 3.62\n",
            "| 에폭 1 |  반복 161 / 9295 | 시간 11[s] | 손실 3.48\n",
            "| 에폭 1 |  반복 181 / 9295 | 시간 13[s] | 손실 3.37\n",
            "| 에폭 1 |  반복 201 / 9295 | 시간 14[s] | 손실 3.26\n",
            "| 에폭 1 |  반복 221 / 9295 | 시간 16[s] | 손실 3.13\n",
            "| 에폭 1 |  반복 241 / 9295 | 시간 17[s] | 손실 3.07\n",
            "| 에폭 1 |  반복 261 / 9295 | 시간 19[s] | 손실 3.02\n",
            "| 에폭 1 |  반복 281 / 9295 | 시간 20[s] | 손실 2.94\n",
            "| 에폭 1 |  반복 301 / 9295 | 시간 22[s] | 손실 2.91\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-3b066c6c22bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# 학습 시작\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/common/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, t, max_epoch, batch_size, max_grad, eval_interval)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;31m# 기울기 구해 매개변수 갱신\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 공유된 가중치를 하나로 모음\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/ch04/cbow.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, contexts, target)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontexts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mns_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/ch04/negative_sampling_layer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, h, target)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mnegative_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_negative_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# 긍정적 예 순전파\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/ch04/negative_sampling_layer.py\u001b[0m in \u001b[0;36mget_negative_sample\u001b[0;34m(self, target)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mp\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0mnegative_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;31m# GPU(cupy）로 계산할 때는 속도를 우선한다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqANFyE4Nlki"
      },
      "source": [
        "##4.3.3 CBOW 모델 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vxp7dD8gJpfW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "613b42d1-20fc-487d-ec9b-75137f4e37ac"
      },
      "source": [
        "import sys,os\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append('os.chdir')\n",
        "\n",
        "\n",
        "from common.util import most_similar, analogy\n",
        "import pickle\n",
        "\n",
        "\n",
        "pkl_file = '/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/ch04/cbow_params.pkl'\n",
        "\n",
        "\n",
        "with open(pkl_file, 'rb') as f:\n",
        "    params = pickle.load(f)\n",
        "    word_vecs = params['word_vecs']\n",
        "    word_to_id = params['word_to_id']\n",
        "    id_to_word = params['id_to_word']\n",
        "\n",
        "# 가장 비슷한(most similar) 단어 뽑기\n",
        "querys = ['you', 'year', 'car', 'toyota']\n",
        "for query in querys:\n",
        "    most_similar(query, word_to_id, id_to_word, word_vecs, top=5)\n",
        "\n",
        "# 유추(analogy) 작업\n",
        "print('-'*50)\n",
        "analogy('king', 'man', 'queen',  word_to_id, id_to_word, word_vecs)\n",
        "analogy('take', 'took', 'go',  word_to_id, id_to_word, word_vecs)\n",
        "analogy('car', 'cars', 'child',  word_to_id, id_to_word, word_vecs)\n",
        "analogy('good', 'better', 'bad',  word_to_id, id_to_word, word_vecs)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[query] you\n",
            " we: 0.6103515625\n",
            " someone: 0.59130859375\n",
            " i: 0.55419921875\n",
            " something: 0.48974609375\n",
            " anyone: 0.47314453125\n",
            "\n",
            "[query] year\n",
            " month: 0.71875\n",
            " week: 0.65234375\n",
            " spring: 0.62744140625\n",
            " summer: 0.6259765625\n",
            " decade: 0.603515625\n",
            "\n",
            "[query] car\n",
            " luxury: 0.497314453125\n",
            " arabia: 0.47802734375\n",
            " auto: 0.47119140625\n",
            " disk-drive: 0.450927734375\n",
            " travel: 0.4091796875\n",
            "\n",
            "[query] toyota\n",
            " ford: 0.55078125\n",
            " instrumentation: 0.509765625\n",
            " mazda: 0.49365234375\n",
            " bethlehem: 0.47509765625\n",
            " nissan: 0.474853515625\n",
            "--------------------------------------------------\n",
            "\n",
            "[analogy] king:man = queen:?\n",
            " woman: 5.16015625\n",
            " veto: 4.9296875\n",
            " ounce: 4.69140625\n",
            " earthquake: 4.6328125\n",
            " successor: 4.609375\n",
            "\n",
            "[analogy] take:took = go:?\n",
            " went: 4.55078125\n",
            " points: 4.25\n",
            " began: 4.09375\n",
            " comes: 3.98046875\n",
            " oct.: 3.90625\n",
            "\n",
            "[analogy] car:cars = child:?\n",
            " children: 5.21875\n",
            " average: 4.7265625\n",
            " yield: 4.20703125\n",
            " cattle: 4.1875\n",
            " priced: 4.1796875\n",
            "\n",
            "[analogy] good:better = bad:?\n",
            " more: 6.6484375\n",
            " less: 6.0625\n",
            " rather: 5.21875\n",
            " slower: 4.734375\n",
            " greater: 4.671875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RFYCkRUh0IE"
      },
      "source": [
        "#5장 순환 신경망(RNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRmkwXchh7hR"
      },
      "source": [
        "##5.3.1 RNN 계층구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzqBghuH3TWR"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class RNN:\n",
        "    def __init__(self, Wx, Wh, b):\n",
        "        self.params = [Wx, Wh, b]\n",
        "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
        "        self.cache = None\n",
        "\n",
        "    def forward(self, x, h_prev):\n",
        "        Wx, Wh, b = self.params\n",
        "        t = np.dot(h_prev, Wh) + np.dot(x, Wx) + b\n",
        "        h_next = np.tanh(t)\n",
        "\n",
        "        self.cache = (x, h_prev, h_next)\n",
        "        return h_next\n",
        "\n",
        "    def backward(self, dh_next):\n",
        "        Wx, Wh, b = self.params\n",
        "        x, h_prev, h_next = self.cache\n",
        "\n",
        "        dt = dh_next * (1 - h_next ** 2)\n",
        "        db = np.sum(dt, axis=0)\n",
        "        dWh = np.dot(h_prev.T, dt)\n",
        "        dh_prev = np.dot(dt, Wh.T)\n",
        "        dWx = np.dot(x.T, dt)\n",
        "        dx = np.dot(dt, Wx.T)\n",
        "\n",
        "        self.grads[0][...] = dWx\n",
        "        self.grads[1][...] = dWh\n",
        "        self.grads[2][...] = db\n",
        "\n",
        "        return dx, dh_prev\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce2-PsQLkyvx"
      },
      "source": [
        "##5.3.2 Time RNN 계층 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aJVoIl0kaTG"
      },
      "source": [
        "class TimeRNN:\n",
        "    def __init__(self, Wx, Wh, b, stateful=False):\n",
        "        self.params = [Wx, Wh, b]\n",
        "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
        "        self.layers = None\n",
        "\n",
        "        self.h, self.dh = None, None\n",
        "        self.stateful = stateful\n",
        "\n",
        "    def set_state(self, h):\n",
        "        self.h = h\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.h = None\n",
        "\n",
        "\n",
        "    def forward(self, xs):\n",
        "        Wx, Wh, b = self.params\n",
        "        N, T, D = xs.shape\n",
        "        D, H = Wx.shape\n",
        "\n",
        "        self.layers = []\n",
        "        hs = np.empty((N, T, H), dtype='f')\n",
        "\n",
        "        if not self.stateful or self.h is None:\n",
        "            self.h = np.zeros((N, H), dtype='f')\n",
        "\n",
        "        for t in range(T):\n",
        "            layer = RNN(*self.params)\n",
        "            self.h = layer.forward(xs[:, t, :], self.h)\n",
        "            hs[:, t, :] = self.h\n",
        "            self.layers.append(layer)\n",
        "\n",
        "        return hs\n",
        "\n",
        "    def backward(self, dhs):\n",
        "        Wx, Wh, b = self.params\n",
        "        N, T, H = dhs.shape\n",
        "        D, H = Wx.shape\n",
        "\n",
        "        dxs = np.empty((N, T, D), dtype='f')\n",
        "        dh = 0\n",
        "        grads = [0, 0, 0]\n",
        "        for t in reversed(range(T)):\n",
        "            layer = self.layers[t]\n",
        "            dx, dh = layer.backward(dhs[:, t, :] + dh)\n",
        "            dxs[:, t, :] = dx\n",
        "\n",
        "            for i, grad in enumerate(layer.grads):\n",
        "                grads[i] += grad\n",
        "\n",
        "        for i, grad in enumerate(grads):\n",
        "            self.grads[i][...] = grad\n",
        "        self.dh = dh\n",
        "\n",
        "        return dxs\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGFGR6ufs67t"
      },
      "source": [
        "##5.5.1 RNNLM 학습과 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1b4BCIrP9ZL"
      },
      "source": [
        "import sys,os\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append('os.chdir')\n",
        "\n",
        "import numpy as np\n",
        "from common.time_layers import *\n",
        "\n",
        "class SimpleRnnlm:\n",
        "  def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
        "    V, D, H = vocab_size, wordvec_size, hidden_size\n",
        "    rn = np.random.randn\n",
        "\n",
        "    #가중치 초기화\n",
        "    embed_W = (rn(V,D) / 100).astype('f')\n",
        "    rnn_Wx = (rn(D, H) / np.sqrt(D).astype('f')\n",
        "    rnn_Wh = (rn(H, H) / np.sqrt(H)).astype('f')\n",
        "    rnn_b = np.zeros(H).astype('f')\n",
        "\n",
        "    affine_W = (rn(H, V) / np.aqrt(H)).astype('f')\n",
        "    affine_b = np.zeros(V).astype('f')\n",
        "\n",
        "    #계층 생성\n",
        "    self.layers = {\n",
        "        TimeEmbedding(embed_W),\n",
        "        TimeRNN(rnn_Wx, rnn_Wh, rnn_b, stateful=True),\n",
        "        TimeAffine(affine_W, affine_b)\n",
        "    }\n",
        "    self.loss_layer = TimeSoftmaxWithLoss()\n",
        "    self.rnn_layer = self.layers[1]\n",
        "\n",
        "    #모든 가중치와 기울기를 리스트에 모은다.\n",
        "    self.params, self.grads = [], []\n",
        "    for layer in self.layers:\n",
        "      self.params += layer.params\n",
        "      self.grads += layer.grads\n",
        "\n",
        "\n",
        "    def forward(self, xs, ts):\n",
        "      for layer in self.layer:\n",
        "        xs = layer.forward(xs)\n",
        "      loss = self.loss_layer.forward(xs, ts)\n",
        "      return loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "      dout = self.loss_layer.backward(dout)\n",
        "      for layer in reversed(self.layers):\n",
        "        dout = layer.backward(dout)\n",
        "      return dout\n",
        "\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QrvJ7-Uc44s"
      },
      "source": [
        "##5.5.3 RNNNLM의 학습 코드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMcOm7CVdury",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "603a2d11-de20-4f94-906b-0737efe80478"
      },
      "source": [
        "import sys, os\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append('os.chdir')\n",
        "\n",
        "import numpy as np\n",
        "from common.optimizer import SGD\n",
        "from dataset import ptb\n",
        "from ch05.simple_rnnlm import SimpleRnnlm\n",
        "\n",
        "# 하이퍼파리미터 설정\n",
        "batch_size = 10\n",
        "wordvec_size = 100\n",
        "hidden_size = 100   # RNN의 은닉 상태 벡터의 원소 수\n",
        "time_size = 5     # Truncated BPTT가 한 번에 펼치는 시간 크기\n",
        "lr = 0.1\n",
        "max_epoch = 100\n",
        "\n",
        "# 학습 데이터 읽기(전체 중 1000개만)\n",
        "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
        "corpus_size = 1000\n",
        "corpus = corpus[:corpus_size]\n",
        "vocab_size = int(max(corpus) + 1)\n",
        "\n",
        "xs = corpus[:-1]    # 입력\n",
        "ts = corpus[1:]     # 출력(정답 레이블)\n",
        "data_size = len(xs)\n",
        "print(' 말뭉치 크기 : %d, 어휘 수 : %d' % (corpus_size, vocab_size))\n",
        "\n",
        "# 학습 시 사용하는 변수\n",
        "max_iters = data_size // (batch_size * time_size)\n",
        "time_idx = 0\n",
        "total_loss = 0\n",
        "loss_count = 0\n",
        "ppl_list = []\n",
        "\n",
        "# 모델 생성\n",
        "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
        "optimizer = SGD(lr)\n",
        "\n",
        "# 1 각 미니배치에서 샘플을 읽기 시작 위치를 계산\n",
        "jump = (corpus_size - 1) // batch_size\n",
        "offsets = [i * jump for i in range(batch_size) ]\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "  for iter in range(max_iters):\n",
        "    # 2 미니배치 획득\n",
        "    batch_x = np.empty((batch_size, time_size), dtype= 'i')\n",
        "    batch_t = np.empty((batch_size, time_size), dtype= 'i')\n",
        "    for t in range(time_size):\n",
        "      for i, offset in enumerate(offsets):\n",
        "        batch_x[i, t] = xs[(offset + time_idx) % data_size]\n",
        "        batch_t[i, t] = ts[(offset + time_idx) % data_size]\n",
        "\n",
        "      time_idx += 1 \n",
        "\n",
        "    # 기울기를 구하여 매개변수 갱신\n",
        "    loss = model.forward(batch_x, batch_t)\n",
        "    model.backward()\n",
        "    optimizer.update(model.params, model.grads)\n",
        "    total_loss += loss\n",
        "    loss_count += 1\n",
        "\n",
        "  # 3 에폭마다 퍼플렉서티 평가\n",
        "  ppl = np.exp(total_loss / loss_count)\n",
        "  print('| 에폭 %d | 퍼플렉서티 평가 %.2f' % (epoch+1, ppl))\n",
        "  ppl_list.append(float(ppl))\n",
        "  total_loss, loss_count = 0, 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 말뭉치 크기 : 1000, 어휘 수 : 418\n",
            "| 에폭 1 | 퍼플렉서티 평가 378.81\n",
            "| 에폭 2 | 퍼플렉서티 평가 248.06\n",
            "| 에폭 3 | 퍼플렉서티 평가 221.51\n",
            "| 에폭 4 | 퍼플렉서티 평가 213.44\n",
            "| 에폭 5 | 퍼플렉서티 평가 204.55\n",
            "| 에폭 6 | 퍼플렉서티 평가 202.56\n",
            "| 에폭 7 | 퍼플렉서티 평가 198.34\n",
            "| 에폭 8 | 퍼플렉서티 평가 196.55\n",
            "| 에폭 9 | 퍼플렉서티 평가 192.07\n",
            "| 에폭 10 | 퍼플렉서티 평가 192.30\n",
            "| 에폭 11 | 퍼플렉서티 평가 189.26\n",
            "| 에폭 12 | 퍼플렉서티 평가 191.53\n",
            "| 에폭 13 | 퍼플렉서티 평가 189.04\n",
            "| 에폭 14 | 퍼플렉서티 평가 189.48\n",
            "| 에폭 15 | 퍼플렉서티 평가 189.19\n",
            "| 에폭 16 | 퍼플렉서티 평가 185.20\n",
            "| 에폭 17 | 퍼플렉서티 평가 183.23\n",
            "| 에폭 18 | 퍼플렉서티 평가 179.56\n",
            "| 에폭 19 | 퍼플렉서티 평가 180.70\n",
            "| 에폭 20 | 퍼플렉서티 평가 181.48\n",
            "| 에폭 21 | 퍼플렉서티 평가 179.69\n",
            "| 에폭 22 | 퍼플렉서티 평가 174.84\n",
            "| 에폭 23 | 퍼플렉서티 평가 173.20\n",
            "| 에폭 24 | 퍼플렉서티 평가 173.96\n",
            "| 에폭 25 | 퍼플렉서티 평가 170.73\n",
            "| 에폭 26 | 퍼플렉서티 평가 170.19\n",
            "| 에폭 27 | 퍼플렉서티 평가 165.24\n",
            "| 에폭 28 | 퍼플렉서티 평가 163.66\n",
            "| 에폭 29 | 퍼플렉서티 평가 162.79\n",
            "| 에폭 30 | 퍼플렉서티 평가 155.15\n",
            "| 에폭 31 | 퍼플렉서티 평가 156.07\n",
            "| 에폭 32 | 퍼플렉서티 평가 152.47\n",
            "| 에폭 33 | 퍼플렉서티 평가 153.45\n",
            "| 에폭 34 | 퍼플렉서티 평가 145.22\n",
            "| 에폭 35 | 퍼플렉서티 평가 142.67\n",
            "| 에폭 36 | 퍼플렉서티 평가 140.14\n",
            "| 에폭 37 | 퍼플렉서티 평가 134.16\n",
            "| 에폭 38 | 퍼플렉서티 평가 132.70\n",
            "| 에폭 39 | 퍼플렉서티 평가 126.67\n",
            "| 에폭 40 | 퍼플렉서티 평가 121.15\n",
            "| 에폭 41 | 퍼플렉서티 평가 121.36\n",
            "| 에폭 42 | 퍼플렉서티 평가 113.75\n",
            "| 에폭 43 | 퍼플렉서티 평가 109.58\n",
            "| 에폭 44 | 퍼플렉서티 평가 106.56\n",
            "| 에폭 45 | 퍼플렉서티 평가 102.80\n",
            "| 에폭 46 | 퍼플렉서티 평가 100.41\n",
            "| 에폭 47 | 퍼플렉서티 평가 94.41\n",
            "| 에폭 48 | 퍼플렉서티 평가 90.50\n",
            "| 에폭 49 | 퍼플렉서티 평가 87.57\n",
            "| 에폭 50 | 퍼플렉서티 평가 82.87\n",
            "| 에폭 51 | 퍼플렉서티 평가 78.65\n",
            "| 에폭 52 | 퍼플렉서티 평가 75.66\n",
            "| 에폭 53 | 퍼플렉서티 평가 71.79\n",
            "| 에폭 54 | 퍼플렉서티 평가 70.18\n",
            "| 에폭 55 | 퍼플렉서티 평가 65.36\n",
            "| 에폭 56 | 퍼플렉서티 평가 62.32\n",
            "| 에폭 57 | 퍼플렉서티 평가 59.30\n",
            "| 에폭 58 | 퍼플렉서티 평가 54.72\n",
            "| 에폭 59 | 퍼플렉서티 평가 52.84\n",
            "| 에폭 60 | 퍼플렉서티 평가 51.14\n",
            "| 에폭 61 | 퍼플렉서티 평가 48.64\n",
            "| 에폭 62 | 퍼플렉서티 평가 45.56\n",
            "| 에폭 63 | 퍼플렉서티 평가 42.64\n",
            "| 에폭 64 | 퍼플렉서티 평가 41.38\n",
            "| 에폭 65 | 퍼플렉서티 평가 38.73\n",
            "| 에폭 66 | 퍼플렉서티 평가 37.07\n",
            "| 에폭 67 | 퍼플렉서티 평가 35.43\n",
            "| 에폭 68 | 퍼플렉서티 평가 32.03\n",
            "| 에폭 69 | 퍼플렉서티 평가 31.33\n",
            "| 에폭 70 | 퍼플렉서티 평가 29.66\n",
            "| 에폭 71 | 퍼플렉서티 평가 27.77\n",
            "| 에폭 72 | 퍼플렉서티 평가 25.97\n",
            "| 에폭 73 | 퍼플렉서티 평가 25.13\n",
            "| 에폭 74 | 퍼플렉서티 평가 23.56\n",
            "| 에폭 75 | 퍼플렉서티 평가 22.49\n",
            "| 에폭 76 | 퍼플렉서티 평가 20.31\n",
            "| 에폭 77 | 퍼플렉서티 평가 20.30\n",
            "| 에폭 78 | 퍼플렉서티 평가 18.75\n",
            "| 에폭 79 | 퍼플렉서티 평가 18.23\n",
            "| 에폭 80 | 퍼플렉서티 평가 16.95\n",
            "| 에폭 81 | 퍼플렉서티 평가 16.53\n",
            "| 에폭 82 | 퍼플렉서티 평가 16.10\n",
            "| 에폭 83 | 퍼플렉서티 평가 15.33\n",
            "| 에폭 84 | 퍼플렉서티 평가 14.39\n",
            "| 에폭 85 | 퍼플렉서티 평가 13.43\n",
            "| 에폭 86 | 퍼플렉서티 평가 12.39\n",
            "| 에폭 87 | 퍼플렉서티 평가 12.62\n",
            "| 에폭 88 | 퍼플렉서티 평가 11.64\n",
            "| 에폭 89 | 퍼플렉서티 평가 10.84\n",
            "| 에폭 90 | 퍼플렉서티 평가 10.35\n",
            "| 에폭 91 | 퍼플렉서티 평가 9.87\n",
            "| 에폭 92 | 퍼플렉서티 평가 9.54\n",
            "| 에폭 93 | 퍼플렉서티 평가 8.99\n",
            "| 에폭 94 | 퍼플렉서티 평가 8.14\n",
            "| 에폭 95 | 퍼플렉서티 평가 7.58\n",
            "| 에폭 96 | 퍼플렉서티 평가 7.34\n",
            "| 에폭 97 | 퍼플렉서티 평가 7.34\n",
            "| 에폭 98 | 퍼플렉서티 평가 7.22\n",
            "| 에폭 99 | 퍼플렉서티 평가 6.45\n",
            "| 에폭 100 | 퍼플렉서티 평가 6.37\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGJvp7_-B2o5"
      },
      "source": [
        "#6장 게이트가 추가된 RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S52iD121HBk"
      },
      "source": [
        "## 6.1.3 기울기 소실과 기울기 폭발의 원인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emydaPXEmVLD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "outputId": "3fb86ae8-ed81-449e-b2b4-906bfe91a63c"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "N = 2    # 미니배치 크기\n",
        "H = 3    # 은닉 상태 벡터의 차원 수\n",
        "T = 20   # 시계열 데이터의 길이\n",
        "\n",
        "dh = np.ones((N, H))\n",
        "np.random.seed(3)     #  재현할 수 있도록 난수의 시드 고정\n",
        "#Wh = np.random.randn(H, H)\n",
        "Wh = np.random.randn(H, H) * 0.5\n",
        "\n",
        "norm_list = []\n",
        "for t in range(T):\n",
        "  dh = np.matmul(dh, Wh.T)\n",
        "  norm = np.sqrt(np.sum(dh**2)) / N\n",
        "  norm_list.append(norm)\n",
        "\n",
        "  # 그래프 그리기\n",
        "plt.plot(np.arange(len(norm_list)), norm_list)\n",
        "plt.xticks([0, 4, 9, 14, 19], [1, 5, 10, 15, 20])\n",
        "plt.xlabel('시간 크기(time step)')\n",
        "plt.ylabel('노름(norm)')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49884 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44036 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 53356 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44592 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 45432 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47492 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49884 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44036 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 53356 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44592 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 45432 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47492 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuc21_Gr1Oz3"
      },
      "source": [
        "##6.1.4 기울기 폭발 대책"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL7wvBoapNk0"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "dW1 = np.random.rand(3, 3) * 10\n",
        "dW2 = np.random.rand(3, 3) * 10\n",
        "grads = [dW1, dW2]\n",
        "max_norm = 5.0\n",
        "\n",
        "def clip_grads(grads, max_norm):\n",
        "  total_norm = 0\n",
        "  for grad in grads:\n",
        "    total_norm += np.sum(grad ** 2)\n",
        "  total_norm = np.sqrt(total_norm)\n",
        "\n",
        "  rate = max_norm / (total_norm + 1*e - 6)\n",
        "  if rate < 1:\n",
        "    for grad in grads:\n",
        "      grad +=rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JroSUB2H8lnD"
      },
      "source": [
        "##6.3 LSTM 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVeB0xneu25o"
      },
      "source": [
        "class LSTM:\n",
        "    def __init__(self, Wx, Wh, b):\n",
        "        '''\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        Wx: 입력 x에 대한 가중치 매개변수(4개분의 가중치가 담겨 있음)\n",
        "        Wh: 은닉 상태 h에 대한 가장추 매개변수(4개분의 가중치가 담겨 있음)\n",
        "        b: 편향（4개분의 편향이 담겨 있음）\n",
        "        '''\n",
        "        self.params = [Wx, Wh, b]\n",
        "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
        "        self.cache = None\n",
        "\n",
        "    def forward(self, x, h_prev, c_prev):\n",
        "        Wx, Wh, b = self.params\n",
        "        N, H = h_prev.shape\n",
        "\n",
        "        A = np.dot(x, Wx) + np.dot(h_prev, Wh) + b\n",
        "\n",
        "        f = A[:, :H]\n",
        "        g = A[:, H:2*H]\n",
        "        i = A[:, 2*H:3*H]\n",
        "        o = A[:, 3*H:]\n",
        "\n",
        "        f = sigmoid(f)\n",
        "        g = np.tanh(g)\n",
        "        i = sigmoid(i)\n",
        "        o = sigmoid(o)\n",
        "\n",
        "        c_next = f * c_prev + g * i\n",
        "        h_next = o * np.tanh(c_next)\n",
        "\n",
        "        self.cache = (x, h_prev, c_prev, i, f, g, o, c_next)\n",
        "        return h_next, c_next\n",
        "\n",
        "    def backward(self, dh_next, dc_next):\n",
        "        Wx, Wh, b = self.params\n",
        "        x, h_prev, c_prev, i, f, g, o, c_next = self.cache\n",
        "\n",
        "        tanh_c_next = np.tanh(c_next)\n",
        "\n",
        "        ds = dc_next + (dh_next * o) * (1 - tanh_c_next ** 2)\n",
        "\n",
        "        dc_prev = ds * f\n",
        "\n",
        "        di = ds * g\n",
        "        df = ds * c_prev\n",
        "        do = dh_next * tanh_c_next\n",
        "        dg = ds * i\n",
        "\n",
        "        di *= i * (1 - i)\n",
        "        df *= f * (1 - f)\n",
        "        do *= o * (1 - o)\n",
        "        dg *= (1 - g ** 2)\n",
        "\n",
        "        dA = np.hstack((df, dg, di, do))\n",
        "\n",
        "        dWh = np.dot(h_prev.T, dA)\n",
        "        dWx = np.dot(x.T, dA)\n",
        "        db = dA.sum(axis=0)\n",
        "\n",
        "        self.grads[0][...] = dWx\n",
        "        self.grads[1][...] = dWh\n",
        "        self.grads[2][...] = db\n",
        "\n",
        "        dx = np.dot(dA, Wx.T)\n",
        "        dh_prev = np.dot(dA, Wh.T)\n",
        "\n",
        "        return dx, dh_prev, dc_prev\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8OQPGGjIoRD"
      },
      "source": [
        "##6.3.1 Time LSTM 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfS5VxqE9qw6"
      },
      "source": [
        "class TimeLSTM:\n",
        "    def __init__(self, Wx, Wh, b, stateful=False):\n",
        "        self.params = [Wx, Wh, b]\n",
        "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
        "        self.layers = None\n",
        "\n",
        "        self.h, self.c = None, None\n",
        "        self.dh = None\n",
        "        self.stateful = stateful\n",
        "\n",
        "    def forward(self, xs):\n",
        "        Wx, Wh, b = self.params\n",
        "        N, T, D = xs.shape\n",
        "        H = Wh.shape[0]\n",
        "\n",
        "        self.layers = []\n",
        "        hs = np.empty((N, T, H), dtype='f')\n",
        "\n",
        "        if not self.stateful or self.h is None:\n",
        "            self.h = np.zeros((N, H), dtype='f')\n",
        "        if not self.stateful or self.c is None:\n",
        "            self.c = np.zeros((N, H), dtype='f')\n",
        "\n",
        "        for t in range(T):\n",
        "            layer = LSTM(*self.params)\n",
        "            self.h, self.c = layer.forward(xs[:, t, :], self.h, self.c)\n",
        "            hs[:, t, :] = self.h\n",
        "\n",
        "            self.layers.append(layer)\n",
        "\n",
        "        return hs\n",
        "\n",
        "    def backward(self, dhs):\n",
        "        Wx, Wh, b = self.params\n",
        "        N, T, H = dhs.shape\n",
        "        D = Wx.shape[0]\n",
        "\n",
        "        dxs = np.empty((N, T, D), dtype='f')\n",
        "        dh, dc = 0, 0\n",
        "\n",
        "        grads = [0, 0, 0]\n",
        "        for t in reversed(range(T)):\n",
        "            layer = self.layers[t]\n",
        "            dx, dh, dc = layer.backward(dhs[:, t, :] + dh, dc)\n",
        "            dxs[:, t, :] = dx\n",
        "            for i, grad in enumerate(layer.grads):\n",
        "                grads[i] += grad\n",
        "\n",
        "        for i, grad in enumerate(grads):\n",
        "            self.grads[i][...] = grad\n",
        "        self.dh = dh\n",
        "        return dxs\n",
        "\n",
        "    def set_state(self, h, c=None):\n",
        "        self.h, self.c = h, c\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.h, self.c = None, None\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5buLw86IK6bZ"
      },
      "source": [
        "##6.4 LSTM을 사용한 언어 모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAdyW76MLCpI"
      },
      "source": [
        "\n",
        "import sys, os\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append('os.chdir')\n",
        "\n",
        "from common.time_layers import *\n",
        "from common.base_model import BaseModel\n",
        "\n",
        "\n",
        "class Rnnlm(BaseModel):\n",
        "    def __init__(self, vocab_size=10000, wordvec_size=100, hidden_size=100):\n",
        "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
        "        rn = np.random.randn\n",
        "\n",
        "        # 가중치 초기화\n",
        "        embed_W = (rn(V, D) / 100).astype('f')\n",
        "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
        "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
        "        lstm_b = np.zeros(4 * H).astype('f')\n",
        "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
        "        affine_b = np.zeros(V).astype('f')\n",
        "\n",
        "        # 계층 생성\n",
        "        self.layers = [\n",
        "            TimeEmbedding(embed_W),\n",
        "            TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True),\n",
        "            TimeAffine(affine_W, affine_b)\n",
        "        ]\n",
        "        self.loss_layer = TimeSoftmaxWithLoss()\n",
        "        self.lstm_layer = self.layers[1]\n",
        "\n",
        "        # 모든 가중치와 기울기를 리스트에 모은다.\n",
        "        self.params, self.grads = [], []\n",
        "        for layer in self.layers:\n",
        "            self.params += layer.params\n",
        "            self.grads += layer.grads\n",
        "\n",
        "    def predict(self, xs):\n",
        "        for layer in self.layers:\n",
        "            xs = layer.forward(xs)\n",
        "        return xs\n",
        "\n",
        "    def forward(self, xs, ts):\n",
        "        score = self.predict(xs)\n",
        "        loss = self.loss_layer.forward(score, ts)\n",
        "        return loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        dout = self.loss_layer.backward(dout)\n",
        "        for layer in reversed(self.layers):\n",
        "            dout = layer.backward(dout)\n",
        "        return dout\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.lstm_layer.reset_state()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77bqokVC-UA-"
      },
      "source": [
        "#6.5 RNNLM 추가 개선"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6w-p2EE-cB5"
      },
      "source": [
        "##6.5.4 개선된 RNNLM 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fWFAYm59_fg"
      },
      "source": [
        "import sys, os\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append('os.chdir')\n",
        "\n",
        "from common.time_layers import *\n",
        "from common.np import *  # import numpy as np\n",
        "from common.base_model import BaseModel\n",
        "\n",
        "\n",
        "class BetterRnnlm(BaseModel):\n",
        "    '''\n",
        "     LSTM 계층을 2개 사용하고 각 층에 드롭아웃을 적용한 모델이다.\n",
        "     아래 [1]에서 제안한 모델을 기초로 하였고, [2]와 [3]의 가중치 공유(weight tying)를 적용했다.\n",
        "\n",
        "     [1] Recurrent Neural Network Regularization (https://arxiv.org/abs/1409.2329)\n",
        "     [2] Using the Output Embedding to Improve Language Models (https://arxiv.org/abs/1608.05859)\n",
        "     [3] Tying Word Vectors and Word Classifiers (https://arxiv.org/pdf/1611.01462.pdf)\n",
        "    '''\n",
        "    def __init__(self, vocab_size=10000, wordvec_size=650,\n",
        "                 hidden_size=650, dropout_ratio=0.5):\n",
        "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
        "        rn = np.random.randn\n",
        "\n",
        "        embed_W = (rn(V, D) / 100).astype('f')\n",
        "        lstm_Wx1 = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
        "        lstm_Wh1 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
        "        lstm_b1 = np.zeros(4 * H).astype('f')\n",
        "        lstm_Wx2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
        "        lstm_Wh2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
        "        lstm_b2 = np.zeros(4 * H).astype('f')\n",
        "        affine_b = np.zeros(V).astype('f')\n",
        "\n",
        "        self.layers = [\n",
        "            TimeEmbedding(embed_W),\n",
        "            TimeDropout(dropout_ratio),\n",
        "            TimeLSTM(lstm_Wx1, lstm_Wh1, lstm_b1, stateful=True),\n",
        "            TimeDropout(dropout_ratio),\n",
        "            TimeLSTM(lstm_Wx2, lstm_Wh2, lstm_b2, stateful=True),\n",
        "            TimeDropout(dropout_ratio),\n",
        "            TimeAffine(embed_W.T, affine_b)  # weight tying!!\n",
        "        ]\n",
        "        self.loss_layer = TimeSoftmaxWithLoss()\n",
        "        self.lstm_layers = [self.layers[2], self.layers[4]]\n",
        "        self.drop_layers = [self.layers[1], self.layers[3], self.layers[5]]\n",
        "\n",
        "        self.params, self.grads = [], []\n",
        "        for layer in self.layers:\n",
        "            self.params += layer.params\n",
        "            self.grads += layer.grads\n",
        "\n",
        "    def predict(self, xs, train_flg=False):\n",
        "        for layer in self.drop_layers:\n",
        "            layer.train_flg = train_flg\n",
        "\n",
        "        for layer in self.layers:\n",
        "            xs = layer.forward(xs)\n",
        "        return xs\n",
        "\n",
        "    def forward(self, xs, ts, train_flg=True):\n",
        "        score = self.predict(xs, train_flg)\n",
        "        loss = self.loss_layer.forward(score, ts)\n",
        "        return loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        dout = self.loss_layer.backward(dout)\n",
        "        for layer in reversed(self.layers):\n",
        "            dout = layer.backward(dout)\n",
        "        return dout\n",
        "\n",
        "    def reset_state(self):\n",
        "        for layer in self.lstm_layers:\n",
        "            layer.reset_state()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFGXQQHi-ntr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "1c8f2620-fa45-4ea4-8f12-8141bf5b6650"
      },
      "source": [
        "import sys, os\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append('os.chdir')\n",
        "\n",
        "\n",
        "from common import config\n",
        "# GPU에서 실행하려면 아래 주석을 해제하세요(CuPy 필요).\n",
        "# ==============================================\n",
        "# config.GPU = True\n",
        "# ==============================================\n",
        "from common.optimizer import SGD\n",
        "from common.trainer import RnnlmTrainer\n",
        "from common.util import eval_perplexity, to_gpu\n",
        "from dataset import ptb\n",
        "from ch06.better_rnnlm import BetterRnnlm\n",
        "\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "batch_size = 20\n",
        "wordvec_size = 650\n",
        "hidden_size = 650\n",
        "time_size = 35\n",
        "lr = 20.0\n",
        "max_epoch = 40\n",
        "max_grad = 0.25\n",
        "dropout = 0.5\n",
        "\n",
        "# 학습 데이터 읽기\n",
        "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
        "corpus_val, _, _ = ptb.load_data('val')\n",
        "corpus_test, _, _ = ptb.load_data('test')\n",
        "\n",
        "if config.GPU:\n",
        "    corpus = to_gpu(corpus)\n",
        "    corpus_val = to_gpu(corpus_val)\n",
        "    corpus_test = to_gpu(corpus_test)\n",
        "\n",
        "vocab_size = len(word_to_id)\n",
        "xs = corpus[:-1]\n",
        "ts = corpus[1:]\n",
        "\n",
        "model = BetterRnnlm(vocab_size, wordvec_size, hidden_size, dropout)\n",
        "optimizer = SGD(lr)\n",
        "trainer = RnnlmTrainer(model, optimizer)\n",
        "\n",
        "best_ppl = float('inf')\n",
        "for epoch in range(max_epoch):\n",
        "    trainer.fit(xs, ts, max_epoch=1, batch_size=batch_size,\n",
        "                time_size=time_size, max_grad=max_grad)\n",
        "\n",
        "    model.reset_state()\n",
        "    ppl = eval_perplexity(model, corpus_val)\n",
        "    print('검증 퍼플렉서티: ', ppl)\n",
        "\n",
        "    if best_ppl > ppl:\n",
        "        best_ppl = ppl\n",
        "        model.save_params()\n",
        "    else:\n",
        "        lr /= 4.0\n",
        "        optimizer.lr = lr\n",
        "\n",
        "    model.reset_state()\n",
        "    print('-' * 50)\n",
        "\n",
        "\n",
        "# 테스트 데이터로 평가\n",
        "model.reset_state()\n",
        "ppl_test = eval_perplexity(model, corpus_test)\n",
        "print('테스트 퍼플렉서티: ', ppl_test)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading ptb.valid.txt ... \n",
            "Done\n",
            "Downloading ptb.test.txt ... \n",
            "Done\n",
            "| 에폭 1 |  반복 1 / 1327 | 시간 4[s] | 퍼플렉서티 9999.52\n",
            "| 에폭 1 |  반복 21 / 1327 | 시간 73[s] | 퍼플렉서티 4340.90\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCuYMkHLfBXV"
      },
      "source": [
        "#7장"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0TXuk_ffDnc"
      },
      "source": [
        "##7.1.2 문장 생성 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZ72lMk2-5Ap",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20a1569e-27f7-4c16-ad94-201faad9c295"
      },
      "source": [
        "import sys, os\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append('os.chdir')\n",
        "\n",
        "import numpy as np\n",
        "from common.functions import softmax\n",
        "from ch06.rnnlm import Rnnlm\n",
        "from ch06.better_rnnlm import BetterRnnlm\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class RnnlmGen(Rnnlm):\n",
        "    def generate(self, start_id, skip_ids=None, sample_size=100):\n",
        "        word_ids = [start_id]\n",
        "\n",
        "        x = start_id\n",
        "        while len(word_ids) < sample_size:\n",
        "            x = np.array(x).reshape(1, 1)\n",
        "            score = self.predict(x)\n",
        "            p = softmax(score.flatten())\n",
        "\n",
        "            sampled = np.random.choice(len(p), size=1, p=p)\n",
        "            if (skip_ids is None) or (sampled not in skip_ids):\n",
        "                x = sampled\n",
        "                word_ids.append(int(x))\n",
        "\n",
        "        return word_ids\n",
        "\n",
        "    def get_state(self):\n",
        "        return self.lstm_layer.h, self.lstm_layer.c\n",
        "\n",
        "    def set_state(self, state):\n",
        "        self.lstm_layer.set_state(*state)\n",
        "\n",
        "\n",
        "class BetterRnnlmGen(BetterRnnlm):\n",
        "    def generate(self, start_id, skip_ids=None, sample_size=100):\n",
        "        word_ids = [start_id]\n",
        "\n",
        "        x = start_id\n",
        "        while len(word_ids) < sample_size:\n",
        "            x = np.array(x).reshape(1, 1)\n",
        "            score = self.predict(x).flatten()\n",
        "            p = softmax(score).flatten()\n",
        "\n",
        "            sampled = np.random.choice(len(p), size=1, p=p)\n",
        "            if (skip_ids is None) or (sampled not in skip_ids):\n",
        "                x = sampled\n",
        "                word_ids.append(int(x))\n",
        "\n",
        "        return word_ids\n",
        "\n",
        "    def get_state(self):\n",
        "        states = []\n",
        "        for layer in self.lstm_layers:\n",
        "            states.append((layer.h, layer.c))\n",
        "        return states\n",
        "\n",
        "    def set_state(self, states):\n",
        "        for layer, state in zip(self.lstm_layers, states):\n",
        "            layer.set_state(*state)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNQi2TPKgWxk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "a4ec5545-749d-4ac0-b250-db644228496d"
      },
      "source": [
        "import sys, os\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append('os.chdir')\n",
        "\n",
        "from ch07.rnnlm_gen import RnnlmGen\n",
        "from dataset import ptb\n",
        "\n",
        "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
        "vocab_size = len(word_to_id)\n",
        "corpus_size = len(corpus)\n",
        "\n",
        "model = RnnlmGen()\n",
        "model.load_params('/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/ch06/Rnnlm.pkl')\n",
        "\n",
        "# start 문자와 skip 문자 설정\n",
        "start_word = 'you'\n",
        "start_id = word_to_id[start_word]\n",
        "skip_words = ['N', '<unk>', '$']\n",
        "skip_ids = [word_to_id[w] for w in skip_words]\n",
        "# 문장 생성\n",
        "word_ids = model.generate(start_id, skip_ids)\n",
        "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
        "txt = txt.replace(' <eos>', '.\\n')\n",
        "print(txt)\n",
        "print(start_id)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "you tube he even consented to forget for quotations to play productivity today and them than late to the moment.\n",
            " first company said silver along at a leveraged buy-out of raw cancer.\n",
            " require more money and far the last educational policy is n't aimed at all but contended or instead strategy for the flag it does n't come down.\n",
            " mr. honecker wants to have a matter.\n",
            " mr. sharon said the participation my cause in the kansas city had become assured on his job.\n",
            " but mr. roman has received a new loan campaign which is strong\n",
            "316\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54A0TWnNj6Ur"
      },
      "source": [
        "##7.1.3 더 좋은 문장으로"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vycMYlngq_A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "outputId": "dde46a76-3bca-4669-9d04-3199195988d2"
      },
      "source": [
        "import sys, os\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append('os.chdir')\n",
        "from common.np import *\n",
        "from ch07.rnnlm_gen import BetterRnnlmGen\n",
        "from dataset import ptb\n",
        "\n",
        "\n",
        "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
        "vocab_size = len(word_to_id)\n",
        "corpus_size = len(corpus)\n",
        "\n",
        "\n",
        "model = BetterRnnlmGen()\n",
        "model.load_params('/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/ch06/BetterRnnlm.pkl')\n",
        "\n",
        "# start 문자와 skip 문자 설정\n",
        "'''\n",
        "start_word = 'you'\n",
        "start_id = word_to_id[start_word]\n",
        "skip_words = ['N', '<unk>', '$']\n",
        "skip_ids = [word_to_id[w] for w in skip_words]\n",
        "# 문장 생성\n",
        "word_ids = model.generate(start_id, skip_ids)\n",
        "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
        "txt = txt.replace(' <eos>', '.\\n')\n",
        "\n",
        "print(txt)\n",
        "\n",
        "'''\n",
        "model.reset_state()\n",
        "\n",
        "start_words = 'the meaning of life is'\n",
        "start_ids = [word_to_id[w] for w in start_words.split(' ')]\n",
        "\n",
        "for x in start_ids[:-1]:\n",
        "    x = np.array(x).reshape(1, 1)\n",
        "    model.predict(x)\n",
        "\n",
        "word_ids = model.generate(start_ids[-1], skip_ids)\n",
        "word_ids = start_ids[:-1] + word_ids\n",
        "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
        "txt = txt.replace(' <eos>', '.\\n')\n",
        "print('-' * 50)\n",
        "print(txt)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------\n",
            "the meaning of life is the ad pool.\n",
            " people filled with the potential system of businessmen that have continue long need to fill major stocks what is in the market at a time when a white knight is a bad thing.\n",
            " bob ingersoll is a secret and he tried to encourage greater up about a qualified group of positions together not the one thing at a recent.\n",
            " whatever it is is the only thing is a good farmer.\n",
            " but in recent years we 're doing a concept of the and throwing out their package against the company.\n",
            " last issue\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_PRqhCqkDU6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "outputId": "a42b91df-20dd-4baf-ebe0-c04e99e1915b"
      },
      "source": [
        "import sys, os\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append('os.chdir')\n",
        "from dataset import sequence\n",
        "\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = \\\n",
        "    sequence.load_data('addition.txt', seed=1984)\n",
        "char_to_id, id_to_char = sequence.get_vocab()\n",
        "\n",
        "print(char_to_id)\n",
        "\n",
        "print(x_train.shape, t_train.shape)\n",
        "print(x_test.shape, t_test.shape)\n",
        "# (45000, 7) (45000, 5)\n",
        "# (5000, 7) (5000, 5)\n",
        "\n",
        "print(x_train[0])\n",
        "print(t_train[0])\n",
        "# [ 3  0  2  0  0 11  5]\n",
        "# [ 6  0 11  7  5]\n",
        "\n",
        "print(''.join([id_to_char[c] for c in x_train[0]]))\n",
        "print(''.join([id_to_char[c] for c in t_train[0]]))\n",
        "# 71+118\n",
        "# _189\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'1': 0, '6': 1, '+': 2, '7': 3, '5': 4, ' ': 5, '_': 6, '9': 7, '2': 8, '0': 9, '3': 10, '8': 11, '4': 12}\n",
            "(45000, 7) (45000, 5)\n",
            "(5000, 7) (5000, 5)\n",
            "[ 3  0  2  0  0 11  5]\n",
            "[ 6  0 11  7  5]\n",
            "71+118 \n",
            "_189 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoCG-WPjuBZg"
      },
      "source": [
        "##7.3.1 Encoder 클래스"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiCjzDZTtI7h"
      },
      "source": [
        "import sys, os\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append('os.chdir')\n",
        "from common.time_layers import *\n",
        "from common.base_model import BaseModel\n",
        "\n",
        "\n",
        "class Encoder:\n",
        "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
        "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
        "        rn = np.random.randn\n",
        "\n",
        "        embed_W = (rn(V, D) / 100).astype('f')\n",
        "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
        "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
        "        lstm_b = np.zeros(4 * H).astype('f')\n",
        "\n",
        "        self.embed = TimeEmbedding(embed_W)\n",
        "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=False)\n",
        "\n",
        "        self.params = self.embed.params + self.lstm.params\n",
        "        self.grads = self.embed.grads + self.lstm.grads\n",
        "        self.hs = None\n",
        "\n",
        "    def forward(self, xs):\n",
        "        xs = self.embed.forward(xs)\n",
        "        hs = self.lstm.forward(xs)\n",
        "        self.hs = hs\n",
        "        return hs[:, -1, :]\n",
        "\n",
        "    def backward(self, dh):\n",
        "        dhs = np.zeros_like(self.hs)\n",
        "        dhs[:, -1, :] = dh\n",
        "\n",
        "        dout = self.lstm.backward(dhs)\n",
        "        dout = self.embed.backward(dout)\n",
        "        return dout\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDKli74GwlGw"
      },
      "source": [
        "\n",
        "class Decoder:\n",
        "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
        "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
        "        rn = np.random.randn\n",
        "\n",
        "        embed_W = (rn(V, D) / 100).astype('f')\n",
        "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
        "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
        "        lstm_b = np.zeros(4 * H).astype('f')\n",
        "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
        "        affine_b = np.zeros(V).astype('f')\n",
        "\n",
        "        self.embed = TimeEmbedding(embed_W)\n",
        "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True)\n",
        "        self.affine = TimeAffine(affine_W, affine_b)\n",
        "\n",
        "        self.params, self.grads = [], []\n",
        "        for layer in (self.embed, self.lstm, self.affine):\n",
        "            self.params += layer.params\n",
        "            self.grads += layer.grads\n",
        "\n",
        "    def forward(self, xs, h):\n",
        "        self.lstm.set_state(h)\n",
        "\n",
        "        out = self.embed.forward(xs)\n",
        "        out = self.lstm.forward(out)\n",
        "        score = self.affine.forward(out)\n",
        "        return score\n",
        "\n",
        "    def backward(self, dscore):\n",
        "        dout = self.affine.backward(dscore)\n",
        "        dout = self.lstm.backward(dout)\n",
        "        dout = self.embed.backward(dout)\n",
        "        dh = self.lstm.dh\n",
        "        return dh\n",
        "\n",
        "    def generate(self, h, start_id, sample_size):\n",
        "        sampled = []\n",
        "        sample_id = start_id\n",
        "        self.lstm.set_state(h)\n",
        "\n",
        "        for _ in range(sample_size):\n",
        "            x = np.array(sample_id).reshape((1, 1))\n",
        "            out = self.embed.forward(x)\n",
        "            out = self.lstm.forward(out)\n",
        "            score = self.affine.forward(out)\n",
        "\n",
        "            sample_id = np.argmax(score.flatten())\n",
        "            sampled.append(int(sample_id))\n",
        "\n",
        "        return sampled\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r51if6ZL0DOU"
      },
      "source": [
        "##7.3.3 Seq2Seq 클래스"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyoroutCyKBR"
      },
      "source": [
        "class Seq2seq(BaseModel):\n",
        "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
        "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
        "        self.encoder = Encoder(V, D, H)\n",
        "        self.decoder = Decoder(V, D, H)\n",
        "        self.softmax = TimeSoftmaxWithLoss()\n",
        "\n",
        "        self.params = self.encoder.params + self.decoder.params\n",
        "        self.grads = self.encoder.grads + self.decoder.grads\n",
        "\n",
        "    def forward(self, xs, ts):\n",
        "        decoder_xs, decoder_ts = ts[:, :-1], ts[:, 1:]\n",
        "\n",
        "        h = self.encoder.forward(xs)\n",
        "        score = self.decoder.forward(decoder_xs, h)\n",
        "        loss = self.softmax.forward(score, decoder_ts)\n",
        "        return loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        dout = self.softmax.backward(dout)\n",
        "        dh = self.decoder.backward(dout)\n",
        "        dout = self.encoder.backward(dh)\n",
        "        return dout\n",
        "\n",
        "    def generate(self, xs, start_id, sample_size):\n",
        "        h = self.encoder.forward(xs)\n",
        "        sampled = self.decoder.generate(h, start_id, sample_size)\n",
        "        return sampled\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHZmwmEu0A0R"
      },
      "source": [
        "##7.3.4 seq2seq 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jFtAI-Dz0Fo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "outputId": "575c1899-c4c0-46e1-969f-f9eeceb456b8"
      },
      "source": [
        "import sys, os\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append('os.chdir')\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataset import sequence\n",
        "from common.optimizer import Adam\n",
        "from common.trainer import Trainer\n",
        "from common.util import eval_seq2seq\n",
        "from ch07.seq2seq import Seq2seq\n",
        "from ch07.peeky_seq2seq import PeekySeq2seq\n",
        "\n",
        "\n",
        "# 데이터셋 읽기\n",
        "(x_train, t_train), (x_test, t_test) = sequence.load_data('addition.txt')\n",
        "char_to_id, id_to_char = sequence.get_vocab()\n",
        "\n",
        "# 입력 반전 여부 설정 =============================================\n",
        "is_reverse = False  # True\n",
        "if is_reverse:\n",
        "    x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n",
        "# ================================================================\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "vocab_size = len(char_to_id)\n",
        "wordvec_size = 16\n",
        "hideen_size = 128\n",
        "batch_size = 128\n",
        "max_epoch = 25\n",
        "max_grad = 5.0\n",
        "\n",
        "# 일반 혹은 엿보기(Peeky) 설정 =====================================\n",
        "model = Seq2seq(vocab_size, wordvec_size, hideen_size)\n",
        "# model = PeekySeq2seq(vocab_size, wordvec_size, hideen_size)\n",
        "# ================================================================\n",
        "optimizer = Adam()\n",
        "trainer = Trainer(model, optimizer)\n",
        "\n",
        "acc_list = []\n",
        "for epoch in range(max_epoch):\n",
        "    trainer.fit(x_train, t_train, max_epoch=1,\n",
        "                batch_size=batch_size, max_grad=max_grad)\n",
        "\n",
        "    correct_num = 0\n",
        "    for i in range(len(x_test)):\n",
        "        question, correct = x_test[[i]], t_test[[i]]\n",
        "        verbose = i < 10\n",
        "        correct_num += eval_seq2seq(model, question, correct,\n",
        "                                    id_to_char, verbose, is_reverse)\n",
        "\n",
        "    acc = float(correct_num) / len(x_test)\n",
        "    acc_list.append(acc)\n",
        "    print('검증 정확도 %.3f%%' % (acc * 100))\n",
        "\n",
        "# 그래프 그리기\n",
        "x = np.arange(len(acc_list))\n",
        "plt.plot(x, acc_list, marker='o')\n",
        "plt.xlabel('에폭')\n",
        "plt.ylabel('정확도')\n",
        "plt.ylim(0, 1.0)\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b7c011774c3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0meval_seq2seq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mch07\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq2seq\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSeq2seq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mch07\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpeeky_seq2seq\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPeekySeq2seq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/ch07/peeky_seq2seq.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'..'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_layers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mseq2seq\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSeq2seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seq2seq'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdZO2bH_oM2S"
      },
      "source": [
        "# coding: utf-8\n",
        "import sys, os\n",
        "\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/ch07')\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master')\n",
        "from common.time_layers import *\n",
        "from ch07.seq2seq import Seq2seq, Encoder\n",
        "\n",
        "\n",
        "class PeekyDecoder:\n",
        "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
        "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
        "        rn = np.random.randn\n",
        "\n",
        "        embed_W = (rn(V, D) / 100).astype('f')\n",
        "        lstm_Wx = (rn(H + D, 4 * H) / np.sqrt(H + D)).astype('f')\n",
        "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
        "        lstm_b = np.zeros(4 * H).astype('f')\n",
        "        affine_W = (rn(H + H, V) / np.sqrt(H + H)).astype('f')\n",
        "        affine_b = np.zeros(V).astype('f')\n",
        "\n",
        "        self.embed = TimeEmbedding(embed_W)\n",
        "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True)\n",
        "        self.affine = TimeAffine(affine_W, affine_b)\n",
        "\n",
        "        self.params, self.grads = [], []\n",
        "        for layer in (self.embed, self.lstm, self.affine):\n",
        "            self.params += layer.params\n",
        "            self.grads += layer.grads\n",
        "        self.cache = None\n",
        "\n",
        "    def forward(self, xs, h):\n",
        "        N, T = xs.shape\n",
        "        N, H = h.shape\n",
        "\n",
        "        self.lstm.set_state(h)\n",
        "\n",
        "        out = self.embed.forward(xs)\n",
        "        hs = np.repeat(h, T, axis=0).reshape(N, T, H)\n",
        "        out = np.concatenate((hs, out), axis=2)\n",
        "\n",
        "        out = self.lstm.forward(out)\n",
        "        out = np.concatenate((hs, out), axis=2)\n",
        "\n",
        "        score = self.affine.forward(out)\n",
        "        self.cache = H\n",
        "        return score\n",
        "\n",
        "    def backward(self, dscore):\n",
        "        H = self.cache\n",
        "\n",
        "        dout = self.affine.backward(dscore)\n",
        "        dout, dhs0 = dout[:, :, H:], dout[:, :, :H]\n",
        "        dout = self.lstm.backward(dout)\n",
        "        dembed, dhs1 = dout[:, :, H:], dout[:, :, :H]\n",
        "        self.embed.backward(dembed)\n",
        "\n",
        "        dhs = dhs0 + dhs1\n",
        "        dh = self.lstm.dh + np.sum(dhs, axis=1)\n",
        "        return dh\n",
        "\n",
        "    def generate(self, h, start_id, sample_size):\n",
        "        sampled = []\n",
        "        char_id = start_id\n",
        "        self.lstm.set_state(h)\n",
        "\n",
        "        H = h.shape[1]\n",
        "        peeky_h = h.reshape(1, 1, H)\n",
        "        for _ in range(sample_size):\n",
        "            x = np.array([char_id]).reshape((1, 1))\n",
        "            out = self.embed.forward(x)\n",
        "\n",
        "            out = np.concatenate((peeky_h, out), axis=2)\n",
        "            out = self.lstm.forward(out)\n",
        "            out = np.concatenate((peeky_h, out), axis=2)\n",
        "            score = self.affine.forward(out)\n",
        "\n",
        "            char_id = np.argmax(score.flatten())\n",
        "            sampled.append(char_id)\n",
        "\n",
        "        return sampled\n",
        "\n",
        "\n",
        "class PeekySeq2seq(Seq2seq):\n",
        "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
        "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
        "        self.encoder = Encoder(V, D, H)\n",
        "        self.decoder = PeekyDecoder(V, D, H)\n",
        "        self.softmax = TimeSoftmaxWithLoss()\n",
        "\n",
        "        self.params = self.encoder.params + self.decoder.params\n",
        "        self.grads = self.encoder.grads + self.decoder.grads\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUwNLIILpjMF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "df864872-5361-469f-88fc-65df8c790449"
      },
      "source": [
        "import sys, os\n",
        "\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/ch07')\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master')\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataset import sequence\n",
        "from common.optimizer import Adam\n",
        "from common.trainer import Trainer\n",
        "from common.util import eval_seq2seq\n",
        "from seq2seq import Seq2seq\n",
        "from peeky_seq2seq import PeekySeq2seq\n",
        "\n",
        "\n",
        "# 데이터셋 읽기\n",
        "(x_train, t_train), (x_test, t_test) = sequence.load_data('addition.txt')\n",
        "char_to_id, id_to_char = sequence.get_vocab()\n",
        "\n",
        "# 입력 반전 여부 설정 =============================================\n",
        "is_reverse = False  # True\n",
        "if is_reverse:\n",
        "    x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n",
        "# ================================================================\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "vocab_size = len(char_to_id)\n",
        "wordvec_size = 16\n",
        "hideen_size = 128\n",
        "batch_size = 128\n",
        "max_epoch = 25\n",
        "max_grad = 5.0\n",
        "\n",
        "# 일반 혹은 엿보기(Peeky) 설정 =====================================\n",
        "model = Seq2seq(vocab_size, wordvec_size, hideen_size)\n",
        "# model = PeekySeq2seq(vocab_size, wordvec_size, hideen_size)\n",
        "# ================================================================\n",
        "optimizer = Adam()\n",
        "trainer = Trainer(model, optimizer)\n",
        "\n",
        "acc_list = []\n",
        "for epoch in range(max_epoch):\n",
        "    trainer.fit(x_train, t_train, max_epoch=1,\n",
        "                batch_size=batch_size, max_grad=max_grad)\n",
        "\n",
        "    correct_num = 0\n",
        "    for i in range(len(x_test)):\n",
        "        question, correct = x_test[[i]], t_test[[i]]\n",
        "        verbose = i < 10\n",
        "        correct_num += eval_seq2seq(model, question, correct,\n",
        "                                    id_to_char, verbose, is_reverse)\n",
        "\n",
        "    acc = float(correct_num) / len(x_test)\n",
        "    acc_list.append(acc)\n",
        "    print('검증 정확도 %.3f%%' % (acc * 100))\n",
        "\n",
        "# 그래프 그리기\n",
        "x = np.arange(len(acc_list))\n",
        "plt.plot(x, acc_list, marker='o')\n",
        "plt.xlabel('에폭')\n",
        "plt.ylabel('정확도')\n",
        "plt.ylim(0, 1.0)\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| 에폭 1 |  반복 1 / 351 | 시간 0[s] | 손실 4.09\n",
            "| 에폭 1 |  반복 21 / 351 | 시간 1[s] | 손실 3.98\n",
            "| 에폭 1 |  반복 41 / 351 | 시간 2[s] | 손실 2.51\n",
            "| 에폭 1 |  반복 61 / 351 | 시간 3[s] | 손실 2.02\n",
            "| 에폭 1 |  반복 81 / 351 | 시간 5[s] | 손실 1.96\n",
            "| 에폭 1 |  반복 101 / 351 | 시간 6[s] | 손실 1.91\n",
            "| 에폭 1 |  반복 121 / 351 | 시간 7[s] | 손실 1.89\n",
            "| 에폭 1 |  반복 141 / 351 | 시간 9[s] | 손실 1.87\n",
            "| 에폭 1 |  반복 161 / 351 | 시간 10[s] | 손실 1.86\n",
            "| 에폭 1 |  반복 181 / 351 | 시간 11[s] | 손실 1.86\n",
            "| 에폭 1 |  반복 201 / 351 | 시간 13[s] | 손실 1.85\n",
            "| 에폭 1 |  반복 221 / 351 | 시간 14[s] | 손실 1.85\n",
            "| 에폭 1 |  반복 241 / 351 | 시간 15[s] | 손실 1.85\n",
            "| 에폭 1 |  반복 261 / 351 | 시간 17[s] | 손실 1.85\n",
            "| 에폭 1 |  반복 281 / 351 | 시간 18[s] | 손실 1.84\n",
            "| 에폭 1 |  반복 301 / 351 | 시간 19[s] | 손실 1.84\n",
            "| 에폭 1 |  반복 321 / 351 | 시간 21[s] | 손실 1.84\n",
            "| 에폭 1 |  반복 341 / 351 | 시간 22[s] | 손실 1.82\n",
            "Q 77+85  \n",
            "T 162 \n",
            "\u001b[91m☒\u001b[0m 102 \n",
            "---\n",
            "Q 975+164\n",
            "T 1139\n",
            "\u001b[91m☒\u001b[0m 1011\n",
            "---\n",
            "Q 582+84 \n",
            "T 666 \n",
            "\u001b[91m☒\u001b[0m 102 \n",
            "---\n",
            "Q 8+155  \n",
            "T 163 \n",
            "\u001b[91m☒\u001b[0m 102 \n",
            "---\n",
            "Q 367+55 \n",
            "T 422 \n",
            "\u001b[91m☒\u001b[0m 102 \n",
            "---\n",
            "Q 600+257\n",
            "T 857 \n",
            "\u001b[91m☒\u001b[0m 1011\n",
            "---\n",
            "Q 761+292\n",
            "T 1053\n",
            "\u001b[91m☒\u001b[0m 1011\n",
            "---\n",
            "Q 830+597\n",
            "T 1427\n",
            "\u001b[91m☒\u001b[0m 1011\n",
            "---\n",
            "Q 26+838 \n",
            "T 864 \n",
            "\u001b[91m☒\u001b[0m 102 \n",
            "---\n",
            "Q 143+93 \n",
            "T 236 \n",
            "\u001b[91m☒\u001b[0m 102 \n",
            "---\n",
            "검증 정확도 0.200%\n",
            "| 에폭 2 |  반복 1 / 351 | 시간 0[s] | 손실 1.77\n",
            "| 에폭 2 |  반복 21 / 351 | 시간 1[s] | 손실 1.79\n",
            "| 에폭 2 |  반복 41 / 351 | 시간 2[s] | 손실 1.78\n",
            "| 에폭 2 |  반복 61 / 351 | 시간 4[s] | 손실 1.77\n",
            "| 에폭 2 |  반복 81 / 351 | 시간 5[s] | 손실 1.77\n",
            "| 에폭 2 |  반복 101 / 351 | 시간 6[s] | 손실 1.76\n",
            "| 에폭 2 |  반복 121 / 351 | 시간 7[s] | 손실 1.76\n",
            "| 에폭 2 |  반복 141 / 351 | 시간 9[s] | 손실 1.76\n",
            "| 에폭 2 |  반복 161 / 351 | 시간 10[s] | 손실 1.76\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-95d4f330d215>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     trainer.fit(x_train, t_train, max_epoch=1,\n\u001b[0;32m---> 43\u001b[0;31m                 batch_size=batch_size, max_grad=max_grad)\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mcorrect_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/common/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, t, max_epoch, batch_size, max_grad, eval_interval)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;31m# 기울기 구해 매개변수 갱신\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 공유된 가중치를 하나로 모음\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/ch07/seq2seq.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xs, ts)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mdecoder_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_ts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/ch07/seq2seq.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xs)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mhs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/common/time_layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xs)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m             \u001b[0mhs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/common/time_layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h_prev, c_prev)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbBEK9jL1tQs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "outputId": "9f4ff9fc-821e-413e-b9e9-23a3847327f5"
      },
      "source": [
        "# coding: utf-8\n",
        "import sys, os\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master\")\n",
        "sys.path.append('os.chdir')\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataset import sequence\n",
        "from common.optimizer import Adam\n",
        "from common.trainer import Trainer\n",
        "from common.util import eval_seq2seq\n",
        "from ch08.attention_seq2seq import AttentionSeq2seq\n",
        "from ch07.seq2seq import Seq2seq\n",
        "from ch07.peeky_seq2seq import PeekySeq2seq\n",
        "\n",
        "\n",
        "# 데이터 읽기\n",
        "(x_train, t_train), (x_test, t_test) = sequence.load_data('date.txt')\n",
        "char_to_id, id_to_char = sequence.get_vocab()\n",
        "\n",
        "# 입력 문장 반전\n",
        "x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "vocab_size = len(char_to_id)\n",
        "wordvec_size = 16\n",
        "hidden_size = 256\n",
        "batch_size = 128\n",
        "max_epoch = 10\n",
        "max_grad = 5.0\n",
        "\n",
        "model = AttentionSeq2seq(vocab_size, wordvec_size, hidden_size)\n",
        "# model = Seq2seq(vocab_size, wordvec_size, hidden_size)\n",
        "# model = PeekySeq2seq(vocab_size, wordvec_size, hidden_size)\n",
        "\n",
        "optimizer = Adam()\n",
        "trainer = Trainer(model, optimizer)\n",
        "\n",
        "acc_list = []\n",
        "for epoch in range(max_epoch):\n",
        "    trainer.fit(x_train, t_train, max_epoch=1,\n",
        "                batch_size=batch_size, max_grad=max_grad)\n",
        "\n",
        "    correct_num = 0\n",
        "    for i in range(len(x_test)):\n",
        "        question, correct = x_test[[i]], t_test[[i]]\n",
        "        verbose = i < 10\n",
        "        correct_num += eval_seq2seq(model, question, correct,\n",
        "                                    id_to_char, verbose, is_reverse=True)\n",
        "\n",
        "    acc = float(correct_num) / len(x_test)\n",
        "    acc_list.append(acc)\n",
        "    print('정확도 %.3f%%' % (acc * 100))\n",
        "\n",
        "\n",
        "model.save_params()\n",
        "\n",
        "# 그래프 그리기\n",
        "x = np.arange(len(acc_list))\n",
        "plt.plot(x, acc_list, marker='o')\n",
        "plt.xlabel('에폭')\n",
        "plt.ylabel('정확도')\n",
        "plt.ylim(-0.05, 1.05)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| 에폭 1 |  반복 1 / 351 | 시간 0[s] | 손실 4.08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-2f02f85d969b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     trainer.fit(x_train, t_train, max_epoch=1,\n\u001b[0;32m---> 43\u001b[0;31m                 batch_size=batch_size, max_grad=max_grad)\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mcorrect_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/common/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, t, max_epoch, batch_size, max_grad, eval_interval)\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;31m# 기울기 구해 매개변수 갱신\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 공유된 가중치를 하나로 모음\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmax_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/ch07/seq2seq.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, dout)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mdh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/ch08/attention_seq2seq.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, dscore)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mdc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddec_hs0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mdenc_hs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddec_hs1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mddec_hs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mddec_hs0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mddec_hs1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mddec_hs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/ch08/attention_layer.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, dout)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mdhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0mdhs_enc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdhs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mdhs_dec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/ch08/attention_layer.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, dout)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mdhs0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_sum_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mdhs1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_weight_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mdhs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdhs0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdhs1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2-master/ch08/attention_layer.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, da)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mdhs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mdhr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDm3U-tOo0KB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}